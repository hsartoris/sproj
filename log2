2018-04-29 07:17:57.964716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:17:57.965242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.66GiB
2018-04-29 07:17:57.965263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:17:58.186349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:17:58.186377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:17:58.186384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:17:58.186562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7290 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '25',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 9.2568; conv batch loss = 8.7880
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7600; conv batch loss = 0.8100
Step 2249	dumb batch loss = 0.5293; conv batch loss = 0.4913
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2901; conv batch loss = 0.3767
Step 4499	dumb batch loss = 0.2217; conv batch loss = 0.2982
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1494; conv batch loss = 0.1881
Step 6749	dumb batch loss = 0.1313; conv batch loss = 0.1508
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1449; conv batch loss = 0.1669
Step 8999	dumb batch loss = 0.0804; conv batch loss = 0.1178
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0940; conv batch loss = 0.1072
Step 11249	dumb batch loss = 0.1312; conv batch loss = 0.1497
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0938; conv batch loss = 0.1162
Step 13499	dumb batch loss = 0.0990; conv batch loss = 0.1067
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0747; conv batch loss = 0.0823
Step 15749	dumb batch loss = 0.0844; conv batch loss = 0.0942
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.1007; conv batch loss = 0.1029
Step 17999	dumb batch loss = 0.0651; conv batch loss = 0.0962
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0583; conv batch loss = 0.0998
Step 20249	dumb batch loss = 0.0660; conv batch loss = 0.0538
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0687; conv batch loss = 0.1131
Step 22499	dumb batch loss = 0.0927; conv batch loss = 0.0722
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1153; conv batch loss = 0.0919
Step 24749	dumb batch loss = 0.1116; conv batch loss = 0.0864
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0845; conv batch loss = 0.0929
Step 26999	dumb batch loss = 0.0753; conv batch loss = 0.1047
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0635; conv batch loss = 0.0801
Step 29249	dumb batch loss = 0.0471; conv batch loss = 0.0712
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0840; conv batch loss = 0.0711
Step 31499	dumb batch loss = 0.0874; conv batch loss = 0.0930
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0907; conv batch loss = 0.0953
Step 33749	dumb batch loss = 0.0834; conv batch loss = 0.1176
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0823; conv batch loss = 0.0799
Step 35999	dumb batch loss = 0.0760; conv batch loss = 0.0560
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0751; conv batch loss = 0.0787
Step 38249	dumb batch loss = 0.0526; conv batch loss = 0.0468
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0887; conv batch loss = 0.0795
Step 40499	dumb batch loss = 0.0468; conv batch loss = 0.0538
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0526; conv batch loss = 0.0679
Step 42749	dumb batch loss = 0.0717; conv batch loss = 0.0647
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0644; conv batch loss = 0.0590
Step 44999	dumb batch loss = 0.0736; conv batch loss = 0.0714
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0653; conv batch loss = 0.0647
Step 47249	dumb batch loss = 0.0860; conv batch loss = 0.1010
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0608; conv batch loss = 0.0593
Step 49499	dumb batch loss = 0.0915; conv batch loss = 0.0865
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/25/final.ckpt
Minimum dumb loss: (40499, 0.046751257)
Minimum conv loss: (38249, 0.046847437)
Dumb model prediction:
[[-0.  -0.  -0.   0.  -0.   0.   0.  -0.  -0.  -0. ]
 [ 1.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.   0.  -0.   0.   0.  -0.  -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.   0.  -0.  -0.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.   0.   0.  -0.  -0.   0.1]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.   0. ]
 [-0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0. ]]
Conv model prediction:
[[-0. -0. -0. -0. -0. -0. -0. -0. -0.  0.]
 [ 1. -0. -0. -0. -0. -0. -0.  0. -0. -0.]
 [ 1.  1. -0.  0.  0. -0. -0.  0. -0.  0.]
 [-0. -0. -0. -0. -0. -0. -0. -0. -0.  0.]
 [-0. -0. -0. -0. -0.  0.  0. -0. -0.  1.]
 [-0. -0. -0. -0.  1. -0. -0. -0. -0.  0.]
 [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]
 [-0. -0. -0. -0. -0. -0.  1. -0. -0. -0.]
 [-0. -0. -0. -0. -0. -0.  0.  1. -0. -0.]
 [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]]
2018-04-29 07:23:47.763289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:23:47.763593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.63GiB
2018-04-29 07:23:47.763613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:23:47.975141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:23:47.975176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:23:47.975183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:23:47.975379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7290 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '26',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 8.6200; conv batch loss = 11.5093
Saved checkpoint 1
Step 1124	dumb batch loss = 0.8201; conv batch loss = 0.7994
Step 2249	dumb batch loss = 0.5017; conv batch loss = 0.5136
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2652; conv batch loss = 0.4260
Step 4499	dumb batch loss = 0.2482; conv batch loss = 0.3376
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1898; conv batch loss = 0.2031
Step 6749	dumb batch loss = 0.1384; conv batch loss = 0.2049
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1784; conv batch loss = 0.1827
Step 8999	dumb batch loss = 0.0972; conv batch loss = 0.1830
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.1097; conv batch loss = 0.1351
Step 11249	dumb batch loss = 0.1401; conv batch loss = 0.1592
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1002; conv batch loss = 0.1459
Step 13499	dumb batch loss = 0.1214; conv batch loss = 0.1457
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0822; conv batch loss = 0.1125
Step 15749	dumb batch loss = 0.0706; conv batch loss = 0.1138
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0894; conv batch loss = 0.1319
Step 17999	dumb batch loss = 0.0828; conv batch loss = 0.1234
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.1013; conv batch loss = 0.1202
Step 20249	dumb batch loss = 0.0707; conv batch loss = 0.0593
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0955; conv batch loss = 0.0957
Step 22499	dumb batch loss = 0.0964; conv batch loss = 0.1084
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1020; conv batch loss = 0.1055
Step 24749	dumb batch loss = 0.0735; conv batch loss = 0.1012
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0779; conv batch loss = 0.0901
Step 26999	dumb batch loss = 0.0705; conv batch loss = 0.0898
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0742; conv batch loss = 0.0915
Step 29249	dumb batch loss = 0.0662; conv batch loss = 0.0739
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0598; conv batch loss = 0.0763
Step 31499	dumb batch loss = 0.0939; conv batch loss = 0.0951
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0914; conv batch loss = 0.1300
Step 33749	dumb batch loss = 0.0936; conv batch loss = 0.1000
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0681; conv batch loss = 0.0871
Step 35999	dumb batch loss = 0.0779; conv batch loss = 0.0877
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0872; conv batch loss = 0.0809
Step 38249	dumb batch loss = 0.0459; conv batch loss = 0.0731
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.1045; conv batch loss = 0.0892
Step 40499	dumb batch loss = 0.0479; conv batch loss = 0.0741
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0643; conv batch loss = 0.0843
Step 42749	dumb batch loss = 0.0592; conv batch loss = 0.0584
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0560; conv batch loss = 0.0777
Step 44999	dumb batch loss = 0.0913; conv batch loss = 0.0916
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0880; conv batch loss = 0.0709
Step 47249	dumb batch loss = 0.1164; conv batch loss = 0.1026
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0901; conv batch loss = 0.0777
Step 49499	dumb batch loss = 0.1079; conv batch loss = 0.0940
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/26/final.ckpt
Minimum dumb loss: (38249, 0.045854762)
Minimum conv loss: (42749, 0.058394924)
Dumb model prediction:
[[-0.  -0.  -0.  -0.   0.   0.  -0.   0.  -0.  -0. ]
 [ 1.  -0.  -0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.  -0.  -0.2  0.   0.   0.   0.  -0.   0. ]
 [-0.  -0.  -0.  -0.   0.   0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.   0.   0.   0.   0.  -0.   0.2]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.   0.2]
 [-0.  -0.  -0.  -0.   0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.  -0.   0.   0.   1.  -0.  -0.  -0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]
Conv model prediction:
[[-0.   0.   0.   0.   0.   0.   0.  -0.  -0.  -0. ]
 [ 1.  -0.  -0.  -0.1 -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.   0.   0.   0.  -0.  -0.   0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.   0.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.   0.   0.  -0.   0.   0.   0.9]
 [-0.  -0.  -0.   0.   1.   0.  -0.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.   0.  -0.   0.   0.   0.   1.  -0.   0.   0. ]
 [-0.  -0.  -0.   0.   0.  -0.  -0.   1.  -0.   0. ]
 [-0.  -0.  -0.   0.  -0.   0.   0.  -0.   0.   0. ]]
2018-04-29 07:29:36.874251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:29:36.874540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.83GiB
2018-04-29 07:29:36.874556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:29:37.080990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:29:37.081026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:29:37.081034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:29:37.081234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7561 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '27',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 4.4272; conv batch loss = 10.2843
Saved checkpoint 1
Step 1124	dumb batch loss = 0.6376; conv batch loss = 0.8134
Step 2249	dumb batch loss = 0.2811; conv batch loss = 0.5018
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2162; conv batch loss = 0.3364
Step 4499	dumb batch loss = 0.1963; conv batch loss = 0.2476
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1194; conv batch loss = 0.1751
Step 6749	dumb batch loss = 0.1405; conv batch loss = 0.1701
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1517; conv batch loss = 0.1598
Step 8999	dumb batch loss = 0.1230; conv batch loss = 0.0999
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0971; conv batch loss = 0.0992
Step 11249	dumb batch loss = 0.1233; conv batch loss = 0.1384
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1303; conv batch loss = 0.1281
Step 13499	dumb batch loss = 0.1142; conv batch loss = 0.1163
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.1101; conv batch loss = 0.0745
Step 15749	dumb batch loss = 0.0660; conv batch loss = 0.0825
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0920; conv batch loss = 0.0764
Step 17999	dumb batch loss = 0.0799; conv batch loss = 0.1015
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0663; conv batch loss = 0.0774
Step 20249	dumb batch loss = 0.0465; conv batch loss = 0.0570
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0811; conv batch loss = 0.0735
Step 22499	dumb batch loss = 0.0952; conv batch loss = 0.0709
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1376; conv batch loss = 0.1332
Step 24749	dumb batch loss = 0.1037; conv batch loss = 0.0745
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.1009; conv batch loss = 0.0565
Step 26999	dumb batch loss = 0.1276; conv batch loss = 0.0953
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.1091; conv batch loss = 0.0747
Step 29249	dumb batch loss = 0.0685; conv batch loss = 0.0518
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0657; conv batch loss = 0.0800
Step 31499	dumb batch loss = 0.1131; conv batch loss = 0.0845
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0804; conv batch loss = 0.0956
Step 33749	dumb batch loss = 0.0767; conv batch loss = 0.0609
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0589; conv batch loss = 0.0666
Step 35999	dumb batch loss = 0.0690; conv batch loss = 0.0821
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0835; conv batch loss = 0.0738
Step 38249	dumb batch loss = 0.0583; conv batch loss = 0.0399
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0993; conv batch loss = 0.0827
Step 40499	dumb batch loss = 0.0481; conv batch loss = 0.0521
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0572; conv batch loss = 0.0585
Step 42749	dumb batch loss = 0.0636; conv batch loss = 0.0585
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0615; conv batch loss = 0.0633
Step 44999	dumb batch loss = 0.0724; conv batch loss = 0.0615
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0796; conv batch loss = 0.0687
Step 47249	dumb batch loss = 0.0828; conv batch loss = 0.0888
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0846; conv batch loss = 0.0568
Step 49499	dumb batch loss = 0.1087; conv batch loss = 0.0942
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/27/final.ckpt
Minimum dumb loss: (20249, 0.046507698)
Minimum conv loss: (38249, 0.039876398)
Dumb model prediction:
[[-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.3]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
Conv model prediction:
[[ 0.   0.  -0.   0.1  0.   0.   0.  -0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.  -0.   0.1  0.   0.  -0.  -0.   0.   0. ]
 [ 0.  -0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.  -0.   0.   0.  -0.   0.   0.  -0.   0.  -0.2]
 [ 0.   0.  -0.   0.   1.   0.   0.   0.   0.   0. ]
 [ 0.   0.  -0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.  -0.   0.   0.  -0.   0.   1.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]
2018-04-29 07:35:27.964258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:35:27.964649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.74GiB
2018-04-29 07:35:27.964667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:35:28.217263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:35:28.217302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:35:28.217310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:35:28.217512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7326 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '28',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 13.0593; conv batch loss = 8.5634
Saved checkpoint 1
Step 1124	dumb batch loss = 0.8022; conv batch loss = 0.7324
Step 2249	dumb batch loss = 0.4820; conv batch loss = 0.3789
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.3335; conv batch loss = 0.3208
Step 4499	dumb batch loss = 0.2455; conv batch loss = 0.2302
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.2148; conv batch loss = 0.1737
Step 6749	dumb batch loss = 0.1442; conv batch loss = 0.1471
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1813; conv batch loss = 0.1580
Step 8999	dumb batch loss = 0.1357; conv batch loss = 0.0823
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.1014; conv batch loss = 0.0769
Step 11249	dumb batch loss = 0.1397; conv batch loss = 0.1195
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1025; conv batch loss = 0.0981
Step 13499	dumb batch loss = 0.1348; conv batch loss = 0.0835
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0883; conv batch loss = 0.0721
Step 15749	dumb batch loss = 0.0729; conv batch loss = 0.0583
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0859; conv batch loss = 0.0884
Step 17999	dumb batch loss = 0.0984; conv batch loss = 0.0837
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0851; conv batch loss = 0.0748
Step 20249	dumb batch loss = 0.0687; conv batch loss = 0.0485
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0727; conv batch loss = 0.0869
Step 22499	dumb batch loss = 0.0905; conv batch loss = 0.0733
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1248; conv batch loss = 0.1070
Step 24749	dumb batch loss = 0.1152; conv batch loss = 0.0732
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0998; conv batch loss = 0.0855
Step 26999	dumb batch loss = 0.1200; conv batch loss = 0.1067
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0636; conv batch loss = 0.0792
Step 29249	dumb batch loss = 0.0659; conv batch loss = 0.0532
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0549; conv batch loss = 0.0630
Step 31499	dumb batch loss = 0.1028; conv batch loss = 0.0653
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0816; conv batch loss = 0.0861
Step 33749	dumb batch loss = 0.0864; conv batch loss = 0.0742
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0915; conv batch loss = 0.0564
Step 35999	dumb batch loss = 0.0793; conv batch loss = 0.0676
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0566; conv batch loss = 0.0480
Step 38249	dumb batch loss = 0.0464; conv batch loss = 0.0436
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0804; conv batch loss = 0.0820
Step 40499	dumb batch loss = 0.0557; conv batch loss = 0.0439
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0715; conv batch loss = 0.0605
Step 42749	dumb batch loss = 0.0665; conv batch loss = 0.0518
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0670; conv batch loss = 0.0414
Step 44999	dumb batch loss = 0.0823; conv batch loss = 0.0713
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0753; conv batch loss = 0.0654
Step 47249	dumb batch loss = 0.0780; conv batch loss = 0.0733
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0953; conv batch loss = 0.0620
Step 49499	dumb batch loss = 0.0976; conv batch loss = 0.0691
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/28/final.ckpt
Minimum dumb loss: (38249, 0.04643138)
Minimum conv loss: (43874, 0.041394822)
Dumb model prediction:
[[-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.   0.1 -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.8]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.1 -0.   0.  -0.   1.  -0.  -0. ]
 [-0.   0.   0.  -0.  -0.   0.  -0.  -0.  -0.  -0. ]]
Conv model prediction:
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
2018-04-29 07:41:17.028839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:41:17.029141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.73GiB
2018-04-29 07:41:17.029157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:41:17.236361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:41:17.236394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:41:17.236402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:41:17.236594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7426 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '29',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 9.9356; conv batch loss = 7.7561
Saved checkpoint 1
Step 1124	dumb batch loss = 0.8033; conv batch loss = 0.7151
Step 2249	dumb batch loss = 0.4123; conv batch loss = 0.2661
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2721; conv batch loss = 0.1996
Step 4499	dumb batch loss = 0.2249; conv batch loss = 0.1687
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1386; conv batch loss = 0.1091
Step 6749	dumb batch loss = 0.1502; conv batch loss = 0.1349
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1633; conv batch loss = 0.1237
Step 8999	dumb batch loss = 0.1064; conv batch loss = 0.0798
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0932; conv batch loss = 0.0623
Step 11249	dumb batch loss = 0.1237; conv batch loss = 0.1537
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1137; conv batch loss = 0.1007
Step 13499	dumb batch loss = 0.1176; conv batch loss = 0.1170
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0914; conv batch loss = 0.0884
Step 15749	dumb batch loss = 0.0819; conv batch loss = 0.0716
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0758; conv batch loss = 0.0943
Step 17999	dumb batch loss = 0.0919; conv batch loss = 0.0769
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0977; conv batch loss = 0.0833
Step 20249	dumb batch loss = 0.0794; conv batch loss = 0.0528
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0756; conv batch loss = 0.0819
Step 22499	dumb batch loss = 0.0697; conv batch loss = 0.0675
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1009; conv batch loss = 0.0947
Step 24749	dumb batch loss = 0.0849; conv batch loss = 0.0710
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0816; conv batch loss = 0.0844
Step 26999	dumb batch loss = 0.0931; conv batch loss = 0.0852
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0814; conv batch loss = 0.0837
Step 29249	dumb batch loss = 0.0571; conv batch loss = 0.0576
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0811; conv batch loss = 0.0573
Step 31499	dumb batch loss = 0.0912; conv batch loss = 0.0668
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0807; conv batch loss = 0.0705
Step 33749	dumb batch loss = 0.0761; conv batch loss = 0.0744
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0762; conv batch loss = 0.0508
Step 35999	dumb batch loss = 0.0786; conv batch loss = 0.0647
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0646; conv batch loss = 0.0573
Step 38249	dumb batch loss = 0.0427; conv batch loss = 0.0217
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0775; conv batch loss = 0.0877
Step 40499	dumb batch loss = 0.0510; conv batch loss = 0.0431
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0652; conv batch loss = 0.0646
Step 42749	dumb batch loss = 0.0558; conv batch loss = 0.0689
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0623; conv batch loss = 0.0559
Step 44999	dumb batch loss = 0.0642; conv batch loss = 0.0652
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0623; conv batch loss = 0.0558
Step 47249	dumb batch loss = 0.0680; conv batch loss = 0.0857
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0816; conv batch loss = 0.0723
Step 49499	dumb batch loss = 0.0849; conv batch loss = 0.0673
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/29/final.ckpt
Minimum dumb loss: (38249, 0.04270771)
Minimum conv loss: (38249, 0.021655025)
Dumb model prediction:
[[ 0.  -0.  -0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   0.  -0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.   0.  -0.   0.   0.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.   0.   0.   0.   0.   0.   0.6]
 [-0.  -0.  -0.   0.   1.   0.   0.   0.  -0.   0. ]
 [ 0.  -0.  -0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.  -0.  -0.   0.   0.   0.   1.   0.   0.   0. ]
 [ 0.  -0.  -0.   0.   0.   0.   0.   1.   0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.   0.  -0.  -0.   0. ]]
Conv model prediction:
[[-0.  -0.  -0.   0.  -0.  -0.   0.  -0.  -0.   0. ]
 [ 1.   0.  -0.   0.  -0.  -0.  -0.   0.   0.   0. ]
 [ 1.   1.  -0.   0.1 -0.  -0.   0.  -0.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.5]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.   0.  -0.  -0.   0.   1.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
2018-04-29 07:47:06.145421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:47:06.145712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.80GiB
2018-04-29 07:47:06.145733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:47:06.346036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:47:06.346080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:47:06.346088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:47:06.346285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7445 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '30',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 11.1652; conv batch loss = 10.9355
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7939; conv batch loss = 0.8456
Step 2249	dumb batch loss = 0.3976; conv batch loss = 0.5582
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2721; conv batch loss = 0.3620
Step 4499	dumb batch loss = 0.2429; conv batch loss = 0.2907
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1745; conv batch loss = 0.2046
Step 6749	dumb batch loss = 0.1492; conv batch loss = 0.1822
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1828; conv batch loss = 0.2029
Step 8999	dumb batch loss = 0.1352; conv batch loss = 0.1191
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.1120; conv batch loss = 0.1158
Step 11249	dumb batch loss = 0.1300; conv batch loss = 0.1727
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1131; conv batch loss = 0.1153
Step 13499	dumb batch loss = 0.1297; conv batch loss = 0.1076
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.1005; conv batch loss = 0.0821
Step 15749	dumb batch loss = 0.0809; conv batch loss = 0.0930
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0919; conv batch loss = 0.0878
Step 17999	dumb batch loss = 0.1125; conv batch loss = 0.1094
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0924; conv batch loss = 0.0901
Step 20249	dumb batch loss = 0.0646; conv batch loss = 0.0619
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0812; conv batch loss = 0.1049
Step 22499	dumb batch loss = 0.1034; conv batch loss = 0.0839
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1206; conv batch loss = 0.1241
Step 24749	dumb batch loss = 0.1044; conv batch loss = 0.0779
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0940; conv batch loss = 0.0825
Step 26999	dumb batch loss = 0.0800; conv batch loss = 0.0964
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0861; conv batch loss = 0.0704
Step 29249	dumb batch loss = 0.0528; conv batch loss = 0.0745
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0763; conv batch loss = 0.0879
Step 31499	dumb batch loss = 0.0804; conv batch loss = 0.0851
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0909; conv batch loss = 0.0842
Step 33749	dumb batch loss = 0.0725; conv batch loss = 0.0842
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0825; conv batch loss = 0.0799
Step 35999	dumb batch loss = 0.0737; conv batch loss = 0.0877
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0753; conv batch loss = 0.0587
Step 38249	dumb batch loss = 0.0622; conv batch loss = 0.0904
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.1035; conv batch loss = 0.1195
Step 40499	dumb batch loss = 0.0522; conv batch loss = 0.0511
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0632; conv batch loss = 0.0906
Step 42749	dumb batch loss = 0.0642; conv batch loss = 0.0947
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0748; conv batch loss = 0.0799
Step 44999	dumb batch loss = 0.0707; conv batch loss = 0.1007
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0827; conv batch loss = 0.0910
Step 47249	dumb batch loss = 0.0870; conv batch loss = 0.1123
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0690; conv batch loss = 0.1122
Step 49499	dumb batch loss = 0.0773; conv batch loss = 0.1129
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/30/final.ckpt
Minimum dumb loss: (40499, 0.05223887)
Minimum conv loss: (40499, 0.051148266)
Dumb model prediction:
[[ 0.   0.   0.  -0.  -0.   0.  -0.  -0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.   0.  -0.   0.  -0. ]
 [ 1.   1.   0.  -0.   0.   0.   0.  -0.   0.   0. ]
 [ 0.   0.   0.  -0.  -0.   0.   0.  -0.   0.  -0. ]
 [ 0.   0.   0.   0.  -0.   0.   0.   0.   0.   0.4]
 [ 0.   0.   0.  -0.   1.   0.   0.  -0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.   0.   0. ]
 [-0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]
Conv model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   0.   0.   0.1  0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.  -0.   0.  -0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  -0.2]
 [ 0.   0.   0.   0.   1.   0.   0.   0.   0.   0.1]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]
2018-04-29 07:52:55.835964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:52:55.836501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.74GiB
2018-04-29 07:52:55.836522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:52:56.043786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:52:56.043815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:52:56.043823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:52:56.044093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7427 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '31',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 17.5206; conv batch loss = 7.3270
Saved checkpoint 1
Step 1124	dumb batch loss = 0.8104; conv batch loss = 0.7774
Step 2249	dumb batch loss = 0.6016; conv batch loss = 0.4154
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.3511; conv batch loss = 0.2850
Step 4499	dumb batch loss = 0.2620; conv batch loss = 0.2878
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1733; conv batch loss = 0.1770
Step 6749	dumb batch loss = 0.1620; conv batch loss = 0.1840
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.2012; conv batch loss = 0.1852
Step 8999	dumb batch loss = 0.1147; conv batch loss = 0.1257
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0966; conv batch loss = 0.0978
Step 11249	dumb batch loss = 0.1379; conv batch loss = 0.1762
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1073; conv batch loss = 0.1183
Step 13499	dumb batch loss = 0.1417; conv batch loss = 0.1236
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0792; conv batch loss = 0.0885
Step 15749	dumb batch loss = 0.0674; conv batch loss = 0.0866
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.1067; conv batch loss = 0.0918
Step 17999	dumb batch loss = 0.1066; conv batch loss = 0.0993
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0838; conv batch loss = 0.1045
Step 20249	dumb batch loss = 0.0786; conv batch loss = 0.0740
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0922; conv batch loss = 0.1003
Step 22499	dumb batch loss = 0.0902; conv batch loss = 0.1029
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1084; conv batch loss = 0.1207
Step 24749	dumb batch loss = 0.1097; conv batch loss = 0.1124
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0846; conv batch loss = 0.0923
Step 26999	dumb batch loss = 0.0831; conv batch loss = 0.1048
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0611; conv batch loss = 0.1210
Step 29249	dumb batch loss = 0.0693; conv batch loss = 0.0636
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0675; conv batch loss = 0.0816
Step 31499	dumb batch loss = 0.0935; conv batch loss = 0.1064
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0683; conv batch loss = 0.0919
Step 33749	dumb batch loss = 0.0865; conv batch loss = 0.0921
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0596; conv batch loss = 0.0766
Step 35999	dumb batch loss = 0.0778; conv batch loss = 0.0712
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0677; conv batch loss = 0.0576
Step 38249	dumb batch loss = 0.0635; conv batch loss = 0.0434
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0847; conv batch loss = 0.1366
Step 40499	dumb batch loss = 0.0522; conv batch loss = 0.0631
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0763; conv batch loss = 0.0799
Step 42749	dumb batch loss = 0.0731; conv batch loss = 0.0819
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0723; conv batch loss = 0.0642
Step 44999	dumb batch loss = 0.0610; conv batch loss = 0.0832
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.1129; conv batch loss = 0.0849
Step 47249	dumb batch loss = 0.0825; conv batch loss = 0.0919
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0647; conv batch loss = 0.0676
Step 49499	dumb batch loss = 0.1270; conv batch loss = 0.1347
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/31/final.ckpt
Minimum dumb loss: (40499, 0.052211147)
Minimum conv loss: (38249, 0.043379705)
Dumb model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.  -0.   0.   0.   0.   0.   0.  -0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.7]
 [ 0.   0.   0.   0.   1.   0.   0.   0.   0.   0.2]
 [ 0.  -0.   0.   0.   0.   0.   0.  -0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.  -0.   0.   0.   0.   0.   0.  -0.   0.   0. ]]
Conv model prediction:
[[ 0.   0.   0.  -0.   0.   0.  -0.  -0.   0.  -0. ]
 [ 1.   0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.   0.1 -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.   0.  -0.  -0.  -0.  -0.   0.7]
 [ 0.   0.  -0.  -0.   1.   0.  -0.  -0.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.  -0.  -0.  -0.   0.   0.   0.9  0.  -0.  -0. ]
 [-0.   0.   0.  -0.   0.  -0.  -0.   1.   0.  -0. ]
 [-0.  -0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0. ]]
2018-04-29 07:58:44.209873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:58:44.210249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.74GiB
2018-04-29 07:58:44.210266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:58:44.416973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:58:44.417010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:58:44.417018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:58:44.417214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7427 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '32',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 13.7643; conv batch loss = 12.8395
Saved checkpoint 1
Step 1124	dumb batch loss = 0.8125; conv batch loss = 0.8226
Step 2249	dumb batch loss = 0.5070; conv batch loss = 0.4609
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.3139; conv batch loss = 0.3767
Step 4499	dumb batch loss = 0.2593; conv batch loss = 0.2743
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1578; conv batch loss = 0.1315
Step 6749	dumb batch loss = 0.1458; conv batch loss = 0.1299
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1788; conv batch loss = 0.1530
Step 8999	dumb batch loss = 0.1127; conv batch loss = 0.0912
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0777; conv batch loss = 0.0817
Step 11249	dumb batch loss = 0.1107; conv batch loss = 0.1353
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0994; conv batch loss = 0.0866
Step 13499	dumb batch loss = 0.1266; conv batch loss = 0.0945
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0735; conv batch loss = 0.0579
Step 15749	dumb batch loss = 0.0625; conv batch loss = 0.0731
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0853; conv batch loss = 0.0959
Step 17999	dumb batch loss = 0.0677; conv batch loss = 0.0766
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0892; conv batch loss = 0.0672
Step 20249	dumb batch loss = 0.0447; conv batch loss = 0.0406
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0751; conv batch loss = 0.0598
Step 22499	dumb batch loss = 0.0723; conv batch loss = 0.0703
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0876; conv batch loss = 0.1080
Step 24749	dumb batch loss = 0.0941; conv batch loss = 0.0969
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0692; conv batch loss = 0.0737
Step 26999	dumb batch loss = 0.0705; conv batch loss = 0.0981
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0953; conv batch loss = 0.0670
Step 29249	dumb batch loss = 0.0649; conv batch loss = 0.0533
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0609; conv batch loss = 0.0614
Step 31499	dumb batch loss = 0.0842; conv batch loss = 0.0753
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0787; conv batch loss = 0.0891
Step 33749	dumb batch loss = 0.0664; conv batch loss = 0.0974
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0602; conv batch loss = 0.0655
Step 35999	dumb batch loss = 0.0489; conv batch loss = 0.0407
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0608; conv batch loss = 0.0661
Step 38249	dumb batch loss = 0.0365; conv batch loss = 0.0468
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0725; conv batch loss = 0.0598
Step 40499	dumb batch loss = 0.0533; conv batch loss = 0.0410
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0530; conv batch loss = 0.0499
Step 42749	dumb batch loss = 0.0619; conv batch loss = 0.0477
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0678; conv batch loss = 0.0679
Step 44999	dumb batch loss = 0.0726; conv batch loss = 0.0731
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0768; conv batch loss = 0.0590
Step 47249	dumb batch loss = 0.0796; conv batch loss = 0.0816
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0695; conv batch loss = 0.0717
Step 49499	dumb batch loss = 0.0868; conv batch loss = 0.0803
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/32/final.ckpt
Minimum dumb loss: (38249, 0.036487043)
Minimum conv loss: (20249, 0.04055362)
Dumb model prediction:
[[-0. -0. -0.  0. -0. -0.  0. -0. -0.  0.]
 [ 1. -0. -0. -0. -0. -0.  0.  0. -0.  0.]
 [ 1.  1. -0.  0.  0. -0.  0.  0. -0.  0.]
 [-0. -0. -0.  0. -0. -0. -0. -0. -0.  0.]
 [-0. -0. -0.  0. -0. -0. -0. -0. -0.  0.]
 [-0. -0. -0.  0.  1. -0.  0. -0. -0.  0.]
 [ 0. -0. -0.  0. -0. -0. -0. -0. -0.  0.]
 [ 0. -0. -0.  0. -0. -0.  1.  0. -0.  0.]
 [ 0. -0. -0.  0. -0. -0.  0.  1. -0.  0.]
 [-0. -0. -0.  0. -0. -0. -0. -0. -0.  0.]]
Conv model prediction:
[[ 0.1  0.   0.   0.   0.   0.   0.   0.1  0.  -0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.1  0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.1  0.   0.   0.1  0.   0.5]
 [ 0.   0.   0.   0.   1.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.   0. ]
 [ 0.1  0.1  0.   0.   0.   0.   1.   0.1  0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]
2018-04-29 08:04:34.089170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:04:34.089463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.71GiB
2018-04-29 08:04:34.089479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:04:34.335825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:04:34.335863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:04:34.335871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:04:34.336066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7314 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '33',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 5.2252; conv batch loss = 7.0255
Saved checkpoint 1
Step 1124	dumb batch loss = 0.6624; conv batch loss = 0.8268
Step 2249	dumb batch loss = 0.1956; conv batch loss = 0.5374
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.1665; conv batch loss = 0.3637
Step 4499	dumb batch loss = 0.1442; conv batch loss = 0.2282
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1174; conv batch loss = 0.1649
Step 6749	dumb batch loss = 0.1159; conv batch loss = 0.1256
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1372; conv batch loss = 0.1563
Step 8999	dumb batch loss = 0.0767; conv batch loss = 0.0814
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0792; conv batch loss = 0.0747
Step 11249	dumb batch loss = 0.1093; conv batch loss = 0.1467
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0975; conv batch loss = 0.1038
Step 13499	dumb batch loss = 0.0983; conv batch loss = 0.0862
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0831; conv batch loss = 0.0580
Step 15749	dumb batch loss = 0.0739; conv batch loss = 0.0707
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0977; conv batch loss = 0.0775
Step 17999	dumb batch loss = 0.0845; conv batch loss = 0.0760
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0796; conv batch loss = 0.0743
Step 20249	dumb batch loss = 0.0377; conv batch loss = 0.0578
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0656; conv batch loss = 0.0677
Step 22499	dumb batch loss = 0.0694; conv batch loss = 0.0563
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0810; conv batch loss = 0.1011
Step 24749	dumb batch loss = 0.0757; conv batch loss = 0.0710
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0714; conv batch loss = 0.0577
Step 26999	dumb batch loss = 0.1096; conv batch loss = 0.0715
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0779; conv batch loss = 0.0798
Step 29249	dumb batch loss = 0.0394; conv batch loss = 0.0491
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0536; conv batch loss = 0.0617
Step 31499	dumb batch loss = 0.0794; conv batch loss = 0.0774
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0737; conv batch loss = 0.0826
Step 33749	dumb batch loss = 0.0886; conv batch loss = 0.0875
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.1026; conv batch loss = 0.0597
Step 35999	dumb batch loss = 0.0610; conv batch loss = 0.0521
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0604; conv batch loss = 0.0587
Step 38249	dumb batch loss = 0.0414; conv batch loss = 0.0319
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0862; conv batch loss = 0.0696
Step 40499	dumb batch loss = 0.0610; conv batch loss = 0.0359
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0721; conv batch loss = 0.0704
Step 42749	dumb batch loss = 0.0532; conv batch loss = 0.0599
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0728; conv batch loss = 0.0565
Step 44999	dumb batch loss = 0.0862; conv batch loss = 0.0536
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0871; conv batch loss = 0.0691
Step 47249	dumb batch loss = 0.1077; conv batch loss = 0.0763
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0712; conv batch loss = 0.0623
Step 49499	dumb batch loss = 0.1058; conv batch loss = 0.0865
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/33/final.ckpt
Minimum dumb loss: (20249, 0.0377228)
Minimum conv loss: (38249, 0.031864855)
Dumb model prediction:
[[-0.  -0.  -0.  -0.  -0.   0.  -0.  -0.   0.  -0. ]
 [ 1.   0.   0.  -0.  -0.   0.  -0.   0.   0.  -0. ]
 [ 1.   1.   0.   0.3  0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0.1]
 [ 0.  -0.  -0.  -0.   1.   0.  -0.  -0.   0.   0.1]
 [-0.  -0.   0.  -0.  -0.   0.   0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.   0. ]
 [ 0.  -0.   0.  -0.  -0.  -0.  -0.   1.   0.   0. ]
 [ 0.  -0.   0.  -0.  -0.   0.  -0.  -0.   0.  -0. ]]
Conv model prediction:
[[ 0.   0.   0.   0.  -0.  -0.  -0.  -0.   0.  -0. ]
 [ 1.   0.   0.   0.   0.  -0.  -0.   0.   0.  -0. ]
 [ 1.   1.   0.   0.  -0.  -0.  -0.   0.   0.  -0. ]
 [ 0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0.   0.9]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.   0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.   0.   0.  -0.   0.  -0.   1.  -0.   0.  -0. ]
 [ 0.  -0.   0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [-0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.  -0. ]]
2018-04-29 08:10:25.128331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:10:25.128640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.45GiB
2018-04-29 08:10:25.128656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:10:25.397232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:10:25.397278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:10:25.397297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:10:25.397530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7198 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '34',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 10.1828; conv batch loss = 16.8006
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7827; conv batch loss = 0.7852
Step 2249	dumb batch loss = 0.3971; conv batch loss = 0.3638
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2813; conv batch loss = 0.2862
Step 4499	dumb batch loss = 0.1901; conv batch loss = 0.2360
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1501; conv batch loss = 0.1481
Step 6749	dumb batch loss = 0.1327; conv batch loss = 0.1686
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1428; conv batch loss = 0.1323
Step 8999	dumb batch loss = 0.0922; conv batch loss = 0.1036
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0925; conv batch loss = 0.0941
Step 11249	dumb batch loss = 0.1159; conv batch loss = 0.1188
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0805; conv batch loss = 0.1094
Step 13499	dumb batch loss = 0.1089; conv batch loss = 0.1119
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0730; conv batch loss = 0.0780
Step 15749	dumb batch loss = 0.0772; conv batch loss = 0.0794
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0987; conv batch loss = 0.0965
Step 17999	dumb batch loss = 0.0804; conv batch loss = 0.0958
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0903; conv batch loss = 0.0974
Step 20249	dumb batch loss = 0.0459; conv batch loss = 0.0504
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0732; conv batch loss = 0.0895
Step 22499	dumb batch loss = 0.0882; conv batch loss = 0.0663
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1058; conv batch loss = 0.0971
Step 24749	dumb batch loss = 0.0796; conv batch loss = 0.0811
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0537; conv batch loss = 0.0706
Step 26999	dumb batch loss = 0.0887; conv batch loss = 0.0950
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0716; conv batch loss = 0.0784
Step 29249	dumb batch loss = 0.0635; conv batch loss = 0.0691
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0521; conv batch loss = 0.0808
Step 31499	dumb batch loss = 0.0928; conv batch loss = 0.0713
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0683; conv batch loss = 0.0827
Step 33749	dumb batch loss = 0.0890; conv batch loss = 0.0692
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0746; conv batch loss = 0.0633
Step 35999	dumb batch loss = 0.0671; conv batch loss = 0.0688
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0651; conv batch loss = 0.0576
Step 38249	dumb batch loss = 0.0553; conv batch loss = 0.0377
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0937; conv batch loss = 0.0969
Step 40499	dumb batch loss = 0.0639; conv batch loss = 0.0437
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0726; conv batch loss = 0.0735
Step 42749	dumb batch loss = 0.0618; conv batch loss = 0.0588
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0794; conv batch loss = 0.0542
Step 44999	dumb batch loss = 0.0743; conv batch loss = 0.0774
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0699; conv batch loss = 0.0629
Step 47249	dumb batch loss = 0.0914; conv batch loss = 0.0700
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0859; conv batch loss = 0.0641
Step 49499	dumb batch loss = 0.1165; conv batch loss = 0.0894
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/34/final.ckpt
Minimum dumb loss: (20249, 0.045850545)
Minimum conv loss: (38249, 0.0377401)
Dumb model prediction:
[[-0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.   0.3]
 [ 1.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.  -0. ]
 [ 1.   1.  -0.   0.2 -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0.   0.4]
 [ 0.  -0.   0.  -0.   1.  -0.  -0.  -0.   0.   0. ]
 [-0.   0.   0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.   0.   0.  -0.  -0.  -0.   1.  -0.   0.  -0. ]
 [-0.   0.   0.  -0.  -0.  -0.  -0.   1.   0.  -0. ]
 [ 0.   0.   0.   0.  -0.  -0.  -0.  -0.   0.  -0. ]]
Conv model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.  -0.   0.   0.  -0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0.2]
 [ 0.   0.   0.   0.   1.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]
2018-04-29 08:16:14.746971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:16:14.747503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.74GiB
2018-04-29 08:16:14.747524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:16:14.959924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:16:14.959961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:16:14.959969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:16:14.960172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7426 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '35',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 11.3884; conv batch loss = 11.8465
Saved checkpoint 1
Step 1124	dumb batch loss = 0.8192; conv batch loss = 0.8027
Step 2249	dumb batch loss = 0.4970; conv batch loss = 0.4566
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2918; conv batch loss = 0.3424
Step 4499	dumb batch loss = 0.1998; conv batch loss = 0.2394
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1566; conv batch loss = 0.1683
Step 6749	dumb batch loss = 0.1487; conv batch loss = 0.1398
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.2082; conv batch loss = 0.1486
Step 8999	dumb batch loss = 0.1003; conv batch loss = 0.1018
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.1003; conv batch loss = 0.1118
Step 11249	dumb batch loss = 0.1416; conv batch loss = 0.1166
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0775; conv batch loss = 0.1079
Step 13499	dumb batch loss = 0.1188; conv batch loss = 0.1196
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0674; conv batch loss = 0.0816
Step 15749	dumb batch loss = 0.0590; conv batch loss = 0.0702
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0964; conv batch loss = 0.1051
Step 17999	dumb batch loss = 0.0997; conv batch loss = 0.0921
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0793; conv batch loss = 0.1151
Step 20249	dumb batch loss = 0.0539; conv batch loss = 0.0969
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0536; conv batch loss = 0.0758
Step 22499	dumb batch loss = 0.0959; conv batch loss = 0.0885
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0996; conv batch loss = 0.1086
Step 24749	dumb batch loss = 0.1091; conv batch loss = 0.0750
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0802; conv batch loss = 0.0979
Step 26999	dumb batch loss = 0.0948; conv batch loss = 0.0970
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0873; conv batch loss = 0.0793
Step 29249	dumb batch loss = 0.0668; conv batch loss = 0.0581
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0500; conv batch loss = 0.0665
Step 31499	dumb batch loss = 0.0796; conv batch loss = 0.0996
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0761; conv batch loss = 0.0962
Step 33749	dumb batch loss = 0.0568; conv batch loss = 0.0850
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0666; conv batch loss = 0.0994
Step 35999	dumb batch loss = 0.0540; conv batch loss = 0.0730
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0782; conv batch loss = 0.0725
Step 38249	dumb batch loss = 0.0655; conv batch loss = 0.0477
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0806; conv batch loss = 0.1154
Step 40499	dumb batch loss = 0.0447; conv batch loss = 0.0616
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0605; conv batch loss = 0.0666
Step 42749	dumb batch loss = 0.0619; conv batch loss = 0.0607
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0456; conv batch loss = 0.0738
Step 44999	dumb batch loss = 0.0717; conv batch loss = 0.0677
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0872; conv batch loss = 0.0798
Step 47249	dumb batch loss = 0.0785; conv batch loss = 0.0985
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0686; conv batch loss = 0.0900
Step 49499	dumb batch loss = 0.0899; conv batch loss = 0.0948
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/35/final.ckpt
Minimum dumb loss: (40499, 0.044660505)
Minimum conv loss: (38249, 0.04769521)
Dumb model prediction:
[[-0. -0. -0.  0. -0. -0.  0. -0. -0.  0.]
 [ 1. -0. -0.  0.  0. -0.  0.  0. -0.  0.]
 [ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]
 [-0. -0. -0.  0. -0. -0.  0. -0. -0.  0.]
 [ 0. -0. -0.  0. -0.  0.  0.  0. -0.  0.]
 [ 0. -0. -0.  0.  1.  0.  0.  0. -0.  0.]
 [ 0. -0. -0.  0. -0. -0.  0. -0. -0.  0.]
 [ 0. -0. -0.  0. -0. -0.  1. -0. -0.  0.]
 [ 0. -0. -0.  0. -0. -0.  0.  1. -0.  0.]
 [-0. -0. -0.  0. -0. -0.  0. -0. -0. -0.]]
Conv model prediction:
[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.6]
 [0.  0.  0.  0.  1.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  1.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]
2018-04-29 08:22:03.820844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:22:03.821135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.83GiB
2018-04-29 08:22:03.821151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:22:04.027871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:22:04.027907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:22:04.027915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:22:04.028111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7561 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '36',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 6.9288; conv batch loss = 9.6362
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7109; conv batch loss = 0.7724
Step 2249	dumb batch loss = 0.2612; conv batch loss = 0.4670
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2087; conv batch loss = 0.3022
Step 4499	dumb batch loss = 0.1655; conv batch loss = 0.2173
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1161; conv batch loss = 0.1422
Step 6749	dumb batch loss = 0.1157; conv batch loss = 0.1124
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1553; conv batch loss = 0.1391
Step 8999	dumb batch loss = 0.0899; conv batch loss = 0.0933
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0992; conv batch loss = 0.0821
Step 11249	dumb batch loss = 0.1411; conv batch loss = 0.1084
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0983; conv batch loss = 0.0963
Step 13499	dumb batch loss = 0.0834; conv batch loss = 0.0959
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0686; conv batch loss = 0.0779
Step 15749	dumb batch loss = 0.0913; conv batch loss = 0.0687
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0805; conv batch loss = 0.0643
Step 17999	dumb batch loss = 0.0718; conv batch loss = 0.0739
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0689; conv batch loss = 0.0781
Step 20249	dumb batch loss = 0.0487; conv batch loss = 0.0619
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0798; conv batch loss = 0.0564
Step 22499	dumb batch loss = 0.0916; conv batch loss = 0.0718
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1055; conv batch loss = 0.0791
Step 24749	dumb batch loss = 0.0941; conv batch loss = 0.0709
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0622; conv batch loss = 0.0696
Step 26999	dumb batch loss = 0.0828; conv batch loss = 0.0776
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0547; conv batch loss = 0.0770
Step 29249	dumb batch loss = 0.0700; conv batch loss = 0.0694
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0746; conv batch loss = 0.0532
Step 31499	dumb batch loss = 0.0682; conv batch loss = 0.0852
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0946; conv batch loss = 0.0909
Step 33749	dumb batch loss = 0.0991; conv batch loss = 0.0645
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.1027; conv batch loss = 0.0574
Step 35999	dumb batch loss = 0.0742; conv batch loss = 0.0637
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0623; conv batch loss = 0.0545
Step 38249	dumb batch loss = 0.0594; conv batch loss = 0.0594
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0862; conv batch loss = 0.0766
Step 40499	dumb batch loss = 0.0424; conv batch loss = 0.0464
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0574; conv batch loss = 0.0606
Step 42749	dumb batch loss = 0.0587; conv batch loss = 0.0546
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0531; conv batch loss = 0.0507
Step 44999	dumb batch loss = 0.0823; conv batch loss = 0.0700
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0829; conv batch loss = 0.0455
Step 47249	dumb batch loss = 0.0773; conv batch loss = 0.0879
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0796; conv batch loss = 0.0812
Step 49499	dumb batch loss = 0.0934; conv batch loss = 0.0894
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/36/final.ckpt
Minimum dumb loss: (40499, 0.042446848)
Minimum conv loss: (46124, 0.045455854)
Dumb model prediction:
[[-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [ 1.  -0.  -0.   0.   0.  -0.  -0.  -0.   0.   0. ]
 [ 1.   1.   0.   0.   0.  -0.  -0.   0.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.   0.  -0.   0.   0.3]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.   0.   0.  -0.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   0.   1.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
Conv model prediction:
[[-0.  -0.   0.  -0.  -0.   0.  -0.   0.  -0.  -0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.  -0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [-0.  -0.   0.  -0.  -0.   0.   0.  -0.  -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.   0.   0.  -0.  -0.   0.1]
 [ 0.   0.   0.   0.   1.   0.   0.   0.  -0.  -0. ]
 [-0.  -0.   0.   0.  -0.   0.  -0.   0.  -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.   0.   1.  -0.  -0.  -0. ]
 [ 0.  -0.   0.  -0.   0.   0.   0.   1.   0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.   0.   0.  -0.  -0. ]]
2018-04-29 08:27:52.745635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:27:52.745925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.83GiB
2018-04-29 08:27:52.745941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:27:52.950574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:27:52.950619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:27:52.950627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:27:52.950833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7561 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '37',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 5.7731; conv batch loss = 10.6224
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7435; conv batch loss = 0.7292
Step 2249	dumb batch loss = 0.3092; conv batch loss = 0.4392
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2441; conv batch loss = 0.2945
Step 4499	dumb batch loss = 0.1981; conv batch loss = 0.2709
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1414; conv batch loss = 0.1891
Step 6749	dumb batch loss = 0.1300; conv batch loss = 0.1829
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1574; conv batch loss = 0.1667
Step 8999	dumb batch loss = 0.1041; conv batch loss = 0.0825
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0747; conv batch loss = 0.0917
Step 11249	dumb batch loss = 0.1477; conv batch loss = 0.1216
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1056; conv batch loss = 0.1060
Step 13499	dumb batch loss = 0.1131; conv batch loss = 0.1090
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0885; conv batch loss = 0.0702
Step 15749	dumb batch loss = 0.0654; conv batch loss = 0.0749
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0899; conv batch loss = 0.0878
Step 17999	dumb batch loss = 0.0630; conv batch loss = 0.0943
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0817; conv batch loss = 0.0831
Step 20249	dumb batch loss = 0.0657; conv batch loss = 0.0845
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0839; conv batch loss = 0.1050
Step 22499	dumb batch loss = 0.0612; conv batch loss = 0.1087
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1079; conv batch loss = 0.1226
Step 24749	dumb batch loss = 0.0932; conv batch loss = 0.0744
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0929; conv batch loss = 0.0735
Step 26999	dumb batch loss = 0.1012; conv batch loss = 0.1012
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0649; conv batch loss = 0.0843
Step 29249	dumb batch loss = 0.0622; conv batch loss = 0.0499
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0501; conv batch loss = 0.0731
Step 31499	dumb batch loss = 0.0813; conv batch loss = 0.0831
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0755; conv batch loss = 0.0857
Step 33749	dumb batch loss = 0.0613; conv batch loss = 0.0612
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0729; conv batch loss = 0.0700
Step 35999	dumb batch loss = 0.0951; conv batch loss = 0.0690
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0564; conv batch loss = 0.0701
Step 38249	dumb batch loss = 0.0546; conv batch loss = 0.0529
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0817; conv batch loss = 0.0940
Step 40499	dumb batch loss = 0.0653; conv batch loss = 0.0551
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0570; conv batch loss = 0.0612
Step 42749	dumb batch loss = 0.0835; conv batch loss = 0.0621
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0640; conv batch loss = 0.0542
Step 44999	dumb batch loss = 0.0702; conv batch loss = 0.0851
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0863; conv batch loss = 0.0809
Step 47249	dumb batch loss = 0.0894; conv batch loss = 0.0898
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.1027; conv batch loss = 0.0629
Step 49499	dumb batch loss = 0.0901; conv batch loss = 0.0932
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/37/final.ckpt
Minimum dumb loss: (30374, 0.05011883)
Minimum conv loss: (29249, 0.049901035)
Dumb model prediction:
[[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]
 [ 1. -0. -0. -0. -0.  0. -0. -0. -0. -0.]
 [ 1.  1.  0. -0. -0.  0. -0. -0. -0. -0.]
 [-0. -0.  0. -0. -0.  0. -0. -0. -0.  0.]
 [-0. -0.  0. -0. -0. -0. -0. -0. -0.  0.]
 [-0. -0.  0. -0.  1. -0. -0. -0. -0. -0.]
 [-0. -0.  0. -0. -0. -0. -0. -0. -0. -0.]
 [-0. -0. -0. -0. -0. -0.  1. -0. -0. -0.]
 [-0. -0. -0. -0. -0. -0. -0.  1. -0. -0.]
 [-0. -0.  0. -0. -0.  0. -0. -0. -0. -0.]]
Conv model prediction:
[[-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.   0.1 -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   1. ]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
2018-04-29 08:33:43.503986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:33:43.507099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.74GiB
2018-04-29 08:33:43.507122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:33:43.718092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:33:43.718128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:33:43.718135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:33:43.718339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7429 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '38',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 6.0858; conv batch loss = 11.1118
Saved checkpoint 1
Step 1124	dumb batch loss = 0.8001; conv batch loss = 0.7747
Step 2249	dumb batch loss = 0.3247; conv batch loss = 0.4796
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2138; conv batch loss = 0.3790
Step 4499	dumb batch loss = 0.1710; conv batch loss = 0.2582
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1202; conv batch loss = 0.1688
Step 6749	dumb batch loss = 0.1218; conv batch loss = 0.1510
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1358; conv batch loss = 0.1656
Step 8999	dumb batch loss = 0.0865; conv batch loss = 0.1109
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0827; conv batch loss = 0.0934
Step 11249	dumb batch loss = 0.1546; conv batch loss = 0.1492
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0969; conv batch loss = 0.1305
Step 13499	dumb batch loss = 0.1238; conv batch loss = 0.0884
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0555; conv batch loss = 0.0966
Step 15749	dumb batch loss = 0.0698; conv batch loss = 0.0998
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0831; conv batch loss = 0.0815
Step 17999	dumb batch loss = 0.0618; conv batch loss = 0.0833
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0713; conv batch loss = 0.0847
Step 20249	dumb batch loss = 0.0541; conv batch loss = 0.0541
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0813; conv batch loss = 0.0730
Step 22499	dumb batch loss = 0.0863; conv batch loss = 0.0697
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1154; conv batch loss = 0.1046
Step 24749	dumb batch loss = 0.0952; conv batch loss = 0.0850
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0682; conv batch loss = 0.0848
Step 26999	dumb batch loss = 0.0693; conv batch loss = 0.0959
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0739; conv batch loss = 0.0796
Step 29249	dumb batch loss = 0.0662; conv batch loss = 0.0515
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0609; conv batch loss = 0.0700
Step 31499	dumb batch loss = 0.0807; conv batch loss = 0.1018
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0911; conv batch loss = 0.0859
Step 33749	dumb batch loss = 0.0682; conv batch loss = 0.0768
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0731; conv batch loss = 0.0735
Step 35999	dumb batch loss = 0.0733; conv batch loss = 0.0626
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0701; conv batch loss = 0.0620
Step 38249	dumb batch loss = 0.0543; conv batch loss = 0.0511
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0919; conv batch loss = 0.0860
Step 40499	dumb batch loss = 0.0477; conv batch loss = 0.0698
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0408; conv batch loss = 0.0738
Step 42749	dumb batch loss = 0.0524; conv batch loss = 0.0931
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0704; conv batch loss = 0.0570
Step 44999	dumb batch loss = 0.0545; conv batch loss = 0.0923
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0951; conv batch loss = 0.0760
Step 47249	dumb batch loss = 0.0947; conv batch loss = 0.1054
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0763; conv batch loss = 0.0928
Step 49499	dumb batch loss = 0.0916; conv batch loss = 0.0754
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/38/final.ckpt
Minimum dumb loss: (41624, 0.040809028)
Minimum conv loss: (38249, 0.0511156)
Dumb model prediction:
[[-0. -0. -0.  0. -0.  0.  0. -0. -0.  0.]
 [ 1. -0.  0.  0. -0.  0. -0. -0. -0.  0.]
 [ 1.  1.  0.  0. -0.  0.  0. -0.  0.  0.]
 [-0. -0. -0.  0. -0.  0. -0. -0. -0.  0.]
 [-0. -0. -0.  0. -0.  0.  0. -0. -0.  1.]
 [-0. -0. -0.  0.  1.  0.  0. -0. -0.  0.]
 [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]
 [-0. -0. -0.  0. -0.  0.  1. -0. -0.  0.]
 [-0. -0. -0.  0. -0.  0. -0.  1. -0.  0.]
 [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]]
Conv model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   0.   0.  -0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [-0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.   0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.6]
 [-0.   0.   0.  -0.   1.   0.   0.  -0.   0.   0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.  -0.  -0.   0.   1.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [-0.   0.   0.  -0.   0.   0.   0.   0.   0.   0. ]]
2018-04-29 08:39:32.613804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:39:32.614093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.83GiB
2018-04-29 08:39:32.614118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:39:32.820913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:39:32.820948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:39:32.820955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:39:32.821151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7561 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '39',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 13.6247; conv batch loss = 11.4478
Saved checkpoint 1
Step 1124	dumb batch loss = 0.8074; conv batch loss = 0.7330
Step 2249	dumb batch loss = 0.5440; conv batch loss = 0.3832
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2555; conv batch loss = 0.2907
Step 4499	dumb batch loss = 0.2548; conv batch loss = 0.2903
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1621; conv batch loss = 0.1500
Step 6749	dumb batch loss = 0.1623; conv batch loss = 0.1829
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1635; conv batch loss = 0.1698
Step 8999	dumb batch loss = 0.0970; conv batch loss = 0.1220
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.1053; conv batch loss = 0.1106
Step 11249	dumb batch loss = 0.1209; conv batch loss = 0.1320
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0989; conv batch loss = 0.1109
Step 13499	dumb batch loss = 0.1434; conv batch loss = 0.1017
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0865; conv batch loss = 0.0872
Step 15749	dumb batch loss = 0.0676; conv batch loss = 0.0958
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0850; conv batch loss = 0.0868
Step 17999	dumb batch loss = 0.0879; conv batch loss = 0.0903
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0864; conv batch loss = 0.1008
Step 20249	dumb batch loss = 0.0542; conv batch loss = 0.0541
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0792; conv batch loss = 0.0964
Step 22499	dumb batch loss = 0.0917; conv batch loss = 0.0796
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0926; conv batch loss = 0.1046
Step 24749	dumb batch loss = 0.0859; conv batch loss = 0.0942
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0764; conv batch loss = 0.1017
Step 26999	dumb batch loss = 0.0844; conv batch loss = 0.0908
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0753; conv batch loss = 0.0766
Step 29249	dumb batch loss = 0.0652; conv batch loss = 0.0571
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0888; conv batch loss = 0.0797
Step 31499	dumb batch loss = 0.0925; conv batch loss = 0.0791
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0857; conv batch loss = 0.0762
Step 33749	dumb batch loss = 0.0621; conv batch loss = 0.0912
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0856; conv batch loss = 0.0515
Step 35999	dumb batch loss = 0.0710; conv batch loss = 0.0913
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0726; conv batch loss = 0.0841
Step 38249	dumb batch loss = 0.0628; conv batch loss = 0.0336
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0780; conv batch loss = 0.1001
Step 40499	dumb batch loss = 0.0750; conv batch loss = 0.0641
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0781; conv batch loss = 0.0681
Step 42749	dumb batch loss = 0.0636; conv batch loss = 0.0860
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0465; conv batch loss = 0.0709
Step 44999	dumb batch loss = 0.0725; conv batch loss = 0.1028
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0843; conv batch loss = 0.0933
Step 47249	dumb batch loss = 0.0728; conv batch loss = 0.0932
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0783; conv batch loss = 0.0641
Step 49499	dumb batch loss = 0.0751; conv batch loss = 0.0920
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/39/final.ckpt
Minimum dumb loss: (43874, 0.046499092)
Minimum conv loss: (38249, 0.03355479)
Dumb model prediction:
[[-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.   0.1]
 [ 1.  -0.  -0.   0.   0.  -0.   0.   0.  -0.   0. ]
 [ 1.   1.  -0.   0.2  0.  -0.   0.   0.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   0.  -0.  -0.   0.3]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.   0.2]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.   0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.   0.  -0.   0.   1.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
Conv model prediction:
[[ 0.   0.   0.  -0.   0.   0.   0.   0.  -0.  -0. ]
 [ 1.   0.   0.   0.   0.   0.   0.  -0.   0.   0. ]
 [ 1.   1.   0.   0.  -0.  -0.   0.   0.  -0.  -0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  -0. ]
 [-0.   0.   0.   0.   0.   0.   0.   0.  -0.  -0.3]
 [ 0.   0.   0.  -0.   1.   0.   0.   0.  -0.  -0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  -0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.   0.  -0. ]
 [-0.   0.  -0.   0.   0.  -0.  -0.   1.   0.   0. ]
 [ 0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0. ]]
2018-04-29 08:45:22.022709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:45:22.023114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.80GiB
2018-04-29 08:45:22.023134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:45:22.229041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:45:22.229078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:45:22.229086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:45:22.229290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7433 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '40',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 9.7997; conv batch loss = 7.5881
Saved checkpoint 1
Step 1124	dumb batch loss = 0.8030; conv batch loss = 0.7426
Step 2249	dumb batch loss = 0.2732; conv batch loss = 0.4666
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2224; conv batch loss = 0.3546
Step 4499	dumb batch loss = 0.2489; conv batch loss = 0.2839
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1290; conv batch loss = 0.2086
Step 6749	dumb batch loss = 0.1384; conv batch loss = 0.2126
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1473; conv batch loss = 0.2166
Step 8999	dumb batch loss = 0.1007; conv batch loss = 0.1868
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.1154; conv batch loss = 0.1413
Step 11249	dumb batch loss = 0.1761; conv batch loss = 0.1816
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0948; conv batch loss = 0.1476
Step 13499	dumb batch loss = 0.1433; conv batch loss = 0.1583
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0889; conv batch loss = 0.1140
Step 15749	dumb batch loss = 0.0763; conv batch loss = 0.1267
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.1039; conv batch loss = 0.1293
Step 17999	dumb batch loss = 0.1012; conv batch loss = 0.1068
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0825; conv batch loss = 0.1320
Step 20249	dumb batch loss = 0.0642; conv batch loss = 0.0770
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0774; conv batch loss = 0.0975
Step 22499	dumb batch loss = 0.0779; conv batch loss = 0.0894
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1097; conv batch loss = 0.1233
Step 24749	dumb batch loss = 0.1066; conv batch loss = 0.1064
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0842; conv batch loss = 0.0926
Step 26999	dumb batch loss = 0.0934; conv batch loss = 0.1011
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0730; conv batch loss = 0.1068
Step 29249	dumb batch loss = 0.0817; conv batch loss = 0.0935
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.1232; conv batch loss = 0.0992
Step 31499	dumb batch loss = 0.0685; conv batch loss = 0.0914
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.1010; conv batch loss = 0.1134
Step 33749	dumb batch loss = 0.0953; conv batch loss = 0.0682
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.1012; conv batch loss = 0.0726
Step 35999	dumb batch loss = 0.1377; conv batch loss = 0.0838
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0804; conv batch loss = 0.0736
Step 38249	dumb batch loss = 0.0588; conv batch loss = 0.0526
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.1317; conv batch loss = 0.0989
Step 40499	dumb batch loss = 0.0936; conv batch loss = 0.0556
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0811; conv batch loss = 0.0793
Step 42749	dumb batch loss = 0.0785; conv batch loss = 0.0662
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0635; conv batch loss = 0.0563
Step 44999	dumb batch loss = 0.0805; conv batch loss = 0.0911
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0822; conv batch loss = 0.0777
Step 47249	dumb batch loss = 0.0901; conv batch loss = 0.0858
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0893; conv batch loss = 0.0785
Step 49499	dumb batch loss = 0.1056; conv batch loss = 0.0873
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/40/final.ckpt
Minimum dumb loss: (38249, 0.05878356)
Minimum conv loss: (38249, 0.05256207)
Dumb model prediction:
[[-0.   0.   0.  -0.   0.   0.  -0.  -0.   0.   0. ]
 [ 1.   0.  -0.   0.   0.  -0.  -0.  -0.   0.  -0. ]
 [ 1.   1.  -0.   0.1 -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.   0.   0.  -0.   0.   0.   0.   0.   0.   0. ]
 [-0.   0.   0.  -0.   0.   0.  -0.  -0.   0.   0.3]
 [-0.   0.   0.  -0.   1.  -0.  -0.  -0.   0.   0. ]
 [-0.   0.   0.  -0.   0.   0.  -0.   0.   0.  -0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.   0.   0. ]
 [-0.   0.  -0.  -0.   0.  -0.   0.   1.  -0.  -0. ]
 [-0.   0.   0.  -0.   0.   0.  -0.   0.   0.  -0. ]]
Conv model prediction:
[[-0.   0.  -0.   0.  -0.  -0.  -0.   0.   0.   0. ]
 [ 1.   0.  -0.   0.  -0.  -0.   0.   0.   0.   0. ]
 [ 1.   1.  -0.  -0.2  0.   0.  -0.   0.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.   0.  -0.   0.3]
 [-0.  -0.  -0.   0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.  -0.  -0.   0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.   0.  -0.  -0.   0.   1.  -0.  -0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
2018-04-29 08:51:13.066950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:51:13.067238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.65GiB
2018-04-29 08:51:13.067254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:51:13.346065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:51:13.346101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:51:13.346109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:51:13.346311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7271 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '41',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 4.5773; conv batch loss = 7.9542
Saved checkpoint 1
Step 1124	dumb batch loss = 0.5591; conv batch loss = 0.7911
Step 2249	dumb batch loss = 0.2300; conv batch loss = 0.4816
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2091; conv batch loss = 0.3634
Step 4499	dumb batch loss = 0.1843; conv batch loss = 0.2683
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1422; conv batch loss = 0.1967
Step 6749	dumb batch loss = 0.1050; conv batch loss = 0.1699
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1423; conv batch loss = 0.1582
Step 8999	dumb batch loss = 0.0913; conv batch loss = 0.1007
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0928; conv batch loss = 0.1180
Step 11249	dumb batch loss = 0.1201; conv batch loss = 0.1423
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1020; conv batch loss = 0.1220
Step 13499	dumb batch loss = 0.1016; conv batch loss = 0.1122
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0830; conv batch loss = 0.0816
Step 15749	dumb batch loss = 0.0642; conv batch loss = 0.0764
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0768; conv batch loss = 0.0772
Step 17999	dumb batch loss = 0.0881; conv batch loss = 0.0782
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0796; conv batch loss = 0.0849
Step 20249	dumb batch loss = 0.0511; conv batch loss = 0.0751
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0696; conv batch loss = 0.0667
Step 22499	dumb batch loss = 0.0588; conv batch loss = 0.0745
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1034; conv batch loss = 0.0960
Step 24749	dumb batch loss = 0.0972; conv batch loss = 0.0851
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0582; conv batch loss = 0.0874
Step 26999	dumb batch loss = 0.0748; conv batch loss = 0.0898
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0644; conv batch loss = 0.0777
Step 29249	dumb batch loss = 0.0518; conv batch loss = 0.0637
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0487; conv batch loss = 0.0753
Step 31499	dumb batch loss = 0.0778; conv batch loss = 0.0811
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0742; conv batch loss = 0.0811
Step 33749	dumb batch loss = 0.0879; conv batch loss = 0.0807
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0733; conv batch loss = 0.0597
Step 35999	dumb batch loss = 0.0668; conv batch loss = 0.0926
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0557; conv batch loss = 0.0699
Step 38249	dumb batch loss = 0.0482; conv batch loss = 0.0678
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0892; conv batch loss = 0.0843
Step 40499	dumb batch loss = 0.0393; conv batch loss = 0.0414
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0655; conv batch loss = 0.0661
Step 42749	dumb batch loss = 0.0603; conv batch loss = 0.0731
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0595; conv batch loss = 0.0658
Step 44999	dumb batch loss = 0.0663; conv batch loss = 0.0887
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0722; conv batch loss = 0.0814
Step 47249	dumb batch loss = 0.0882; conv batch loss = 0.1022
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0620; conv batch loss = 0.0719
Step 49499	dumb batch loss = 0.1015; conv batch loss = 0.0932
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/41/final.ckpt
Minimum dumb loss: (40499, 0.039274022)
Minimum conv loss: (40499, 0.041434873)
Dumb model prediction:
[[-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [ 1.  -0.  -0.   0.   0.   0.   0.   0.  -0.   0. ]
 [ 1.   1.  -0.   0.1  0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.   0.7]
 [-0.  -0.  -0.   0.   1.   0.   0.   0.  -0.   0. ]
 [-0.  -0.  -0.   0.   0.  -0.  -0.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.   1.   0.  -0.  -0. ]
 [ 0.  -0.  -0.   0.   0.   0.  -0.   1.  -0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.   0. ]]
Conv model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.2  0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  -0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1]
 [ 0.   0.   0.   0.   1.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]
2018-04-29 08:57:03.477152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:57:03.477454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.51GiB
2018-04-29 08:57:03.477470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:57:03.718881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:57:03.718923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:57:03.718931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:57:03.719117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7198 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '42',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 9.6468; conv batch loss = 11.3602
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7903; conv batch loss = 0.8154
Step 2249	dumb batch loss = 0.3795; conv batch loss = 0.5188
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2619; conv batch loss = 0.3739
Step 4499	dumb batch loss = 0.2178; conv batch loss = 0.2700
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1704; conv batch loss = 0.1855
Step 6749	dumb batch loss = 0.1626; conv batch loss = 0.1511
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1706; conv batch loss = 0.1941
Step 8999	dumb batch loss = 0.1139; conv batch loss = 0.1285
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0713; conv batch loss = 0.1181
Step 11249	dumb batch loss = 0.1420; conv batch loss = 0.1429
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0924; conv batch loss = 0.1152
Step 13499	dumb batch loss = 0.1180; conv batch loss = 0.1195
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0950; conv batch loss = 0.0810
Step 15749	dumb batch loss = 0.0765; conv batch loss = 0.0941
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0960; conv batch loss = 0.0772
Step 17999	dumb batch loss = 0.0870; conv batch loss = 0.0909
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0814; conv batch loss = 0.0930
Step 20249	dumb batch loss = 0.0347; conv batch loss = 0.0733
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0702; conv batch loss = 0.0864
Step 22499	dumb batch loss = 0.0753; conv batch loss = 0.1147
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1228; conv batch loss = 0.1515
Step 24749	dumb batch loss = 0.1041; conv batch loss = 0.1024
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0750; conv batch loss = 0.0934
Step 26999	dumb batch loss = 0.0922; conv batch loss = 0.1210
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0636; conv batch loss = 0.1193
Step 29249	dumb batch loss = 0.0658; conv batch loss = 0.0695
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0737; conv batch loss = 0.0905
Step 31499	dumb batch loss = 0.0705; conv batch loss = 0.1033
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0744; conv batch loss = 0.0843
Step 33749	dumb batch loss = 0.0728; conv batch loss = 0.0801
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0768; conv batch loss = 0.0794
Step 35999	dumb batch loss = 0.0665; conv batch loss = 0.0806
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0624; conv batch loss = 0.0655
Step 38249	dumb batch loss = 0.0676; conv batch loss = 0.0493
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.1086; conv batch loss = 0.1121
Step 40499	dumb batch loss = 0.0564; conv batch loss = 0.0550
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0626; conv batch loss = 0.0725
Step 42749	dumb batch loss = 0.0507; conv batch loss = 0.0762
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0572; conv batch loss = 0.0601
Step 44999	dumb batch loss = 0.0583; conv batch loss = 0.0832
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0723; conv batch loss = 0.0651
Step 47249	dumb batch loss = 0.0988; conv batch loss = 0.0995
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0748; conv batch loss = 0.0737
Step 49499	dumb batch loss = 0.1037; conv batch loss = 0.1095
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/42/final.ckpt
Minimum dumb loss: (20249, 0.034731247)
Minimum conv loss: (38249, 0.049257617)
Dumb model prediction:
[[-0.  -0.  -0.  -0.   0.  -0.   0.   0.  -0.  -0. ]
 [ 1.   0.  -0.   0.2  0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.2  0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [ 0.   0.  -0.   0.   0.   0.   0.   0.   0.  -0. ]
 [ 0.  -0.  -0.   0.   1.   0.   0.   0.   0.   0.2]
 [-0.  -0.  -0.   0.  -0.  -0.   0.   0.  -0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.   1.  -0.  -0.   0. ]
 [ 0.  -0.  -0.   0.   0.  -0.   0.   1.   0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.   0.  -0.   0. ]]
Conv model prediction:
[[ 0.   0.  -0.   0.   0.  -0.  -0.   0.   0.   0.1]
 [ 1.   0.   0.   0.   0.  -0.  -0.  -0.   0.  -0. ]
 [ 1.   1.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.   0.  -0.   0.   0.  -0.  -0.   0.   0.  -0. ]
 [ 0.   0.   0.   0.   0.  -0.  -0.   0.   0.  -0. ]
 [ 0.  -0.  -0.  -0.   1.  -0.  -0.   0.  -0.  -0. ]
 [-0.   0.   0.  -0.  -0.  -0.   0.   0.   0.  -0. ]
 [ 0.   0.   0.   0.  -0.   0.   1.   0.   0.  -0. ]
 [-0.   0.   0.  -0.   0.  -0.  -0.   1.   0.  -0. ]
 [ 0.   0.  -0.   0.  -0.  -0.  -0.   0.   0.  -0. ]]
2018-04-29 09:02:52.150146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 09:02:52.150442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.69GiB
2018-04-29 09:02:52.150459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 09:02:52.352526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 09:02:52.352567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 09:02:52.352578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 09:02:52.352809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7426 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '43',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 4.0085; conv batch loss = 9.2240
Saved checkpoint 1
Step 1124	dumb batch loss = 0.6097; conv batch loss = 0.7553
Step 2249	dumb batch loss = 0.2745; conv batch loss = 0.4488
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2060; conv batch loss = 0.3244
Step 4499	dumb batch loss = 0.2002; conv batch loss = 0.2755
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1284; conv batch loss = 0.1704
Step 6749	dumb batch loss = 0.1114; conv batch loss = 0.1566
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1702; conv batch loss = 0.1918
Step 8999	dumb batch loss = 0.1034; conv batch loss = 0.1119
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0857; conv batch loss = 0.1244
Step 11249	dumb batch loss = 0.1315; conv batch loss = 0.1709
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1292; conv batch loss = 0.1138
Step 13499	dumb batch loss = 0.1192; conv batch loss = 0.1144
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0808; conv batch loss = 0.0847
Step 15749	dumb batch loss = 0.0742; conv batch loss = 0.0735
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0801; conv batch loss = 0.0784
Step 17999	dumb batch loss = 0.1156; conv batch loss = 0.0854
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.1007; conv batch loss = 0.0853
Step 20249	dumb batch loss = 0.0632; conv batch loss = 0.0446
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0714; conv batch loss = 0.0818
Step 22499	dumb batch loss = 0.0801; conv batch loss = 0.0788
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0913; conv batch loss = 0.1002
Step 24749	dumb batch loss = 0.0837; conv batch loss = 0.0788
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0960; conv batch loss = 0.0925
Step 26999	dumb batch loss = 0.0835; conv batch loss = 0.0756
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.1015; conv batch loss = 0.0776
Step 29249	dumb batch loss = 0.0644; conv batch loss = 0.0601
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0572; conv batch loss = 0.0625
Step 31499	dumb batch loss = 0.0793; conv batch loss = 0.0768
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0636; conv batch loss = 0.0695
Step 33749	dumb batch loss = 0.0789; conv batch loss = 0.0645
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0718; conv batch loss = 0.0569
Step 35999	dumb batch loss = 0.0663; conv batch loss = 0.0704
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0701; conv batch loss = 0.0667
Step 38249	dumb batch loss = 0.0421; conv batch loss = 0.0530
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0831; conv batch loss = 0.0987
Step 40499	dumb batch loss = 0.0635; conv batch loss = 0.0561
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0692; conv batch loss = 0.0745
Step 42749	dumb batch loss = 0.0599; conv batch loss = 0.0549
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0661; conv batch loss = 0.0618
Step 44999	dumb batch loss = 0.0939; conv batch loss = 0.0678
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0675; conv batch loss = 0.0619
Step 47249	dumb batch loss = 0.0862; conv batch loss = 0.0718
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0523; conv batch loss = 0.0656
Step 49499	dumb batch loss = 0.1038; conv batch loss = 0.0935
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/43/final.ckpt
Minimum dumb loss: (38249, 0.042099755)
Minimum conv loss: (20249, 0.044615507)
Dumb model prediction:
[[ 0.   0.   0.   0.   0.   0.  -0.   0.   0.   0. ]
 [ 1.   0.   0.  -0.   0.   0.  -0.   0.   0.   0. ]
 [ 1.   1.   0.  -0.   0.   0.  -0.  -0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.  -0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.  -0.   0.   0.   0.1]
 [-0.   0.   0.  -0.   1.  -0.  -0.  -0.   0.  -0. ]
 [-0.   0.   0.  -0.   0.   0.  -0.  -0.   0.  -0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.   0.   0. ]
 [ 0.   0.   0.   0.  -0.  -0.  -0.   1.   0.  -0. ]
 [ 0.   0.   0.   0.   0.   0.  -0.   0.   0.   0. ]]
Conv model prediction:
[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1]
 [0.  0.  0.  0.  1.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  1.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]
2018-04-29 09:08:42.042248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 09:08:42.042535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.73GiB
2018-04-29 09:08:42.042552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 09:08:42.246000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 09:08:42.246049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 09:08:42.246073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 09:08:42.246310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7427 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '44',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 4.2561; conv batch loss = 12.3540
Saved checkpoint 1
Step 1124	dumb batch loss = 0.6629; conv batch loss = 0.7949
Step 2249	dumb batch loss = 0.3142; conv batch loss = 0.4739
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2284; conv batch loss = 0.3929
Step 4499	dumb batch loss = 0.2088; conv batch loss = 0.3196
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1785; conv batch loss = 0.1720
Step 6749	dumb batch loss = 0.1889; conv batch loss = 0.1520
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1975; conv batch loss = 0.1622
Step 8999	dumb batch loss = 0.0985; conv batch loss = 0.1070
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.1055; conv batch loss = 0.1018
Step 11249	dumb batch loss = 0.1358; conv batch loss = 0.1114
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1295; conv batch loss = 0.1046
Step 13499	dumb batch loss = 0.1440; conv batch loss = 0.0998
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0916; conv batch loss = 0.0866
Step 15749	dumb batch loss = 0.1038; conv batch loss = 0.0732
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.1115; conv batch loss = 0.0753
Step 17999	dumb batch loss = 0.0864; conv batch loss = 0.0699
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.1077; conv batch loss = 0.0889
Step 20249	dumb batch loss = 0.0896; conv batch loss = 0.0608
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.1148; conv batch loss = 0.0900
Step 22499	dumb batch loss = 0.0819; conv batch loss = 0.0952
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1243; conv batch loss = 0.0950
Step 24749	dumb batch loss = 0.1059; conv batch loss = 0.0680
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0901; conv batch loss = 0.0736
Step 26999	dumb batch loss = 0.0672; conv batch loss = 0.0833
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0836; conv batch loss = 0.0606
Step 29249	dumb batch loss = 0.0787; conv batch loss = 0.0549
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0793; conv batch loss = 0.0708
Step 31499	dumb batch loss = 0.0752; conv batch loss = 0.0949
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0840; conv batch loss = 0.0814
Step 33749	dumb batch loss = 0.0947; conv batch loss = 0.0734
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0732; conv batch loss = 0.0711
Step 35999	dumb batch loss = 0.0651; conv batch loss = 0.0577
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0819; conv batch loss = 0.0661
Step 38249	dumb batch loss = 0.0629; conv batch loss = 0.0465
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0800; conv batch loss = 0.0822
Step 40499	dumb batch loss = 0.0581; conv batch loss = 0.0640
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0540; conv batch loss = 0.0584
Step 42749	dumb batch loss = 0.0646; conv batch loss = 0.0657
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0485; conv batch loss = 0.0604
Step 44999	dumb batch loss = 0.0687; conv batch loss = 0.0803
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0698; conv batch loss = 0.0806
Step 47249	dumb batch loss = 0.0776; conv batch loss = 0.0633
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.1110; conv batch loss = 0.0808
Step 49499	dumb batch loss = 0.1148; conv batch loss = 0.0960
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/44/final.ckpt
Minimum dumb loss: (43874, 0.04851066)
Minimum conv loss: (38249, 0.04649608)
Dumb model prediction:
[[ 0.  -0.  -0.   0.   0.  -0.   0.   0.  -0.   0. ]
 [ 1.   0.   0.   0.   0.  -0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.   0.  -0.   0.   0.  -0.   0.6]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.   0.  -0.   0.  -0.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [ 0.  -0.  -0.   0.   0.  -0.   0.   1.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0. ]]
Conv model prediction:
[[-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.1  0.3 -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.5]
 [-0.  -0.  -0.1 -0.   1.  -0.1 -0.1 -0.  -0.  -0. ]
 [-0.  -0.  -0.1 -0.  -0.  -0.1 -0.1 -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.1 -0.  -0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
2018-04-29 09:14:33.449275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 09:14:33.449807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.71GiB
2018-04-29 09:14:33.449830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 09:14:33.661570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 09:14:33.661604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 09:14:33.661613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 09:14:33.661814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7295 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '45',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 4.1234; conv batch loss = 9.8428
Saved checkpoint 1
Step 1124	dumb batch loss = 0.6402; conv batch loss = 0.7714
Step 2249	dumb batch loss = 0.2261; conv batch loss = 0.3906
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2153; conv batch loss = 0.3171
Step 4499	dumb batch loss = 0.1690; conv batch loss = 0.2659
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1396; conv batch loss = 0.1492
Step 6749	dumb batch loss = 0.1338; conv batch loss = 0.1869
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1539; conv batch loss = 0.1654
Step 8999	dumb batch loss = 0.0769; conv batch loss = 0.0898
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0755; conv batch loss = 0.0914
Step 11249	dumb batch loss = 0.0929; conv batch loss = 0.1121
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0992; conv batch loss = 0.1021
Step 13499	dumb batch loss = 0.0991; conv batch loss = 0.0852
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0739; conv batch loss = 0.0747
Step 15749	dumb batch loss = 0.0692; conv batch loss = 0.0799
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0929; conv batch loss = 0.0934
Step 17999	dumb batch loss = 0.0730; conv batch loss = 0.0672
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0774; conv batch loss = 0.0829
Step 20249	dumb batch loss = 0.0501; conv batch loss = 0.0673
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0677; conv batch loss = 0.0832
Step 22499	dumb batch loss = 0.0824; conv batch loss = 0.0775
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1037; conv batch loss = 0.1105
Step 24749	dumb batch loss = 0.0856; conv batch loss = 0.0837
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0521; conv batch loss = 0.0626
Step 26999	dumb batch loss = 0.0611; conv batch loss = 0.0841
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0712; conv batch loss = 0.0718
Step 29249	dumb batch loss = 0.0578; conv batch loss = 0.0554
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0458; conv batch loss = 0.0545
Step 31499	dumb batch loss = 0.0847; conv batch loss = 0.0770
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0785; conv batch loss = 0.0790
Step 33749	dumb batch loss = 0.0589; conv batch loss = 0.0900
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0578; conv batch loss = 0.0991
Step 35999	dumb batch loss = 0.0744; conv batch loss = 0.0706
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0579; conv batch loss = 0.0850
Step 38249	dumb batch loss = 0.0478; conv batch loss = 0.0530
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0728; conv batch loss = 0.0726
Step 40499	dumb batch loss = 0.0404; conv batch loss = 0.0544
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0581; conv batch loss = 0.0666
Step 42749	dumb batch loss = 0.0705; conv batch loss = 0.0731
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0462; conv batch loss = 0.0583
Step 44999	dumb batch loss = 0.0959; conv batch loss = 0.0855
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0587; conv batch loss = 0.0738
Step 47249	dumb batch loss = 0.1100; conv batch loss = 0.0978
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0669; conv batch loss = 0.0819
Step 49499	dumb batch loss = 0.0981; conv batch loss = 0.0781
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/45/final.ckpt
Minimum dumb loss: (40499, 0.040407214)
Minimum conv loss: (38249, 0.053015172)
Dumb model prediction:
[[-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.   0.1 -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   1. ]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
Conv model prediction:
[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]
 [0.  0.  0.  0.  1.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  1.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]
2018-04-29 09:20:23.919418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 09:20:23.919844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.74GiB
2018-04-29 09:20:23.919860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 09:20:24.124497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 09:20:24.124533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 09:20:24.124540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 09:20:24.124727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7427 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '46',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 4.5115; conv batch loss = 9.2709
Saved checkpoint 1
Step 1124	dumb batch loss = 0.5339; conv batch loss = 0.7492
Step 2249	dumb batch loss = 0.2053; conv batch loss = 0.3229
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.1779; conv batch loss = 0.2072
Step 4499	dumb batch loss = 0.1643; conv batch loss = 0.2056
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1368; conv batch loss = 0.1397
Step 6749	dumb batch loss = 0.1097; conv batch loss = 0.1395
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1593; conv batch loss = 0.1213
Step 8999	dumb batch loss = 0.0830; conv batch loss = 0.0922
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0972; conv batch loss = 0.0928
Step 11249	dumb batch loss = 0.1487; conv batch loss = 0.1268
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0974; conv batch loss = 0.0801
Step 13499	dumb batch loss = 0.1097; conv batch loss = 0.0914
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.1019; conv batch loss = 0.0726
Step 15749	dumb batch loss = 0.0729; conv batch loss = 0.0746
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0935; conv batch loss = 0.0920
Step 17999	dumb batch loss = 0.0760; conv batch loss = 0.0798
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.1016; conv batch loss = 0.0911
Step 20249	dumb batch loss = 0.0650; conv batch loss = 0.0624
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0680; conv batch loss = 0.0630
Step 22499	dumb batch loss = 0.0931; conv batch loss = 0.0512
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1071; conv batch loss = 0.1020
Step 24749	dumb batch loss = 0.1016; conv batch loss = 0.0770
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.1040; conv batch loss = 0.0891
Step 26999	dumb batch loss = 0.0577; conv batch loss = 0.0686
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0733; conv batch loss = 0.0625
Step 29249	dumb batch loss = 0.0639; conv batch loss = 0.0591
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0785; conv batch loss = 0.0590
Step 31499	dumb batch loss = 0.0752; conv batch loss = 0.0737
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0961; conv batch loss = 0.0741
Step 33749	dumb batch loss = 0.0993; conv batch loss = 0.0943
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.1026; conv batch loss = 0.0654
Step 35999	dumb batch loss = 0.0861; conv batch loss = 0.0687
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0784; conv batch loss = 0.0767
Step 38249	dumb batch loss = 0.0534; conv batch loss = 0.0423
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0986; conv batch loss = 0.0942
Step 40499	dumb batch loss = 0.0480; conv batch loss = 0.0545
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0893; conv batch loss = 0.0581
Step 42749	dumb batch loss = 0.0659; conv batch loss = 0.0558
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0846; conv batch loss = 0.0684
Step 44999	dumb batch loss = 0.0909; conv batch loss = 0.0851
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0723; conv batch loss = 0.0707
Step 47249	dumb batch loss = 0.0804; conv batch loss = 0.0977
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0758; conv batch loss = 0.0758
Step 49499	dumb batch loss = 0.0964; conv batch loss = 0.0751
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/46/final.ckpt
Minimum dumb loss: (40499, 0.04798557)
Minimum conv loss: (38249, 0.042343426)
Dumb model prediction:
[[ 0.   0.   0.   0.  -0.   0.  -0.  -0.   0.  -0. ]
 [ 1.   0.   0.   0.3  0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.1  0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.  -0.   0.  -0.  -0.   0.   0. ]
 [ 0.   0.   0.   0.  -0.   0.  -0.  -0.   0.   0.6]
 [ 0.   0.   0.   0.   1.   0.   0.   0.   0.   0.1]
 [ 0.   0.   0.   0.  -0.   0.   0.  -0.   0.   0. ]
 [ 0.   0.   0.   0.  -0.  -0.   1.  -0.   0.  -0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   1.   0.   0. ]
 [ 0.  -0.   0.   0.  -0.   0.   0.  -0.   0.   0. ]]
Conv model prediction:
[[-0.  -0.  -0.   0.   0.   0.  -0.  -0.   0.   0. ]
 [ 1.  -0.  -0.   0.  -0.  -0.  -0.   0.  -0.   0. ]
 [ 1.   1.  -0.   0.   0.   0.  -0.   0.   0.  -0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.   0.  -0.   0.  -0.  -0.  -0.   0.8]
 [-0.  -0.  -0.   0.   1.   0.  -0.   0.   0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.   0.   0.   0.   1.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.  -0.   0.  -0.   1.  -0.   0. ]
 [-0.  -0.  -0.   0.  -0.   0.  -0.  -0.  -0.  -0. ]]
2018-04-29 09:26:14.110387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 09:26:14.110709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.80GiB
2018-04-29 09:26:14.110727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 09:26:14.361022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 09:26:14.361060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 09:26:14.361068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 09:26:14.361265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7314 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '47',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 6.0682; conv batch loss = 8.0076
Saved checkpoint 1
Step 1124	dumb batch loss = 0.6315; conv batch loss = 0.8197
Step 2249	dumb batch loss = 0.2330; conv batch loss = 0.5118
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2290; conv batch loss = 0.3370
Step 4499	dumb batch loss = 0.1776; conv batch loss = 0.3119
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1143; conv batch loss = 0.2089
Step 6749	dumb batch loss = 0.1167; conv batch loss = 0.1353
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1551; conv batch loss = 0.1949
Step 8999	dumb batch loss = 0.1148; conv batch loss = 0.1107
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0751; conv batch loss = 0.1024
Step 11249	dumb batch loss = 0.1431; conv batch loss = 0.1146
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1203; conv batch loss = 0.1113
Step 13499	dumb batch loss = 0.1219; conv batch loss = 0.0934
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0943; conv batch loss = 0.0623
Step 15749	dumb batch loss = 0.0817; conv batch loss = 0.0665
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0937; conv batch loss = 0.0994
Step 17999	dumb batch loss = 0.1009; conv batch loss = 0.0788
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0897; conv batch loss = 0.0873
Step 20249	dumb batch loss = 0.0571; conv batch loss = 0.0700
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0654; conv batch loss = 0.0773
Step 22499	dumb batch loss = 0.0924; conv batch loss = 0.0700
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1075; conv batch loss = 0.0890
Step 24749	dumb batch loss = 0.0943; conv batch loss = 0.0810
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0714; conv batch loss = 0.0713
Step 26999	dumb batch loss = 0.0807; conv batch loss = 0.0767
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0989; conv batch loss = 0.0682
Step 29249	dumb batch loss = 0.0522; conv batch loss = 0.0356
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0886; conv batch loss = 0.0686
Step 31499	dumb batch loss = 0.1137; conv batch loss = 0.0754
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0840; conv batch loss = 0.0875
Step 33749	dumb batch loss = 0.0875; conv batch loss = 0.0776
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0963; conv batch loss = 0.0649
Step 35999	dumb batch loss = 0.0854; conv batch loss = 0.0786
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0677; conv batch loss = 0.0662
Step 38249	dumb batch loss = 0.0603; conv batch loss = 0.0502
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0962; conv batch loss = 0.0807
Step 40499	dumb batch loss = 0.0843; conv batch loss = 0.0423
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0722; conv batch loss = 0.0658
Step 42749	dumb batch loss = 0.0693; conv batch loss = 0.0545
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0457; conv batch loss = 0.0820
Step 44999	dumb batch loss = 0.0805; conv batch loss = 0.0729
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0730; conv batch loss = 0.0651
Step 47249	dumb batch loss = 0.1098; conv batch loss = 0.0660
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0737; conv batch loss = 0.0684
Step 49499	dumb batch loss = 0.0786; conv batch loss = 0.0807
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/47/final.ckpt
Minimum dumb loss: (43874, 0.045682494)
Minimum conv loss: (29249, 0.03557889)
Dumb model prediction:
[[ 0.   0.   0.  -0.  -0.   0.  -0.  -0.   0.  -0.2]
 [ 1.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.  -0. ]
 [ 1.   1.  -0.  -0.  -0.  -0.  -0.  -0.   0.  -0. ]
 [ 0.   0.   0.  -0.   0.   0.  -0.  -0.   0.  -0. ]
 [ 0.  -0.   0.  -0.  -0.  -0.  -0.  -0.   0.   0.7]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.   0.  -0. ]
 [ 0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.  -0. ]
 [ 0.   0.   0.  -0.  -0.  -0.   1.  -0.   0.  -0. ]
 [ 0.  -0.   0.  -0.  -0.  -0.  -0.   1.   0.  -0. ]
 [ 0.   0.   0.  -0.   0.   0.  -0.   0.   0.  -0. ]]
Conv model prediction:
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
2018-04-29 09:32:04.158047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 09:32:04.158355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.57GiB
2018-04-29 09:32:04.158371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 09:32:04.363979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 09:32:04.364013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 09:32:04.364020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 09:32:04.364201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7290 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '48',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 13.4815; conv batch loss = 10.0885
Saved checkpoint 1
Step 1124	dumb batch loss = 0.8213; conv batch loss = 0.7597
Step 2249	dumb batch loss = 0.4554; conv batch loss = 0.3886
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2605; conv batch loss = 0.3342
Step 4499	dumb batch loss = 0.2264; conv batch loss = 0.2547
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1161; conv batch loss = 0.2109
Step 6749	dumb batch loss = 0.1205; conv batch loss = 0.1846
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1535; conv batch loss = 0.1588
Step 8999	dumb batch loss = 0.0811; conv batch loss = 0.1193
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0911; conv batch loss = 0.1030
Step 11249	dumb batch loss = 0.1286; conv batch loss = 0.1460
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1035; conv batch loss = 0.1035
Step 13499	dumb batch loss = 0.1230; conv batch loss = 0.0997
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0831; conv batch loss = 0.1157
Step 15749	dumb batch loss = 0.0741; conv batch loss = 0.0929
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.1033; conv batch loss = 0.0871
Step 17999	dumb batch loss = 0.0850; conv batch loss = 0.1282
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0646; conv batch loss = 0.0949
Step 20249	dumb batch loss = 0.0691; conv batch loss = 0.0746
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0707; conv batch loss = 0.0679
Step 22499	dumb batch loss = 0.0896; conv batch loss = 0.0845
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1282; conv batch loss = 0.1206
Step 24749	dumb batch loss = 0.0860; conv batch loss = 0.1003
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0727; conv batch loss = 0.0896
Step 26999	dumb batch loss = 0.0890; conv batch loss = 0.1083
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.1078; conv batch loss = 0.0868
Step 29249	dumb batch loss = 0.0565; conv batch loss = 0.0903
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0600; conv batch loss = 0.0618
Step 31499	dumb batch loss = 0.1036; conv batch loss = 0.0773
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0837; conv batch loss = 0.0833
Step 33749	dumb batch loss = 0.0797; conv batch loss = 0.0987
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0851; conv batch loss = 0.1036
Step 35999	dumb batch loss = 0.0704; conv batch loss = 0.0710
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0534; conv batch loss = 0.0786
Step 38249	dumb batch loss = 0.0507; conv batch loss = 0.0508
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.1089; conv batch loss = 0.0972
Step 40499	dumb batch loss = 0.0713; conv batch loss = 0.0525
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0981; conv batch loss = 0.0710
Step 42749	dumb batch loss = 0.0697; conv batch loss = 0.0734
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0652; conv batch loss = 0.0736
Step 44999	dumb batch loss = 0.0734; conv batch loss = 0.0972
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0923; conv batch loss = 0.1039
Step 47249	dumb batch loss = 0.0877; conv batch loss = 0.1158
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.1112; conv batch loss = 0.0828
Step 49499	dumb batch loss = 0.0977; conv batch loss = 0.0813
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/48/final.ckpt
Minimum dumb loss: (38249, 0.0506511)
Minimum conv loss: (38249, 0.05076774)
Dumb model prediction:
[[-0.  -0.  -0.   0.  -0.  -0.   0.  -0.  -0.   0. ]
 [ 1.  -0.  -0.  -0.   0.  -0.   0.   0.  -0.  -0. ]
 [ 1.   1.   0.   0.2  0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.  -0.  -0.   0.   0.   0.   0.  -0.  -0.   0.2]
 [ 0.  -0.  -0.   0.   1.   0.   0.   0.  -0.   0. ]
 [ 0.  -0.  -0.   0.  -0.   0.  -0.  -0.  -0.   0. ]
 [ 0.  -0.  -0.   0.   0.  -0.   1.  -0.  -0.   0. ]
 [ 0.  -0.  -0.   0.   0.   0.   0.   1.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
Conv model prediction:
[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  1.  0.  0.1 0.  0.  0.  0.1 0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5]
 [0.  0.  0.  0.  1.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  1.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]
2018-04-29 09:37:56.090277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 09:37:56.090584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.54GiB
2018-04-29 09:37:56.090606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 09:37:56.338443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 09:37:56.338478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 09:37:56.338486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 09:37:56.338696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7244 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '49',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 9.9967; conv batch loss = 11.2510
Saved checkpoint 1
Step 1124	dumb batch loss = 0.8193; conv batch loss = 0.7876
Step 2249	dumb batch loss = 0.4961; conv batch loss = 0.4774
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2790; conv batch loss = 0.3148
Step 4499	dumb batch loss = 0.2277; conv batch loss = 0.2438
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1719; conv batch loss = 0.1644
Step 6749	dumb batch loss = 0.1597; conv batch loss = 0.1561
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1830; conv batch loss = 0.1620
Step 8999	dumb batch loss = 0.1124; conv batch loss = 0.0975
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0972; conv batch loss = 0.0807
Step 11249	dumb batch loss = 0.1597; conv batch loss = 0.1382
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1137; conv batch loss = 0.0866
Step 13499	dumb batch loss = 0.1584; conv batch loss = 0.1199
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0854; conv batch loss = 0.0758
Step 15749	dumb batch loss = 0.0741; conv batch loss = 0.0812
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.1012; conv batch loss = 0.0692
Step 17999	dumb batch loss = 0.0710; conv batch loss = 0.0727
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0696; conv batch loss = 0.0778
Step 20249	dumb batch loss = 0.0789; conv batch loss = 0.0511
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0904; conv batch loss = 0.0816
Step 22499	dumb batch loss = 0.0704; conv batch loss = 0.0825
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1152; conv batch loss = 0.1223
Step 24749	dumb batch loss = 0.0848; conv batch loss = 0.0812
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0850; conv batch loss = 0.0725
Step 26999	dumb batch loss = 0.0769; conv batch loss = 0.1001
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0903; conv batch loss = 0.0787
Step 29249	dumb batch loss = 0.0863; conv batch loss = 0.0673
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0686; conv batch loss = 0.0885
Step 31499	dumb batch loss = 0.0704; conv batch loss = 0.0917
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0858; conv batch loss = 0.0741
Step 33749	dumb batch loss = 0.1012; conv batch loss = 0.0834
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.1045; conv batch loss = 0.0676
Step 35999	dumb batch loss = 0.0726; conv batch loss = 0.1235
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0899; conv batch loss = 0.0643
Step 38249	dumb batch loss = 0.0428; conv batch loss = 0.0459
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0888; conv batch loss = 0.0793
Step 40499	dumb batch loss = 0.0578; conv batch loss = 0.0447
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0705; conv batch loss = 0.0547
Step 42749	dumb batch loss = 0.0564; conv batch loss = 0.0686
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0508; conv batch loss = 0.0675
Step 44999	dumb batch loss = 0.0720; conv batch loss = 0.0947
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0880; conv batch loss = 0.0633
Step 47249	dumb batch loss = 0.0992; conv batch loss = 0.0664
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0826; conv batch loss = 0.0632
Step 49499	dumb batch loss = 0.0811; conv batch loss = 0.0931
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/49/final.ckpt
Minimum dumb loss: (38249, 0.042776573)
Minimum conv loss: (40499, 0.04465658)
Dumb model prediction:
[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1]
 [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]
 [0.  0.  0.  0.  1.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  1.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]
Conv model prediction:
[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  1.  0.  0.1 0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1]
 [0.  0.  0.  0.  1.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  1.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]
