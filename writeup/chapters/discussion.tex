%! TEX root = /home/hsartoris/sproj/writeup/main.tex
\chapter{Discussion}
As described in \ref{sec:localitybroken}, in all cases tested, models equipped 
with our locality layer tended to stay very close to the benchmark models in 
loss, with a slight tendency towards higher loss. This tendency is explained by 
the simple presence of more values to optimize over. More to the point, we must 
return to the motivation behind incorporating locality into network 
reconstruction: we hope that our model will learn to recognize recurrent local 
structures in biological networks, and use that information to judge individual 
connection probability in the context of its neighbors. Two potential factors in 
our model's failure to manifest this behavior are apparent: data used, and 
specific locality algorithm design.

\section{Data}
An important part of analyzing the performance of our locality layer is to 
understand what we are looking for. In the cases tested, the locality-enabled 
model was not able to outstrip the benchmark model in terms of loss or 
predictive accuracy, but this likely speaks more to the type of data being used 
to train the networks than to the relative efficacy of either architecture. If 
three matrix multiplications are sufficient to reconstruct the structure of a 
network, there is little need for a model to involve abstract concepts like 
locality, and, even if forced to do so, it's not clear that having such concepts 
available would contribute to more effective reconstruction. The ideal test 
dataset, then, would be one on which the benchmark model does not converge to an 
accurate prediction, allowing us to train a locality-enabled model and get some 
idea of how much useful information is actually added. Here, we outline some 
directions we could go in data generation.

\subsection{Complex Neurons}
As it stands, every generator we used to produce data consisted of binary 
connections and created binary outputs. There are clearly more accurate methods 
of simulating biological neural network activity, such as implementing 
Izhikevich neurons\footnote{Cite}, or going as far as generating data with
NEST\footnote{citation}. However, while more complex neurons would probably 
encourage the model to look to locality for information, this alone would not 
suffice.

\subsection{Larger, Structured Networks}
A model being able to leverage its access to locality data to locate 2-simplices 
will not encounter any particular benefit from this ability if the generators it 
is tasked with reconstructing contain at most one such structure. Indeed, 
preliminary results suggest that a large gap opens between models considering 
locality and those not when the training data is generated from a large 
($n\approx50$) network seeded with recurring motifs. On such a dataset, the 
benchmark model cannot get below .5 loss, while the locality-enabled model hits 
.35 easily.

\section{Improvements to Locality Processing}

\subsection{Layering}
There may need to be more initial layers to provide useful data to the Locality 
layers.  As it stands, the model structure requires that the first layer both 
compare the activities of neuron pairs and format the resulting data in such a 
manner that the locality-based layer can usefully include it in determining node 
existence.  Adding at least one intermediary processing layer might allow the 
network to format the data going in to the locality layer in a more useful way.  
Merits further testing.

\subsection{Loss}
\label{subsec:lossdisc}
As described in \ref{subsubsec:losseffects}, our custom loss function equally 
weights false positives and false negatives. Consider these cases:

\begin{enumerate}
	\item Output 0.3; target 1.0: adds $(0.3-1.0)^2=0.49$ to the loss
	\item Output 0.7; target 0.0: adds $(0.7-0.0)^2=0.49$ to the loss
\end{enumerate}
Despite the equivalent loss contributions, the latter case is the less correct 
of the two: while guessing a weak connection where there is a strong one is not 
ideal, it is preferable to guessing a strong connection where there is none.  
Thus our loss function might be modified to more strongly disincentive false 
positives.

\section{Potential Applications/Further Development}

In the process of creating this network, we implemented a pure-numpy version, 
which can run on matrices created by a model trained in TensorFlow. This would, 
along with the portability of our model, allow for training and then 
distributing ready-to-run reconstruction models, without the need for user 
experience with GPUs, machine learning, or any of the like.
