%! TEX root = /home/hsartoris/sproj/writeup/main.tex

\chapter{Background}

\section{Biological Neural Networks}

\section{Graph Structures}

\subsection{Graph Locality}

\section{Convolutional Neural Networks}
Convolutional neural networks as we know them today were first put forth by 
LeCun et al. in 

\subsection{Adaptation to Graph Locality}


\section{Concepts and Terms}
Before diving into the specifics of data production, model architecture, and 
training, it's important to establish several important concepts.

\subsection{Adjacency Matrices}
\label{subsec:adjacency}
The representation of neural network connectivity that we will focus on is the 
adjacency matrix. For \textit{n} neurons, an adjacency matrix $\mathbb{M}$ will 
be of dimensions $(n \times n)$. A simplistic method of predicting network 
activity, and one that we will use to produce our data, is to multiply this 
matrix by an \textit{n}-vector representing current activity at each neuron.  
Such an operation appears as follows for $n=3$:
\[ \begin{bmatrix}
		a & b & c\\
		d & e & f\\
		g & h & i
	\end{bmatrix}
	\times
	\begin{bmatrix}
		x\\
		y\\
		z
	\end{bmatrix}
	=
	\begin{bmatrix}
		ax + by + cz\\
		dx + ey + fz\\
		gx + hy + iz
	\end{bmatrix}
\]
Thus the activity for a given neuron is defined entirely in terms of network 
activity at the previous timestep and the weights in the adjacency matrix in the 
row corresponding to that neuron. We thereby arrive at a simple expression of 
the mechanics of adjacency matrices: 

\begin{enumerate}
	\item Weights in some row \textit{i} define inputs to neuron \textit{i}
	\item Weights in some column \textit{j} define outputs from neuron 
		\textit{j}
	\item The singular weight at $\mathbb{M}_{ij}$ defines the connection from 
		neuron \textit{j} to neuron \textit{i}.  
\end{enumerate}

Keeping this inverse relationship in mind will help prevent confusion in later 
chapters.
