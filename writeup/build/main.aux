\relax 
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Biological Neural Networks}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Graph Structures}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Graph Locality}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Convolutional Neural Networks}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Adaptation to Graph Locality}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Concepts and Terms}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Adjacency Matrices}{4}}
\newlabel{subsec:adjacency}{{2.4.1}{4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Model}{5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{model}{{3}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Data}{5}}
\newlabel{sec:data}{{3.1}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Generation}{6}}
\newlabel{subsec:generation}{{3.1.1}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Example of 3-neuron network and adjacency matrix.\relax }}{6}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:toyex}{{3.1}{6}}
\@writefile{toc}{\contentsline {subsubsection}{Example Data Generation}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Example output matrix for a 3-neuron network simulated for five steps.\relax }}{8}}
\newlabel{fig:exoutput}{{3.2}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Restructuring}{8}}
\newlabel{subsec:restructuring}{{3.1.2}{8}}
\@writefile{toc}{\contentsline {subsubsection}{Input Data}{8}}
\newlabel{subfig:3outexgraph}{{3.3b}{9}}
\newlabel{sub@subfig:3outexgraph}{{b}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Transposed and truncated matrix and associated visualization.\relax }}{9}}
\newlabel{fig:data+vis}{{3.3}{9}}
\@writefile{toc}{\contentsline {subsubsection}{Target Data}{9}}
\newlabel{subsubsec:targetdata}{{3.1.2}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Generalizability}{9}}
\newlabel{subsec:hotswap}{{3.1.3}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Architecture}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Structure \& Computation Details}{10}}
\@writefile{toc}{\contentsline {subsubsection}{Dimensionality-defining Variables}{10}}
\@writefile{toc}{\contentsline {subsubsection}{Omitted Details}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Conceptual Model}{11}}
\newlabel{subsec:conceptualmodel}{{3.2.2}{11}}
\@writefile{toc}{\contentsline {subsubsection}{First Transition}{11}}
\@writefile{toc}{\contentsline {subsubsection}{Locality Layer}{12}}
\newlabel{subsubsec:locality}{{3.2.2}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Relationship between $\mathbb  {D}^{\prime }$ and $\mathbb  {D}^{\prime }_N$.\relax }}{12}}
\newlabel{fig:transform}{{3.4}{12}}
\newlabel{eq:ID}{{\bfseries  3.1a}{13}}
\newlabel{eq:IDOD}{{\bfseries  3.1b}{13}}
\newlabel{eq:dijO}{{\bfseries  3.1c}{13}}
\@writefile{toc}{\contentsline {subsubsection}{Final Transition}{14}}
\newlabel{eq:conceptfinal}{{\bfseries  3.2}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Matrix Model}{14}}
\newlabel{subsec:matmodel}{{3.2.3}{14}}
\@writefile{toc}{\contentsline {subsubsection}{First Layer}{15}}
\newlabel{subsubsec:matfirstlayer}{{3.2.3}{15}}
\newlabel{eq:matfirst}{{\bfseries  3.3}{15}}
\@writefile{toc}{\contentsline {paragraph}{Example:}{15}}
\@writefile{toc}{\contentsline {subsubsection}{Locality Layer}{16}}
\newlabel{subsubsec:matconvlayer}{{3.2.3}{16}}
\newlabel{eq:matsecond}{{\bfseries  3.6}{17}}
\newlabel{eq:matsecondfinal}{{\bfseries  3.6b}{17}}
\@writefile{toc}{\contentsline {subsubsection}{Final Layer}{17}}
\newlabel{subsubsec:matfinallayer}{{3.2.3}{17}}
\newlabel{eq:matfinal}{{\bfseries  3.7}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Benchmark Model}{17}}
\newlabel{subsec:benchmark}{{3.2.4}{17}}
\newlabel{eq:benchsecond}{{\bfseries  3.8}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}\textit  {n}-independence}{18}}
\newlabel{subsec:nindependence}{{3.2.5}{18}}
\@writefile{toc}{\contentsline {subsubsection}{Trainable Values}{18}}
\@writefile{toc}{\contentsline {subparagraph}{First Layer}{18}}
\@writefile{toc}{\contentsline {subparagraph}{Locality Layer}{18}}
\@writefile{toc}{\contentsline {subparagraph}{Final Layer}{18}}
\@writefile{toc}{\contentsline {subparagraph}{Benchmark Model}{19}}
\@writefile{toc}{\contentsline {subsubsection}{Implications}{19}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Training}{20}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Activation Functions}{20}}
\newlabel{sec:activation}{{4.1}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Initial \& Convolutional Layers}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces ReLU function definition and graph\relax }}{20}}
\newlabel{fig:relu}{{4.1}{20}}
\@writefile{toc}{\contentsline {subsubsection}{Alternative Activations}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Sigmoid function definition and graph\relax }}{21}}
\newlabel{fig:sigmoid}{{4.2}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Final Layer}{21}}
\newlabel{subsec:finalactivation}{{4.1.2}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Graph of $y=\qopname  \relax o{tanh}(x)$\relax }}{21}}
\newlabel{fig:tanh}{{4.3}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Loss \& Optimization}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Loss Function}{22}}
\newlabel{eq:ssd}{{\bfseries  4.1a}{22}}
\newlabel{eq:los}{{\bfseries  4.1b}{23}}
\newlabel{eq:losscalc}{{\bfseries  4.1}{23}}
\@writefile{toc}{\contentsline {subsubsection}{Effects}{23}}
\newlabel{subsubsec:losseffects}{{4.2.1}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces \linespread  {1.2}\selectfont  {}Example adjacency matrix\relax }}{23}}
\newlabel{fig:loss_ex}{{4.4}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Optimizer Function}{24}}
\newlabel{subsec:optimizer}{{4.2.2}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Adam decay function over 100 steps. Converges asymptotically to 1.\relax }}{24}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Datasets}{25}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Matrices}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Initialization}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Locality Layer Operations}{25}}
\newlabel{subsec:localops}{{4.4.2}{25}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Hyperparameter Optimization}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Batch Size}{27}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results}{28}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{results}{{5}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Overfitting}{28}}
\newlabel{sec:overfitting}{{5.1}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces \linespread  {1.2}\selectfont  {}Training parameters for null hypothesis networks\relax }}{28}}
\newlabel{fig:nullparams}{{5.1}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Empty Data}{28}}
\newlabel{subsec:empty}{{5.1.1}{28}}
\newlabel{subfig:empty_loss0}{{5.2a}{29}}
\newlabel{sub@subfig:empty_loss0}{{a}{29}}
\newlabel{subfig:empty_loss1}{{5.2b}{29}}
\newlabel{sub@subfig:empty_loss1}{{b}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Predictions and losses when training on an empty dataset\relax }}{29}}
\newlabel{fig:empty_loss}{{5.2}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Random Data}{29}}
\newlabel{subsec:random}{{5.1.2}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Average prediction for random data. loss: 0.5\relax }}{29}}
\newlabel{fig:random_output}{{5.3}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Analysis}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}3-neuron generator}{30}}
\newlabel{results_3neur}{{5.2}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Network structure and adjacency matrix of the generator. (Reproduced from Figure 3.1\hbox {})\relax }}{30}}
\newlabel{fig:2simplex+adjacency}{{5.4}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Example Model}{31}}
\newlabel{subsec:3neurex}{{5.2.1}{31}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Caption for LOF}}{31}}
\newlabel{fig:3neur_loss+params}{{5.1}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Trained Network Operation}{32}}
\newlabel{subsec:trainedoperation}{{5.2.2}{32}}
\newlabel{subfig:3neur_in}{{5.5a}{32}}
\newlabel{sub@subfig:3neur_in}{{a}{32}}
\newlabel{subfig:3neur_out1}{{5.5c}{32}}
\newlabel{sub@subfig:3neur_out1}{{c}{32}}
\newlabel{subfig:3neur_outf}{{5.5d}{32}}
\newlabel{sub@subfig:3neur_outf}{{d}{32}}
\newlabel{subfig:3neur_pred}{{5.5e}{32}}
\newlabel{sub@subfig:3neur_pred}{{e}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Path of data through network. Transparency for each value is scaled relative to the maximum value found in the matrix.\relax }}{32}}
\newlabel{fig:3neur_run}{{5.5}{32}}
\@writefile{toc}{\contentsline {subsubsection}{Brief Analysis}{33}}
\@writefile{toc}{\contentsline {paragraph}{Final Layer}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Final weights (max: 7.31)\relax }}{33}}
\newlabel{fig:3neur_flayer}{{5.6}{33}}
\@writefile{toc}{\contentsline {paragraph}{Locality Layer Functionality}{33}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Higher-order Datasets}{33}}
\newlabel{sec:localitybroken}{{5.3}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Ten neuron generator and adjacency matrix. For purposes of clarity, all zero values in the matrix have been omitted.\relax }}{34}}
\newlabel{fig:10neur}{{5.7}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Loss \& parameters for model trained on data from generator given in Figure 5.7\hbox {}\relax }}{34}}
\newlabel{fig:9neur_loss+params}{{5.8}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Example of data from generator defined in Figure 5.7\hbox {}, passed through the locality-based and benchmarks models.\relax }}{35}}
\newlabel{fig:samepred}{{5.9}{35}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Applicability Beyond Training Data}{35}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Inverted Network}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Inverted version of Figure 5.4\hbox {}\relax }}{36}}
\newlabel{fig:2simplexVar1}{{5.10}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Cyclical Network}{36}}
\newlabel{subsec:cyclical}{{5.4.2}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Cyclical 3-neuron network\relax }}{36}}
\newlabel{fig:2simplexVar2}{{5.11}{36}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Discussion}{38}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Data}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Complex Neurons}{39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Larger, Structured Networks}{39}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Potential Improvements to Locality}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Layering}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Algorithm}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}Loss}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.4}Optimizer}{41}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Potential Applications/Further Development}{41}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Parameter Optimization Miscellanea}{42}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Data}{42}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Spike Rate Determination}{42}}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Model}{43}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Batched Architecture Calculations}{43}}
\newlabel{asec:batched}{{B.1}{43}}
