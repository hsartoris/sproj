2018-04-29 07:17:57.961438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:17:57.962041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.78GiB
2018-04-29 07:17:57.962059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:17:58.173851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:17:58.173887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:17:58.173895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:17:58.174094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7301 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '50',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 6.6946; conv batch loss = 18.6351
Saved checkpoint 1
Step 1124	dumb batch loss = 0.6985; conv batch loss = 0.8119
Step 2249	dumb batch loss = 0.3609; conv batch loss = 0.4295
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2816; conv batch loss = 0.3481
Step 4499	dumb batch loss = 0.1959; conv batch loss = 0.3002
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1182; conv batch loss = 0.1586
Step 6749	dumb batch loss = 0.1228; conv batch loss = 0.1588
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1333; conv batch loss = 0.1526
Step 8999	dumb batch loss = 0.0783; conv batch loss = 0.0926
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0688; conv batch loss = 0.0931
Step 11249	dumb batch loss = 0.1296; conv batch loss = 0.1380
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0956; conv batch loss = 0.1161
Step 13499	dumb batch loss = 0.1142; conv batch loss = 0.1111
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0743; conv batch loss = 0.0737
Step 15749	dumb batch loss = 0.0544; conv batch loss = 0.1048
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0941; conv batch loss = 0.0931
Step 17999	dumb batch loss = 0.0636; conv batch loss = 0.1064
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0740; conv batch loss = 0.0746
Step 20249	dumb batch loss = 0.0258; conv batch loss = 0.0558
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0624; conv batch loss = 0.0811
Step 22499	dumb batch loss = 0.0678; conv batch loss = 0.0896
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0970; conv batch loss = 0.1053
Step 24749	dumb batch loss = 0.0731; conv batch loss = 0.1116
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0688; conv batch loss = 0.0985
Step 26999	dumb batch loss = 0.0663; conv batch loss = 0.1065
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0852; conv batch loss = 0.0780
Step 29249	dumb batch loss = 0.0466; conv batch loss = 0.0664
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0626; conv batch loss = 0.0705
Step 31499	dumb batch loss = 0.0761; conv batch loss = 0.0724
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0833; conv batch loss = 0.0786
Step 33749	dumb batch loss = 0.0718; conv batch loss = 0.0713
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0628; conv batch loss = 0.0891
Step 35999	dumb batch loss = 0.0777; conv batch loss = 0.0672
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0648; conv batch loss = 0.0599
Step 38249	dumb batch loss = 0.0487; conv batch loss = 0.0494
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0910; conv batch loss = 0.0995
Step 40499	dumb batch loss = 0.0446; conv batch loss = 0.0289
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0661; conv batch loss = 0.0628
Step 42749	dumb batch loss = 0.0671; conv batch loss = 0.0783
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0493; conv batch loss = 0.0601
Step 44999	dumb batch loss = 0.0545; conv batch loss = 0.1003
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0719; conv batch loss = 0.0679
Step 47249	dumb batch loss = 0.0770; conv batch loss = 0.0936
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0583; conv batch loss = 0.0803
Step 49499	dumb batch loss = 0.0972; conv batch loss = 0.0714
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/50/final.ckpt
Minimum dumb loss: (20249, 0.025806384)
Minimum conv loss: (40499, 0.02891736)
Dumb model prediction:
[[-0.  -0.  -0.   0.   0.  -0.  -0.  -0.  -0.   0. ]
 [ 1.   0.  -0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.  -0.   0.1  0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [ 0.  -0.  -0.   0.   1.  -0.  -0.   0.   0.   0.1]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.   1.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.   0.   0.   0.   1.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
Conv model prediction:
[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.3]
 [0.  0.  0.  0.  1.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  1.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]
2018-04-29 07:23:47.702364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:23:47.703002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.79GiB
2018-04-29 07:23:47.703020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:23:47.943683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:23:47.943720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:23:47.943728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:23:47.943926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7299 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '51',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 6.4577; conv batch loss = 5.7653
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7534; conv batch loss = 0.7561
Step 2249	dumb batch loss = 0.3041; conv batch loss = 0.3197
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2561; conv batch loss = 0.2264
Step 4499	dumb batch loss = 0.2462; conv batch loss = 0.1847
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.2183; conv batch loss = 0.1283
Step 6749	dumb batch loss = 0.1745; conv batch loss = 0.1151
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.2263; conv batch loss = 0.1325
Step 8999	dumb batch loss = 0.1398; conv batch loss = 0.0697
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.1320; conv batch loss = 0.0754
Step 11249	dumb batch loss = 0.1646; conv batch loss = 0.1100
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1561; conv batch loss = 0.0869
Step 13499	dumb batch loss = 0.1192; conv batch loss = 0.0863
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.1087; conv batch loss = 0.0648
Step 15749	dumb batch loss = 0.0918; conv batch loss = 0.0960
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.1024; conv batch loss = 0.0715
Step 17999	dumb batch loss = 0.1207; conv batch loss = 0.0750
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.1227; conv batch loss = 0.0811
Step 20249	dumb batch loss = 0.0821; conv batch loss = 0.0727
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0807; conv batch loss = 0.0907
Step 22499	dumb batch loss = 0.0862; conv batch loss = 0.0654
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1296; conv batch loss = 0.0918
Step 24749	dumb batch loss = 0.1066; conv batch loss = 0.0829
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.1085; conv batch loss = 0.0663
Step 26999	dumb batch loss = 0.1126; conv batch loss = 0.0766
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0852; conv batch loss = 0.0632
Step 29249	dumb batch loss = 0.0745; conv batch loss = 0.0391
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0990; conv batch loss = 0.0670
Step 31499	dumb batch loss = 0.1068; conv batch loss = 0.0948
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0929; conv batch loss = 0.0775
Step 33749	dumb batch loss = 0.0962; conv batch loss = 0.0613
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.1115; conv batch loss = 0.0615
Step 35999	dumb batch loss = 0.1068; conv batch loss = 0.0543
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.1022; conv batch loss = 0.0634
Step 38249	dumb batch loss = 0.0507; conv batch loss = 0.0446
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0878; conv batch loss = 0.0738
Step 40499	dumb batch loss = 0.0870; conv batch loss = 0.0467
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0750; conv batch loss = 0.0583
Step 42749	dumb batch loss = 0.0855; conv batch loss = 0.0581
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0696; conv batch loss = 0.0736
Step 44999	dumb batch loss = 0.1043; conv batch loss = 0.0615
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0697; conv batch loss = 0.0655
Step 47249	dumb batch loss = 0.1129; conv batch loss = 0.0612
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0822; conv batch loss = 0.0362
Step 49499	dumb batch loss = 0.1082; conv batch loss = 0.0872
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/51/final.ckpt
Minimum dumb loss: (38249, 0.050659776)
Minimum conv loss: (48374, 0.03624076)
Dumb model prediction:
[[ 0.   0.  -0.  -0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   0.   0.   0.1  0.   0.   0.   0.   0.   0. ]
 [ 0.8  1.   0.   0.1  0.   0.   0.   0.   0.   0. ]
 [ 0.   0.  -0.   0.   0.   0.  -0.   0.   0.  -0.1]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.3]
 [ 0.   0.  -0.   0.   1.   0.   0.   0.   0.   0. ]
 [ 0.   0.  -0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.  -0.   0.   0.   0.   1.   0.   0.   0. ]
 [ 0.   0.  -0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.   0.  -0.   0.   0.   0.   0.   0.   0.   0. ]]
Conv model prediction:
[[-0.  -0.  -0.   0.   0.   0.   0.  -0.  -0.   0. ]
 [ 1.  -0.   0.   0.   0.   0.   0.   0.  -0.   0. ]
 [ 1.   1.  -0.   0.2  0.   0.  -0.   0.   0.   0. ]
 [-0.  -0.   0.  -0.   0.  -0.   0.  -0.  -0.   0. ]
 [-0.  -0.   0.  -0.   0.   0.   0.   0.  -0.  -0.2]
 [-0.   0.  -0.   0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.   0.  -0.  -0.  -0.  -0.   0. ]
 [-0.   0.  -0.   0.   0.  -0.   1.  -0.  -0.   0. ]
 [ 0.  -0.   0.   0.  -0.   0.   0.   1.  -0.  -0. ]
 [-0.  -0.   0.  -0.   0.  -0.   0.   0.  -0.  -0. ]]
2018-04-29 07:29:38.452577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:29:38.452870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.64GiB
2018-04-29 07:29:38.452894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:29:38.684785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:29:38.684818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:29:38.684825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:29:38.685021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7380 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '52',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 7.5936; conv batch loss = 8.9739
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7400; conv batch loss = 0.8151
Step 2249	dumb batch loss = 0.3627; conv batch loss = 0.4323
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.1872; conv batch loss = 0.2700
Step 4499	dumb batch loss = 0.1808; conv batch loss = 0.2292
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1367; conv batch loss = 0.1483
Step 6749	dumb batch loss = 0.1406; conv batch loss = 0.1299
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1862; conv batch loss = 0.1267
Step 8999	dumb batch loss = 0.0844; conv batch loss = 0.1016
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0827; conv batch loss = 0.1033
Step 11249	dumb batch loss = 0.1207; conv batch loss = 0.1337
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1181; conv batch loss = 0.1090
Step 13499	dumb batch loss = 0.1130; conv batch loss = 0.0914
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0707; conv batch loss = 0.0672
Step 15749	dumb batch loss = 0.0772; conv batch loss = 0.0800
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0754; conv batch loss = 0.0853
Step 17999	dumb batch loss = 0.0668; conv batch loss = 0.0703
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0782; conv batch loss = 0.0919
Step 20249	dumb batch loss = 0.0362; conv batch loss = 0.0403
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0783; conv batch loss = 0.0722
Step 22499	dumb batch loss = 0.0638; conv batch loss = 0.0680
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0997; conv batch loss = 0.0959
Step 24749	dumb batch loss = 0.0829; conv batch loss = 0.0574
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0782; conv batch loss = 0.0881
Step 26999	dumb batch loss = 0.0762; conv batch loss = 0.0731
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0803; conv batch loss = 0.0961
Step 29249	dumb batch loss = 0.0554; conv batch loss = 0.0509
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0624; conv batch loss = 0.0708
Step 31499	dumb batch loss = 0.0771; conv batch loss = 0.0874
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0738; conv batch loss = 0.0870
Step 33749	dumb batch loss = 0.0813; conv batch loss = 0.0900
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0765; conv batch loss = 0.1001
Step 35999	dumb batch loss = 0.0600; conv batch loss = 0.0889
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0611; conv batch loss = 0.0766
Step 38249	dumb batch loss = 0.0446; conv batch loss = 0.0304
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.1025; conv batch loss = 0.1094
Step 40499	dumb batch loss = 0.0620; conv batch loss = 0.0287
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0645; conv batch loss = 0.0609
Step 42749	dumb batch loss = 0.0781; conv batch loss = 0.0811
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0917; conv batch loss = 0.0666
Step 44999	dumb batch loss = 0.0726; conv batch loss = 0.0840
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0819; conv batch loss = 0.0757
Step 47249	dumb batch loss = 0.1018; conv batch loss = 0.0975
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0752; conv batch loss = 0.0794
Step 49499	dumb batch loss = 0.1038; conv batch loss = 0.1148
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/52/final.ckpt
Minimum dumb loss: (20249, 0.036232065)
Minimum conv loss: (40499, 0.028715499)
Dumb model prediction:
[[-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.   0.1  0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.9]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
Conv model prediction:
[[-0.1 -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.1 -0. ]
 [ 1.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.   0.2 -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.1 -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.6]
 [-0.1 -0.  -0.  -0.   1.  -0.1 -0.  -0.  -0.  -0. ]
 [-0.1 -0.  -0.  -0.  -0.  -0.1 -0.  -0.  -0.  -0. ]
 [-0.1 -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [-0.1 -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
2018-04-29 07:35:27.964363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:35:27.964909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.74GiB
2018-04-29 07:35:27.964931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:35:28.213241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:35:28.213288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:35:28.213296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:35:28.213507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7331 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '53',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 4.0689; conv batch loss = 8.9071
Saved checkpoint 1
Step 1124	dumb batch loss = 0.5059; conv batch loss = 0.7187
Step 2249	dumb batch loss = 0.2428; conv batch loss = 0.4282
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.1790; conv batch loss = 0.3484
Step 4499	dumb batch loss = 0.1767; conv batch loss = 0.2549
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1031; conv batch loss = 0.1892
Step 6749	dumb batch loss = 0.1142; conv batch loss = 0.1636
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1517; conv batch loss = 0.1925
Step 8999	dumb batch loss = 0.0839; conv batch loss = 0.1259
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0680; conv batch loss = 0.0920
Step 11249	dumb batch loss = 0.0981; conv batch loss = 0.1164
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0851; conv batch loss = 0.1246
Step 13499	dumb batch loss = 0.0987; conv batch loss = 0.0972
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0816; conv batch loss = 0.1005
Step 15749	dumb batch loss = 0.0718; conv batch loss = 0.0928
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0770; conv batch loss = 0.0807
Step 17999	dumb batch loss = 0.0686; conv batch loss = 0.0888
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0828; conv batch loss = 0.0875
Step 20249	dumb batch loss = 0.0365; conv batch loss = 0.0634
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.1018; conv batch loss = 0.0819
Step 22499	dumb batch loss = 0.0789; conv batch loss = 0.0891
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1110; conv batch loss = 0.1151
Step 24749	dumb batch loss = 0.0909; conv batch loss = 0.0905
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0832; conv batch loss = 0.0703
Step 26999	dumb batch loss = 0.0675; conv batch loss = 0.0909
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0900; conv batch loss = 0.0748
Step 29249	dumb batch loss = 0.0656; conv batch loss = 0.0589
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0625; conv batch loss = 0.0813
Step 31499	dumb batch loss = 0.0847; conv batch loss = 0.0863
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0817; conv batch loss = 0.1069
Step 33749	dumb batch loss = 0.0793; conv batch loss = 0.0750
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0741; conv batch loss = 0.0660
Step 35999	dumb batch loss = 0.0584; conv batch loss = 0.0579
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0781; conv batch loss = 0.0522
Step 38249	dumb batch loss = 0.0551; conv batch loss = 0.0463
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0724; conv batch loss = 0.0933
Step 40499	dumb batch loss = 0.0603; conv batch loss = 0.0541
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0876; conv batch loss = 0.0622
Step 42749	dumb batch loss = 0.0853; conv batch loss = 0.0568
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.1009; conv batch loss = 0.0765
Step 44999	dumb batch loss = 0.0659; conv batch loss = 0.0785
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0786; conv batch loss = 0.0710
Step 47249	dumb batch loss = 0.0787; conv batch loss = 0.0707
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0704; conv batch loss = 0.0833
Step 49499	dumb batch loss = 0.0788; conv batch loss = 0.1082
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/53/final.ckpt
Minimum dumb loss: (20249, 0.036470544)
Minimum conv loss: (38249, 0.046284094)
Dumb model prediction:
[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.8]
 [0.  0.  0.  0.  1.  0.  0.  0.  0.  0.1]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  1.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]
Conv model prediction:
[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1]
 [0.  0.  0.  0.  1.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  1.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]
2018-04-29 07:41:19.030926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:41:19.031298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.45GiB
2018-04-29 07:41:19.031325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:41:19.305517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:41:19.305555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:41:19.305566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:41:19.305764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7198 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '54',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 5.4244; conv batch loss = 9.2225
Saved checkpoint 1
Step 1124	dumb batch loss = 0.5783; conv batch loss = 0.7644
Step 2249	dumb batch loss = 0.2869; conv batch loss = 0.3409
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.1962; conv batch loss = 0.2593
Step 4499	dumb batch loss = 0.1982; conv batch loss = 0.2145
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1019; conv batch loss = 0.1240
Step 6749	dumb batch loss = 0.0881; conv batch loss = 0.1242
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1545; conv batch loss = 0.1475
Step 8999	dumb batch loss = 0.0799; conv batch loss = 0.1075
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.1135; conv batch loss = 0.0758
Step 11249	dumb batch loss = 0.1432; conv batch loss = 0.1366
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1011; conv batch loss = 0.0918
Step 13499	dumb batch loss = 0.1034; conv batch loss = 0.1080
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0723; conv batch loss = 0.0736
Step 15749	dumb batch loss = 0.0646; conv batch loss = 0.0961
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0940; conv batch loss = 0.0880
Step 17999	dumb batch loss = 0.0570; conv batch loss = 0.0686
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0715; conv batch loss = 0.0825
Step 20249	dumb batch loss = 0.0539; conv batch loss = 0.0586
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0854; conv batch loss = 0.1025
Step 22499	dumb batch loss = 0.0620; conv batch loss = 0.0796
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1127; conv batch loss = 0.1187
Step 24749	dumb batch loss = 0.0991; conv batch loss = 0.1144
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0859; conv batch loss = 0.0569
Step 26999	dumb batch loss = 0.0791; conv batch loss = 0.0858
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0851; conv batch loss = 0.0734
Step 29249	dumb batch loss = 0.0548; conv batch loss = 0.0652
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0566; conv batch loss = 0.0687
Step 31499	dumb batch loss = 0.0815; conv batch loss = 0.0973
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0825; conv batch loss = 0.0845
Step 33749	dumb batch loss = 0.0826; conv batch loss = 0.0946
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0668; conv batch loss = 0.1020
Step 35999	dumb batch loss = 0.0663; conv batch loss = 0.0708
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0733; conv batch loss = 0.0849
Step 38249	dumb batch loss = 0.0452; conv batch loss = 0.0467
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0763; conv batch loss = 0.0817
Step 40499	dumb batch loss = 0.0366; conv batch loss = 0.0468
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0531; conv batch loss = 0.0697
Step 42749	dumb batch loss = 0.0571; conv batch loss = 0.0774
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0507; conv batch loss = 0.0567
Step 44999	dumb batch loss = 0.0750; conv batch loss = 0.0839
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0765; conv batch loss = 0.0751
Step 47249	dumb batch loss = 0.0951; conv batch loss = 0.1030
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0695; conv batch loss = 0.0701
Step 49499	dumb batch loss = 0.0876; conv batch loss = 0.0838
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/54/final.ckpt
Minimum dumb loss: (40499, 0.036593065)
Minimum conv loss: (38249, 0.0467198)
Dumb model prediction:
[[-0.  -0.  -0.   0.  -0.  -0.   0.  -0.  -0.   0. ]
 [ 1.  -0.  -0.   0.  -0.  -0.   0.   0.  -0.   0. ]
 [ 1.   1.  -0.   0.   0.   0.   0.   0.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.8]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.   1.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
Conv model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [-0.   0.   0.  -0.   0.   0.   0.  -0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.2]
 [-0.   0.   0.   0.   1.   0.   0.  -0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.  -0.   0.  -0.   1.  -0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.9  0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.  -0.   0.   0. ]]
2018-04-29 07:47:09.016607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:47:09.016929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.45GiB
2018-04-29 07:47:09.016950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:47:09.286193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:47:09.286240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:47:09.286249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:47:09.286456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7198 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '55',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 6.4670; conv batch loss = 8.1936
Saved checkpoint 1
Step 1124	dumb batch loss = 0.6336; conv batch loss = 0.7350
Step 2249	dumb batch loss = 0.2647; conv batch loss = 0.4190
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2114; conv batch loss = 0.3247
Step 4499	dumb batch loss = 0.1491; conv batch loss = 0.2599
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1319; conv batch loss = 0.1931
Step 6749	dumb batch loss = 0.0921; conv batch loss = 0.1898
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1586; conv batch loss = 0.1797
Step 8999	dumb batch loss = 0.0746; conv batch loss = 0.1092
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0570; conv batch loss = 0.1068
Step 11249	dumb batch loss = 0.1047; conv batch loss = 0.1497
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0745; conv batch loss = 0.1091
Step 13499	dumb batch loss = 0.1091; conv batch loss = 0.1086
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0838; conv batch loss = 0.0838
Step 15749	dumb batch loss = 0.0530; conv batch loss = 0.0919
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0620; conv batch loss = 0.0951
Step 17999	dumb batch loss = 0.0669; conv batch loss = 0.0851
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0890; conv batch loss = 0.0873
Step 20249	dumb batch loss = 0.0539; conv batch loss = 0.0805
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0706; conv batch loss = 0.0843
Step 22499	dumb batch loss = 0.0608; conv batch loss = 0.0914
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1003; conv batch loss = 0.0942
Step 24749	dumb batch loss = 0.0766; conv batch loss = 0.0727
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0547; conv batch loss = 0.0769
Step 26999	dumb batch loss = 0.0555; conv batch loss = 0.0908
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0746; conv batch loss = 0.0723
Step 29249	dumb batch loss = 0.0507; conv batch loss = 0.0619
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0377; conv batch loss = 0.0773
Step 31499	dumb batch loss = 0.0782; conv batch loss = 0.0768
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0709; conv batch loss = 0.0831
Step 33749	dumb batch loss = 0.0807; conv batch loss = 0.0702
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0731; conv batch loss = 0.0801
Step 35999	dumb batch loss = 0.0727; conv batch loss = 0.1116
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0513; conv batch loss = 0.0839
Step 38249	dumb batch loss = 0.0454; conv batch loss = 0.0496
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0656; conv batch loss = 0.0869
Step 40499	dumb batch loss = 0.0453; conv batch loss = 0.0498
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0515; conv batch loss = 0.0719
Step 42749	dumb batch loss = 0.0480; conv batch loss = 0.0688
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0539; conv batch loss = 0.0630
Step 44999	dumb batch loss = 0.0908; conv batch loss = 0.0828
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0618; conv batch loss = 0.0722
Step 47249	dumb batch loss = 0.0864; conv batch loss = 0.0876
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0752; conv batch loss = 0.0736
Step 49499	dumb batch loss = 0.0957; conv batch loss = 0.0908
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/55/final.ckpt
Minimum dumb loss: (30374, 0.037738863)
Minimum conv loss: (38249, 0.049607623)
Dumb model prediction:
[[-0.  -0.  -0.   0.   0.   0.   0.  -0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.   0.  -0.   0.  -0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.   0.  -0.   0.  -0.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.   0.   0.   0.  -0.   0.   0.1]
 [-0.  -0.  -0.   0.   1.  -0.  -0.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.  -0.   0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.   0.   0.   0.   1.  -0.   0.   0. ]
 [-0.  -0.  -0.   0.   0.   0.   0.   1.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0. ]]
Conv model prediction:
[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1]
 [0.  0.  0.  0.  1.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  1.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]
2018-04-29 07:52:57.798633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:52:57.798930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.45GiB
2018-04-29 07:52:57.798946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:52:58.075742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:52:58.075780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:52:58.075788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:52:58.075999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7198 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '56',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 4.7608; conv batch loss = 10.1417
Saved checkpoint 1
Step 1124	dumb batch loss = 0.5760; conv batch loss = 0.7999
Step 2249	dumb batch loss = 0.2188; conv batch loss = 0.4243
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2191; conv batch loss = 0.2956
Step 4499	dumb batch loss = 0.1974; conv batch loss = 0.2472
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1467; conv batch loss = 0.1603
Step 6749	dumb batch loss = 0.1195; conv batch loss = 0.1563
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1552; conv batch loss = 0.1893
Step 8999	dumb batch loss = 0.0834; conv batch loss = 0.1316
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.1136; conv batch loss = 0.1121
Step 11249	dumb batch loss = 0.1362; conv batch loss = 0.1111
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1086; conv batch loss = 0.1090
Step 13499	dumb batch loss = 0.1030; conv batch loss = 0.1042
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0685; conv batch loss = 0.1071
Step 15749	dumb batch loss = 0.1085; conv batch loss = 0.0856
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.1106; conv batch loss = 0.0958
Step 17999	dumb batch loss = 0.0748; conv batch loss = 0.0992
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0809; conv batch loss = 0.1073
Step 20249	dumb batch loss = 0.0635; conv batch loss = 0.0724
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0648; conv batch loss = 0.0682
Step 22499	dumb batch loss = 0.0943; conv batch loss = 0.0714
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1065; conv batch loss = 0.1286
Step 24749	dumb batch loss = 0.0916; conv batch loss = 0.0986
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0748; conv batch loss = 0.0778
Step 26999	dumb batch loss = 0.0799; conv batch loss = 0.0846
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0975; conv batch loss = 0.1062
Step 29249	dumb batch loss = 0.0652; conv batch loss = 0.0716
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0830; conv batch loss = 0.0818
Step 31499	dumb batch loss = 0.0822; conv batch loss = 0.0830
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0729; conv batch loss = 0.0930
Step 33749	dumb batch loss = 0.0866; conv batch loss = 0.0822
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.1011; conv batch loss = 0.0739
Step 35999	dumb batch loss = 0.0650; conv batch loss = 0.0731
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0569; conv batch loss = 0.0605
Step 38249	dumb batch loss = 0.0402; conv batch loss = 0.0607
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0815; conv batch loss = 0.0899
Step 40499	dumb batch loss = 0.0946; conv batch loss = 0.0592
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0859; conv batch loss = 0.0733
Step 42749	dumb batch loss = 0.0667; conv batch loss = 0.0659
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0732; conv batch loss = 0.0735
Step 44999	dumb batch loss = 0.1002; conv batch loss = 0.0932
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0963; conv batch loss = 0.0729
Step 47249	dumb batch loss = 0.0904; conv batch loss = 0.0997
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0756; conv batch loss = 0.0980
Step 49499	dumb batch loss = 0.0993; conv batch loss = 0.1170
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/56/final.ckpt
Minimum dumb loss: (38249, 0.04024114)
Minimum conv loss: (40499, 0.059173122)
Dumb model prediction:
[[ 0.   0.  -0.   0.   0.  -0.   0.  -0.  -0.   0. ]
 [ 1.   0.  -0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.1  0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.  -0.  -0.   0.   0.  -0.   0.  -0.  -0.   0.8]
 [ 0.  -0.  -0.   0.   1.  -0.   0.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [ 0.  -0.  -0.   0.  -0.  -0.   1.  -0.  -0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.   0. ]]
Conv model prediction:
[[-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.1]
 [ 1.  -0.  -0.   0.  -0.  -0.   0.  -0.  -0.   0. ]
 [ 1.   1.  -0.   0.  -0.  -0.   0.   0.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   1. ]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   0.   1.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
2018-04-29 07:58:44.865575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 07:58:44.865954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.54GiB
2018-04-29 07:58:44.865979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 07:58:45.106218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 07:58:45.106251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 07:58:45.106259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 07:58:45.106453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7214 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '57',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 5.9767; conv batch loss = 9.6089
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7244; conv batch loss = 0.8102
Step 2249	dumb batch loss = 0.3207; conv batch loss = 0.4179
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2517; conv batch loss = 0.3247
Step 4499	dumb batch loss = 0.1704; conv batch loss = 0.2435
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1175; conv batch loss = 0.1590
Step 6749	dumb batch loss = 0.0856; conv batch loss = 0.1512
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1219; conv batch loss = 0.1747
Step 8999	dumb batch loss = 0.0999; conv batch loss = 0.1366
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.1003; conv batch loss = 0.1181
Step 11249	dumb batch loss = 0.1050; conv batch loss = 0.1231
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0912; conv batch loss = 0.1208
Step 13499	dumb batch loss = 0.1130; conv batch loss = 0.1231
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0692; conv batch loss = 0.1082
Step 15749	dumb batch loss = 0.0707; conv batch loss = 0.0907
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0732; conv batch loss = 0.0885
Step 17999	dumb batch loss = 0.0789; conv batch loss = 0.0711
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0581; conv batch loss = 0.0919
Step 20249	dumb batch loss = 0.0396; conv batch loss = 0.0749
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0676; conv batch loss = 0.0818
Step 22499	dumb batch loss = 0.0652; conv batch loss = 0.1028
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0818; conv batch loss = 0.1383
Step 24749	dumb batch loss = 0.0809; conv batch loss = 0.0993
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0795; conv batch loss = 0.0900
Step 26999	dumb batch loss = 0.0555; conv batch loss = 0.0830
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0668; conv batch loss = 0.0807
Step 29249	dumb batch loss = 0.0596; conv batch loss = 0.0428
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0443; conv batch loss = 0.0712
Step 31499	dumb batch loss = 0.0919; conv batch loss = 0.0815
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0710; conv batch loss = 0.0796
Step 33749	dumb batch loss = 0.0735; conv batch loss = 0.0839
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0714; conv batch loss = 0.0707
Step 35999	dumb batch loss = 0.0710; conv batch loss = 0.0777
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0714; conv batch loss = 0.0727
Step 38249	dumb batch loss = 0.0588; conv batch loss = 0.0519
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0893; conv batch loss = 0.0846
Step 40499	dumb batch loss = 0.0454; conv batch loss = 0.0493
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0571; conv batch loss = 0.0450
Step 42749	dumb batch loss = 0.0612; conv batch loss = 0.0684
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0408; conv batch loss = 0.0795
Step 44999	dumb batch loss = 0.0479; conv batch loss = 0.0724
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0625; conv batch loss = 0.0781
Step 47249	dumb batch loss = 0.1028; conv batch loss = 0.1159
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0728; conv batch loss = 0.0766
Step 49499	dumb batch loss = 0.0683; conv batch loss = 0.0942
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/57/final.ckpt
Minimum dumb loss: (20249, 0.039616127)
Minimum conv loss: (29249, 0.042802136)
Dumb model prediction:
[[-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [ 1.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.   0.1 -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.2]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
Conv model prediction:
[[-0.  -0.  -0.   0.   0.  -0.  -0.  -0.  -0.   0.1]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.  -0.   0.   0.   0.   0.   0.   0. ]
 [-0.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.   0. ]
 [ 0.   0.   0.   0.  -0.  -0.   0.  -0.   0.  -0.1]
 [-0.   0.   0.   0.   1.  -0.   0.  -0.   0.  -0. ]
 [-0.   0.   0.  -0.   0.  -0.   0.  -0.   0.  -0. ]
 [-0.   0.  -0.  -0.   0.  -0.   1.  -0.   0.  -0. ]
 [-0.   0.   0.   0.   0.  -0.   0.   1.   0.   0. ]
 [-0.   0.   0.  -0.  -0.  -0.   0.  -0.   0.  -0. ]]
2018-04-29 08:04:33.916643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:04:33.919270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.83GiB
2018-04-29 08:04:33.919293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:04:34.202130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:04:34.202176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:04:34.202184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:04:34.202933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7448 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '58',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 5.9590; conv batch loss = 5.8480
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7038; conv batch loss = 0.6802
Step 2249	dumb batch loss = 0.3082; conv batch loss = 0.3441
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2351; conv batch loss = 0.2955
Step 4499	dumb batch loss = 0.2018; conv batch loss = 0.2364
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1722; conv batch loss = 0.1675
Step 6749	dumb batch loss = 0.1368; conv batch loss = 0.1647
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1600; conv batch loss = 0.1654
Step 8999	dumb batch loss = 0.0995; conv batch loss = 0.1027
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0881; conv batch loss = 0.0879
Step 11249	dumb batch loss = 0.1300; conv batch loss = 0.1360
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0891; conv batch loss = 0.1039
Step 13499	dumb batch loss = 0.1177; conv batch loss = 0.1038
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0801; conv batch loss = 0.0808
Step 15749	dumb batch loss = 0.0736; conv batch loss = 0.0759
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0743; conv batch loss = 0.0782
Step 17999	dumb batch loss = 0.0914; conv batch loss = 0.0957
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0666; conv batch loss = 0.1115
Step 20249	dumb batch loss = 0.0483; conv batch loss = 0.0530
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0800; conv batch loss = 0.0637
Step 22499	dumb batch loss = 0.0578; conv batch loss = 0.0955
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1092; conv batch loss = 0.1033
Step 24749	dumb batch loss = 0.0912; conv batch loss = 0.0868
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0648; conv batch loss = 0.0818
Step 26999	dumb batch loss = 0.0863; conv batch loss = 0.0876
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0763; conv batch loss = 0.0893
Step 29249	dumb batch loss = 0.0749; conv batch loss = 0.0791
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0661; conv batch loss = 0.0702
Step 31499	dumb batch loss = 0.0857; conv batch loss = 0.0651
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0789; conv batch loss = 0.0869
Step 33749	dumb batch loss = 0.0828; conv batch loss = 0.0704
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0611; conv batch loss = 0.0832
Step 35999	dumb batch loss = 0.0678; conv batch loss = 0.0667
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0698; conv batch loss = 0.0696
Step 38249	dumb batch loss = 0.0555; conv batch loss = 0.0498
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0725; conv batch loss = 0.1046
Step 40499	dumb batch loss = 0.0471; conv batch loss = 0.0624
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0576; conv batch loss = 0.0778
Step 42749	dumb batch loss = 0.0566; conv batch loss = 0.0645
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0627; conv batch loss = 0.0855
Step 44999	dumb batch loss = 0.0798; conv batch loss = 0.0909
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0969; conv batch loss = 0.0740
Step 47249	dumb batch loss = 0.0988; conv batch loss = 0.1137
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0595; conv batch loss = 0.0886
Step 49499	dumb batch loss = 0.0849; conv batch loss = 0.0921
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/58/final.ckpt
Minimum dumb loss: (40499, 0.047143478)
Minimum conv loss: (38249, 0.049754288)
Dumb model prediction:
[[-0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [ 1.   1.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.   0.   0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.7]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [-0.   0.   0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
Conv model prediction:
[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 1.  1.  0.  0. -0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0. -0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0. -0.]
 [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0. -0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]
2018-04-29 08:10:23.473442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:10:23.473733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.83GiB
2018-04-29 08:10:23.473749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:10:23.681712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:10:23.681749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:10:23.681756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:10:23.681958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7561 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '59',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 8.1994; conv batch loss = 10.0299
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7758; conv batch loss = 0.7712
Step 2249	dumb batch loss = 0.3191; conv batch loss = 0.4989
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2430; conv batch loss = 0.3602
Step 4499	dumb batch loss = 0.2156; conv batch loss = 0.3025
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1760; conv batch loss = 0.1913
Step 6749	dumb batch loss = 0.1233; conv batch loss = 0.1437
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1596; conv batch loss = 0.1616
Step 8999	dumb batch loss = 0.1182; conv batch loss = 0.0964
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0923; conv batch loss = 0.0786
Step 11249	dumb batch loss = 0.1258; conv batch loss = 0.1243
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0779; conv batch loss = 0.1050
Step 13499	dumb batch loss = 0.1076; conv batch loss = 0.1096
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0691; conv batch loss = 0.0855
Step 15749	dumb batch loss = 0.0612; conv batch loss = 0.0834
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0917; conv batch loss = 0.0871
Step 17999	dumb batch loss = 0.0735; conv batch loss = 0.0830
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0905; conv batch loss = 0.1027
Step 20249	dumb batch loss = 0.0586; conv batch loss = 0.0591
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0652; conv batch loss = 0.0885
Step 22499	dumb batch loss = 0.0696; conv batch loss = 0.0598
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1132; conv batch loss = 0.0944
Step 24749	dumb batch loss = 0.0965; conv batch loss = 0.0931
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0918; conv batch loss = 0.1000
Step 26999	dumb batch loss = 0.0738; conv batch loss = 0.0877
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0896; conv batch loss = 0.0903
Step 29249	dumb batch loss = 0.0578; conv batch loss = 0.0725
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0674; conv batch loss = 0.0842
Step 31499	dumb batch loss = 0.0874; conv batch loss = 0.0995
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0761; conv batch loss = 0.0687
Step 33749	dumb batch loss = 0.0794; conv batch loss = 0.1076
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0755; conv batch loss = 0.0916
Step 35999	dumb batch loss = 0.0545; conv batch loss = 0.0770
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0573; conv batch loss = 0.0574
Step 38249	dumb batch loss = 0.0521; conv batch loss = 0.0511
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0772; conv batch loss = 0.1031
Step 40499	dumb batch loss = 0.0595; conv batch loss = 0.0730
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0746; conv batch loss = 0.0444
Step 42749	dumb batch loss = 0.0646; conv batch loss = 0.0552
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0819; conv batch loss = 0.0864
Step 44999	dumb batch loss = 0.0858; conv batch loss = 0.0777
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0838; conv batch loss = 0.0707
Step 47249	dumb batch loss = 0.0882; conv batch loss = 0.0974
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0554; conv batch loss = 0.0590
Step 49499	dumb batch loss = 0.0822; conv batch loss = 0.0964
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/59/final.ckpt
Minimum dumb loss: (38249, 0.05208997)
Minimum conv loss: (41624, 0.0443678)
Dumb model prediction:
[[-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.  -0.  -0.   0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.4]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
Conv model prediction:
[[-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.9]
 [-0.  -0.  -0.  -0.   1.  -0.   0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.   0.   0.  -0.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.   0.  -0.   0.  -0.   1.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0. ]]
2018-04-29 08:16:15.331440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:16:15.331730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.55GiB
2018-04-29 08:16:15.331746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:16:15.541052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:16:15.541086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:16:15.541093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:16:15.541276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7229 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '60',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 4.0684; conv batch loss = 11.1582
Saved checkpoint 1
Step 1124	dumb batch loss = 0.6303; conv batch loss = 0.8261
Step 2249	dumb batch loss = 0.2749; conv batch loss = 0.5162
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2415; conv batch loss = 0.4007
Step 4499	dumb batch loss = 0.1784; conv batch loss = 0.3352
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1265; conv batch loss = 0.2226
Step 6749	dumb batch loss = 0.1240; conv batch loss = 0.1738
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1489; conv batch loss = 0.2328
Step 8999	dumb batch loss = 0.0768; conv batch loss = 0.1248
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0894; conv batch loss = 0.1419
Step 11249	dumb batch loss = 0.1285; conv batch loss = 0.1669
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0871; conv batch loss = 0.1318
Step 13499	dumb batch loss = 0.1059; conv batch loss = 0.1234
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0822; conv batch loss = 0.1050
Step 15749	dumb batch loss = 0.0627; conv batch loss = 0.0809
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0676; conv batch loss = 0.1037
Step 17999	dumb batch loss = 0.0797; conv batch loss = 0.0913
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0824; conv batch loss = 0.1084
Step 20249	dumb batch loss = 0.0481; conv batch loss = 0.0537
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0458; conv batch loss = 0.0752
Step 22499	dumb batch loss = 0.0686; conv batch loss = 0.0980
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0852; conv batch loss = 0.1161
Step 24749	dumb batch loss = 0.0856; conv batch loss = 0.0864
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0758; conv batch loss = 0.0903
Step 26999	dumb batch loss = 0.0699; conv batch loss = 0.0956
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0606; conv batch loss = 0.0828
Step 29249	dumb batch loss = 0.0471; conv batch loss = 0.0605
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0462; conv batch loss = 0.0870
Step 31499	dumb batch loss = 0.0829; conv batch loss = 0.1142
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0750; conv batch loss = 0.0977
Step 33749	dumb batch loss = 0.0741; conv batch loss = 0.1052
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0736; conv batch loss = 0.0750
Step 35999	dumb batch loss = 0.0608; conv batch loss = 0.0938
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0625; conv batch loss = 0.0654
Step 38249	dumb batch loss = 0.0541; conv batch loss = 0.0782
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0560; conv batch loss = 0.0954
Step 40499	dumb batch loss = 0.0483; conv batch loss = 0.0667
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0645; conv batch loss = 0.0763
Step 42749	dumb batch loss = 0.0664; conv batch loss = 0.0628
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0418; conv batch loss = 0.0635
Step 44999	dumb batch loss = 0.0566; conv batch loss = 0.0889
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0694; conv batch loss = 0.0934
Step 47249	dumb batch loss = 0.0800; conv batch loss = 0.0845
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0848; conv batch loss = 0.0882
Step 49499	dumb batch loss = 0.0798; conv batch loss = 0.0983
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/60/final.ckpt
Minimum dumb loss: (43874, 0.041755427)
Minimum conv loss: (20249, 0.053700384)
Dumb model prediction:
[[-0. -0. -0.  0.  0. -0.  0.  0. -0.  0.]
 [ 1. -0. -0.  0.  0. -0.  0.  0.  0.  0.]
 [ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]
 [-0. -0. -0.  0. -0. -0. -0. -0. -0.  0.]
 [-0. -0. -0.  0.  0.  0.  0.  0. -0.  0.]
 [ 0. -0. -0.  0.  1.  0.  0.  0. -0.  0.]
 [-0. -0. -0.  0. -0. -0. -0. -0. -0.  0.]
 [-0. -0. -0.  0. -0. -0.  1. -0. -0.  0.]
 [-0. -0. -0.  0.  0.  0.  0.  1. -0.  0.]
 [-0. -0. -0.  0. -0. -0. -0. -0. -0. -0.]]
Conv model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.  -0.5  0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.8]
 [ 0.   0.   0.   0.   1.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]
2018-04-29 08:22:06.570784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:22:06.571384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.44GiB
2018-04-29 08:22:06.571412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:22:06.850699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:22:06.850751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:22:06.850759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:22:06.850955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7068 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '61',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 8.0756; conv batch loss = 11.1325
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7571; conv batch loss = 0.7872
Step 2249	dumb batch loss = 0.3660; conv batch loss = 0.3849
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2460; conv batch loss = 0.3550
Step 4499	dumb batch loss = 0.2212; conv batch loss = 0.2540
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1393; conv batch loss = 0.1676
Step 6749	dumb batch loss = 0.1467; conv batch loss = 0.1771
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1440; conv batch loss = 0.1975
Step 8999	dumb batch loss = 0.1084; conv batch loss = 0.1142
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0865; conv batch loss = 0.1069
Step 11249	dumb batch loss = 0.1306; conv batch loss = 0.1735
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0955; conv batch loss = 0.1242
Step 13499	dumb batch loss = 0.0971; conv batch loss = 0.1198
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0753; conv batch loss = 0.0857
Step 15749	dumb batch loss = 0.0587; conv batch loss = 0.1119
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0665; conv batch loss = 0.0876
Step 17999	dumb batch loss = 0.0723; conv batch loss = 0.1064
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0652; conv batch loss = 0.1254
Step 20249	dumb batch loss = 0.0457; conv batch loss = 0.0663
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0411; conv batch loss = 0.0683
Step 22499	dumb batch loss = 0.0548; conv batch loss = 0.0869
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0984; conv batch loss = 0.1028
Step 24749	dumb batch loss = 0.0769; conv batch loss = 0.1013
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0719; conv batch loss = 0.1025
Step 26999	dumb batch loss = 0.0597; conv batch loss = 0.1152
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0501; conv batch loss = 0.0935
Step 29249	dumb batch loss = 0.0674; conv batch loss = 0.0609
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0634; conv batch loss = 0.0823
Step 31499	dumb batch loss = 0.0627; conv batch loss = 0.0757
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0702; conv batch loss = 0.0553
Step 33749	dumb batch loss = 0.0836; conv batch loss = 0.0834
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0631; conv batch loss = 0.0690
Step 35999	dumb batch loss = 0.0523; conv batch loss = 0.0627
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0752; conv batch loss = 0.0543
Step 38249	dumb batch loss = 0.0320; conv batch loss = 0.0533
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0765; conv batch loss = 0.0939
Step 40499	dumb batch loss = 0.0392; conv batch loss = 0.0542
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0539; conv batch loss = 0.0733
Step 42749	dumb batch loss = 0.0715; conv batch loss = 0.0812
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0491; conv batch loss = 0.0725
Step 44999	dumb batch loss = 0.0746; conv batch loss = 0.1113
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0651; conv batch loss = 0.0885
Step 47249	dumb batch loss = 0.0740; conv batch loss = 0.1090
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0417; conv batch loss = 0.0882
Step 49499	dumb batch loss = 0.0824; conv batch loss = 0.0796
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/61/final.ckpt
Minimum dumb loss: (38249, 0.031951312)
Minimum conv loss: (38249, 0.053310066)
Dumb model prediction:
[[-0.  -0.  -0.  -0.  -0.  -0.   0.  -0.  -0.   0. ]
 [ 1.  -0.   0.  -0.   0.   0.  -0.  -0.  -0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.1]
 [-0.  -0.   0.   0.   0.   0.  -0.  -0.  -0.   0.2]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.   0. ]
 [ 0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [ 0.  -0.   0.   0.   0.   0.   1.   0.  -0.   0. ]
 [ 0.  -0.   0.   0.  -0.   0.  -0.   1.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0. ]]
Conv model prediction:
[[ 0.  -0.   0.   0.   0.   0.   0.   0.  -0.   0. ]
 [ 1.  -0.   0.   0.   0.   0.   0.   0.  -0.   0. ]
 [ 1.   1.   0.   0.1  0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.  -0.   0.   0.   0. ]
 [ 0.  -0.  -0.   0.  -0.   0.   0.   0.  -0.   0.1]
 [ 0.   0.  -0.   0.   1.   0.   0.   0.   0.   0. ]
 [ 0.   0.  -0.   0.   0.   0.  -0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.  -0.   0. ]
 [ 0.  -0.  -0.   0.   0.   0.   0.   1.  -0.   0. ]
 [-0.  -0.   0.   0.  -0.   0.   0.  -0.  -0.  -0. ]]
2018-04-29 08:27:56.847276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:27:56.847624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.45GiB
2018-04-29 08:27:56.847643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:27:57.124283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:27:57.124343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:27:57.124358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:27:57.124592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7198 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '62',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 6.1133; conv batch loss = 10.8402
Saved checkpoint 1
Step 1124	dumb batch loss = 0.6192; conv batch loss = 0.8198
Step 2249	dumb batch loss = 0.2260; conv batch loss = 0.5135
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2125; conv batch loss = 0.3880
Step 4499	dumb batch loss = 0.1773; conv batch loss = 0.2974
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1042; conv batch loss = 0.1970
Step 6749	dumb batch loss = 0.1221; conv batch loss = 0.1564
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1393; conv batch loss = 0.1482
Step 8999	dumb batch loss = 0.0771; conv batch loss = 0.0810
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0821; conv batch loss = 0.0767
Step 11249	dumb batch loss = 0.1317; conv batch loss = 0.1118
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1161; conv batch loss = 0.1002
Step 13499	dumb batch loss = 0.1029; conv batch loss = 0.0897
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0659; conv batch loss = 0.0668
Step 15749	dumb batch loss = 0.0673; conv batch loss = 0.0512
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0818; conv batch loss = 0.0848
Step 17999	dumb batch loss = 0.0632; conv batch loss = 0.0670
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0787; conv batch loss = 0.0798
Step 20249	dumb batch loss = 0.0410; conv batch loss = 0.0428
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0885; conv batch loss = 0.0720
Step 22499	dumb batch loss = 0.0832; conv batch loss = 0.0671
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0990; conv batch loss = 0.1087
Step 24749	dumb batch loss = 0.0826; conv batch loss = 0.0700
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0740; conv batch loss = 0.0585
Step 26999	dumb batch loss = 0.0705; conv batch loss = 0.0751
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0583; conv batch loss = 0.0577
Step 29249	dumb batch loss = 0.0473; conv batch loss = 0.0481
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0508; conv batch loss = 0.0723
Step 31499	dumb batch loss = 0.0830; conv batch loss = 0.0894
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0964; conv batch loss = 0.0916
Step 33749	dumb batch loss = 0.0657; conv batch loss = 0.0709
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0663; conv batch loss = 0.0639
Step 35999	dumb batch loss = 0.0831; conv batch loss = 0.0734
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0597; conv batch loss = 0.0766
Step 38249	dumb batch loss = 0.0458; conv batch loss = 0.0452
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0814; conv batch loss = 0.0751
Step 40499	dumb batch loss = 0.0519; conv batch loss = 0.0415
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0646; conv batch loss = 0.0363
Step 42749	dumb batch loss = 0.0602; conv batch loss = 0.0476
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0634; conv batch loss = 0.0533
Step 44999	dumb batch loss = 0.0559; conv batch loss = 0.0746
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0902; conv batch loss = 0.0615
Step 47249	dumb batch loss = 0.0912; conv batch loss = 0.0769
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0732; conv batch loss = 0.0812
Step 49499	dumb batch loss = 0.1080; conv batch loss = 0.0729
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/62/final.ckpt
Minimum dumb loss: (20249, 0.040997807)
Minimum conv loss: (41624, 0.03630738)
Dumb model prediction:
[[ 0.   0.  -0.   0.   0.   0.  -0.   0.   0.   0. ]
 [ 1.   0.  -0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.  -0.   0.   0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.1]
 [ 0.  -0.  -0.   0.  -0.   0.  -0.   0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.  -0.  -0.   0.  -0.  -0.   1.  -0.  -0.   0. ]
 [ 0.   0.  -0.   0.   0.   0.  -0.   1.   0.   0. ]
 [ 0.  -0.  -0.   0.  -0.  -0.  -0.  -0.   0.  -0. ]]
Conv model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.  -0.   0.   0.  -0.   0.  -0. ]
 [ 0.   0.   0.   0.  -0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.8]
 [ 0.   0.   0.   0.   1.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.  -0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.   0.   0.  -0.  -0.   0.   0.   0.   0.   0. ]]
2018-04-29 08:33:45.910834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:33:45.911181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.45GiB
2018-04-29 08:33:45.911207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:33:46.216482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:33:46.216531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:33:46.216547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:33:46.216787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7177 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '63',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 6.0198; conv batch loss = 11.5903
Saved checkpoint 1
Step 1124	dumb batch loss = 0.6911; conv batch loss = 0.7807
Step 2249	dumb batch loss = 0.2680; conv batch loss = 0.4384
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2091; conv batch loss = 0.3320
Step 4499	dumb batch loss = 0.2090; conv batch loss = 0.2528
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1458; conv batch loss = 0.1714
Step 6749	dumb batch loss = 0.1230; conv batch loss = 0.1751
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1834; conv batch loss = 0.1447
Step 8999	dumb batch loss = 0.1008; conv batch loss = 0.1155
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.1127; conv batch loss = 0.1114
Step 11249	dumb batch loss = 0.1538; conv batch loss = 0.1531
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0990; conv batch loss = 0.1146
Step 13499	dumb batch loss = 0.0874; conv batch loss = 0.1085
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.1013; conv batch loss = 0.0772
Step 15749	dumb batch loss = 0.0927; conv batch loss = 0.0691
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0982; conv batch loss = 0.0852
Step 17999	dumb batch loss = 0.1253; conv batch loss = 0.0938
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0723; conv batch loss = 0.0743
Step 20249	dumb batch loss = 0.0432; conv batch loss = 0.0627
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0788; conv batch loss = 0.0857
Step 22499	dumb batch loss = 0.0552; conv batch loss = 0.0713
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0901; conv batch loss = 0.0839
Step 24749	dumb batch loss = 0.0875; conv batch loss = 0.0923
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0771; conv batch loss = 0.0855
Step 26999	dumb batch loss = 0.0859; conv batch loss = 0.0822
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0881; conv batch loss = 0.0691
Step 29249	dumb batch loss = 0.0490; conv batch loss = 0.0538
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0774; conv batch loss = 0.0749
Step 31499	dumb batch loss = 0.0785; conv batch loss = 0.0925
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0849; conv batch loss = 0.1092
Step 33749	dumb batch loss = 0.0977; conv batch loss = 0.0732
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.1058; conv batch loss = 0.0826
Step 35999	dumb batch loss = 0.0668; conv batch loss = 0.0727
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0820; conv batch loss = 0.0689
Step 38249	dumb batch loss = 0.0459; conv batch loss = 0.0404
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0695; conv batch loss = 0.0742
Step 40499	dumb batch loss = 0.0745; conv batch loss = 0.0519
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0810; conv batch loss = 0.0618
Step 42749	dumb batch loss = 0.0708; conv batch loss = 0.0837
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0539; conv batch loss = 0.0723
Step 44999	dumb batch loss = 0.0634; conv batch loss = 0.0771
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0648; conv batch loss = 0.0920
Step 47249	dumb batch loss = 0.0838; conv batch loss = 0.0984
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0775; conv batch loss = 0.0612
Step 49499	dumb batch loss = 0.0950; conv batch loss = 0.1043
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/63/final.ckpt
Minimum dumb loss: (20249, 0.043237876)
Minimum conv loss: (38249, 0.040363904)
Dumb model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.  -0.  -0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.  -0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.  -0. ]
 [ 0.  -0.  -0.   0.  -0.  -0.   0.   0.  -0.   0. ]
 [ 0.   0.   0.   0.  -0.   0.   0.   0.  -0.   0.2]
 [ 0.   0.   0.   0.   1.   0.   0.   0.   0.   0.4]
 [ 0.   0.   0.   0.  -0.   0.   0.  -0.  -0.   0. ]
 [ 0.   0.   0.   0.  -0.   0.   1.   0.  -0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.   0.   0.   0.  -0.  -0.   0.  -0.  -0.   0. ]]
Conv model prediction:
[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [1.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.9]
 [0.  0.  0.  0.  1.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  1.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  1.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]
2018-04-29 08:39:33.915199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:39:33.915581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.64GiB
2018-04-29 08:39:33.915604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:39:34.216793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:39:34.216828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:39:34.216835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:39:34.217025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7380 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '64',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 5.3656; conv batch loss = 8.1027
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7189; conv batch loss = 0.7929
Step 2249	dumb batch loss = 0.4054; conv batch loss = 0.3858
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2037; conv batch loss = 0.2462
Step 4499	dumb batch loss = 0.1624; conv batch loss = 0.2306
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.0926; conv batch loss = 0.1431
Step 6749	dumb batch loss = 0.0901; conv batch loss = 0.1528
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1388; conv batch loss = 0.1952
Step 8999	dumb batch loss = 0.0674; conv batch loss = 0.0895
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0861; conv batch loss = 0.0812
Step 11249	dumb batch loss = 0.1179; conv batch loss = 0.1066
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0783; conv batch loss = 0.0998
Step 13499	dumb batch loss = 0.0880; conv batch loss = 0.1023
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0601; conv batch loss = 0.0686
Step 15749	dumb batch loss = 0.0664; conv batch loss = 0.0712
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0666; conv batch loss = 0.0784
Step 17999	dumb batch loss = 0.0663; conv batch loss = 0.0911
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0650; conv batch loss = 0.0848
Step 20249	dumb batch loss = 0.0507; conv batch loss = 0.0694
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0553; conv batch loss = 0.0802
Step 22499	dumb batch loss = 0.0546; conv batch loss = 0.0891
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0936; conv batch loss = 0.1159
Step 24749	dumb batch loss = 0.0936; conv batch loss = 0.1313
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0624; conv batch loss = 0.0779
Step 26999	dumb batch loss = 0.0889; conv batch loss = 0.0988
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0676; conv batch loss = 0.0588
Step 29249	dumb batch loss = 0.0382; conv batch loss = 0.0585
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0550; conv batch loss = 0.0578
Step 31499	dumb batch loss = 0.0656; conv batch loss = 0.0619
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0539; conv batch loss = 0.1009
Step 33749	dumb batch loss = 0.0674; conv batch loss = 0.0730
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0557; conv batch loss = 0.0789
Step 35999	dumb batch loss = 0.0654; conv batch loss = 0.0622
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0740; conv batch loss = 0.0771
Step 38249	dumb batch loss = 0.0361; conv batch loss = 0.0444
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.1067; conv batch loss = 0.0732
Step 40499	dumb batch loss = 0.0333; conv batch loss = 0.0729
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0511; conv batch loss = 0.0649
Step 42749	dumb batch loss = 0.0480; conv batch loss = 0.0615
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0461; conv batch loss = 0.0536
Step 44999	dumb batch loss = 0.0601; conv batch loss = 0.0756
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0810; conv batch loss = 0.0698
Step 47249	dumb batch loss = 0.0740; conv batch loss = 0.1152
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0695; conv batch loss = 0.0669
Step 49499	dumb batch loss = 0.1068; conv batch loss = 0.0912
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/64/final.ckpt
Minimum dumb loss: (40499, 0.033259418)
Minimum conv loss: (38249, 0.044431478)
Dumb model prediction:
[[-0.   0.   0.  -0.  -0.  -0.  -0.   0.   0.  -0. ]
 [ 1.   0.   0.  -0.  -0.  -0.  -0.  -0.   0.  -0. ]
 [ 1.   1.   0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.  -0. ]
 [-0.   0.   0.  -0.  -0.  -0.  -0.   0.  -0.   0.4]
 [ 0.   0.   0.  -0.   1.  -0.  -0.   0.  -0.   0. ]
 [ 0.   0.   0.  -0.   0.   0.  -0.   0.   0.  -0. ]
 [-0.   0.   0.  -0.  -0.  -0.   1.   0.   0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.  -0. ]]
Conv model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.2]
 [ 0.   0.   0.  -0.2  1.   0.   0.   0.   0.   0.1]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]
2018-04-29 08:45:22.025575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:45:22.026066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.74GiB
2018-04-29 08:45:22.026089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:45:22.256492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:45:22.256531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:45:22.256540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:45:22.256734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7426 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '65',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 11.0374; conv batch loss = 8.5696
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7847; conv batch loss = 0.7099
Step 2249	dumb batch loss = 0.4336; conv batch loss = 0.3395
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2814; conv batch loss = 0.3119
Step 4499	dumb batch loss = 0.2501; conv batch loss = 0.2304
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1290; conv batch loss = 0.1659
Step 6749	dumb batch loss = 0.1542; conv batch loss = 0.1555
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1808; conv batch loss = 0.1612
Step 8999	dumb batch loss = 0.1111; conv batch loss = 0.0964
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.1172; conv batch loss = 0.0898
Step 11249	dumb batch loss = 0.1197; conv batch loss = 0.1563
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0972; conv batch loss = 0.1204
Step 13499	dumb batch loss = 0.1097; conv batch loss = 0.1285
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0950; conv batch loss = 0.0997
Step 15749	dumb batch loss = 0.0937; conv batch loss = 0.0870
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0967; conv batch loss = 0.0983
Step 17999	dumb batch loss = 0.0809; conv batch loss = 0.0776
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.1214; conv batch loss = 0.0936
Step 20249	dumb batch loss = 0.0675; conv batch loss = 0.0636
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0823; conv batch loss = 0.0667
Step 22499	dumb batch loss = 0.0872; conv batch loss = 0.0856
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1266; conv batch loss = 0.1287
Step 24749	dumb batch loss = 0.0961; conv batch loss = 0.0968
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.1148; conv batch loss = 0.0941
Step 26999	dumb batch loss = 0.0885; conv batch loss = 0.0872
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0750; conv batch loss = 0.0808
Step 29249	dumb batch loss = 0.0775; conv batch loss = 0.0459
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0697; conv batch loss = 0.0792
Step 31499	dumb batch loss = 0.0659; conv batch loss = 0.0758
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0775; conv batch loss = 0.0924
Step 33749	dumb batch loss = 0.0677; conv batch loss = 0.0640
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0807; conv batch loss = 0.0612
Step 35999	dumb batch loss = 0.0753; conv batch loss = 0.0695
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0741; conv batch loss = 0.0629
Step 38249	dumb batch loss = 0.0446; conv batch loss = 0.0403
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0805; conv batch loss = 0.0748
Step 40499	dumb batch loss = 0.0506; conv batch loss = 0.0441
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0711; conv batch loss = 0.0534
Step 42749	dumb batch loss = 0.0718; conv batch loss = 0.0392
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0716; conv batch loss = 0.0627
Step 44999	dumb batch loss = 0.0803; conv batch loss = 0.0709
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0627; conv batch loss = 0.0825
Step 47249	dumb batch loss = 0.0782; conv batch loss = 0.1095
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0789; conv batch loss = 0.0649
Step 49499	dumb batch loss = 0.0958; conv batch loss = 0.1068
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/65/final.ckpt
Minimum dumb loss: (38249, 0.04456283)
Minimum conv loss: (42749, 0.03922707)
Dumb model prediction:
[[-0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.  -0.  -0.   0.3 -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.  -0.1 -0.  -0.  -0.  -0.1 -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.  -0.  -0.   0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0.   0.2]
 [-0.  -0.   0.  -0.   1.  -0.  -0.  -0.  -0.   0.1]
 [-0.  -0.   0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [-0.   0.   0.  -0.   0.   0.  -0.  -0.   0.  -0. ]]
Conv model prediction:
[[ 0.   0.   0.   0.   0.   0.  -0.   0.   0.   0. ]
 [ 1.  -0.  -0.   0.  -0.   0.  -0.   0.   0.   0. ]
 [ 1.   1.   0.   0.1  0.   0.   0.   0.   0.  -0. ]
 [ 0.   0.   0.   0.   0.   0.  -0.   0.   0.   0. ]
 [ 0.   0.  -0.   0.   0.   0.   0.   0.   0.   0.5]
 [ 0.   0.  -0.   0.   1.   0.   0.   0.   0.   0. ]
 [ 0.   0.  -0.   0.   0.   0.  -0.   0.   0.   0. ]
 [-0.   0.   0.   0.   0.   0.   1.   0.   0.   0. ]
 [-0.  -0.  -0.   0.  -0.   0.  -0.   1.   0.   0. ]
 [-0.   0.   0.   0.  -0.   0.   0.  -0.   0.   0. ]]
2018-04-29 08:51:11.998122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:51:11.998416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.83GiB
2018-04-29 08:51:11.998435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:51:12.209611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:51:12.209648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:51:12.209656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:51:12.209841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7561 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '66',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 11.8544; conv batch loss = 8.5202
Saved checkpoint 1
Step 1124	dumb batch loss = 0.8069; conv batch loss = 0.7958
Step 2249	dumb batch loss = 0.4186; conv batch loss = 0.5453
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2913; conv batch loss = 0.3270
Step 4499	dumb batch loss = 0.2512; conv batch loss = 0.2984
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1557; conv batch loss = 0.1740
Step 6749	dumb batch loss = 0.1564; conv batch loss = 0.1801
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1715; conv batch loss = 0.1632
Step 8999	dumb batch loss = 0.1222; conv batch loss = 0.1115
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.1145; conv batch loss = 0.1037
Step 11249	dumb batch loss = 0.1388; conv batch loss = 0.1539
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0992; conv batch loss = 0.1343
Step 13499	dumb batch loss = 0.1140; conv batch loss = 0.1434
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0915; conv batch loss = 0.0845
Step 15749	dumb batch loss = 0.0659; conv batch loss = 0.0806
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0940; conv batch loss = 0.0950
Step 17999	dumb batch loss = 0.0927; conv batch loss = 0.0859
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0818; conv batch loss = 0.1016
Step 20249	dumb batch loss = 0.0554; conv batch loss = 0.0618
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0752; conv batch loss = 0.0710
Step 22499	dumb batch loss = 0.0767; conv batch loss = 0.0862
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0973; conv batch loss = 0.0880
Step 24749	dumb batch loss = 0.0967; conv batch loss = 0.1006
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0864; conv batch loss = 0.0811
Step 26999	dumb batch loss = 0.0927; conv batch loss = 0.0876
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0863; conv batch loss = 0.0775
Step 29249	dumb batch loss = 0.0590; conv batch loss = 0.0720
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0830; conv batch loss = 0.0904
Step 31499	dumb batch loss = 0.0953; conv batch loss = 0.0946
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0818; conv batch loss = 0.0725
Step 33749	dumb batch loss = 0.0865; conv batch loss = 0.0787
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0888; conv batch loss = 0.0736
Step 35999	dumb batch loss = 0.0792; conv batch loss = 0.0803
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0729; conv batch loss = 0.0563
Step 38249	dumb batch loss = 0.0504; conv batch loss = 0.0679
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0955; conv batch loss = 0.1205
Step 40499	dumb batch loss = 0.0619; conv batch loss = 0.0555
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0851; conv batch loss = 0.0795
Step 42749	dumb batch loss = 0.0843; conv batch loss = 0.0545
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0699; conv batch loss = 0.0709
Step 44999	dumb batch loss = 0.0662; conv batch loss = 0.0622
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0702; conv batch loss = 0.1041
Step 47249	dumb batch loss = 0.0911; conv batch loss = 0.0898
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0819; conv batch loss = 0.0851
Step 49499	dumb batch loss = 0.1047; conv batch loss = 0.0880
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/66/final.ckpt
Minimum dumb loss: (38249, 0.050377414)
Minimum conv loss: (42749, 0.054523934)
Dumb model prediction:
[[ 0.   0.   0.  -0.  -0.   0.   0.  -0.   0.  -0. ]
 [ 1.   0.   0.  -0.  -0.   0.   0.  -0.   0.  -0. ]
 [ 1.   1.   0.  -0.  -0.   0.   0.  -0.   0.  -0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.1]
 [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.4]
 [ 0.   0.   0.  -0.   1.   0.   0.  -0.   0.  -0. ]
 [ 0.   0.   0.  -0.  -0.   0.   0.  -0.  -0.  -0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.9 -0.   0.  -0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   1.   0.  -0. ]
 [ 0.   0.   0.  -0.  -0.   0.   0.   0.   0.  -0. ]]
Conv model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.  -0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.3  0.   0.   0.   0.   0.   0. ]
 [ 0.  -0.   0.   0.   0.  -0.  -0.   0.  -0.   0. ]
 [ 0.  -0.  -0.   0.  -0.   0.  -0.   0.   0.   0.3]
 [ 0.   0.  -0.   0.   1.  -0.  -0.   0.   0.   0. ]
 [ 0.  -0.  -0.   0.   0.  -0.  -0.   0.  -0.   0. ]
 [ 0.  -0.   0.   0.  -0.  -0.   1.  -0.   0.   0. ]
 [ 0.  -0.   0.   0.   0.   0.   0.   0.7  0.  -0. ]
 [ 0.  -0.   0.   0.  -0.  -0.  -0.   0.  -0.   0. ]]
2018-04-29 08:57:02.555096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 08:57:02.555384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.83GiB
2018-04-29 08:57:02.555400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 08:57:02.762196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 08:57:02.762229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 08:57:02.762237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 08:57:02.762433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7561 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '67',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 8.3891; conv batch loss = 10.0219
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7723; conv batch loss = 0.7788
Step 2249	dumb batch loss = 0.3266; conv batch loss = 0.4463
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2307; conv batch loss = 0.3278
Step 4499	dumb batch loss = 0.2007; conv batch loss = 0.3124
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1285; conv batch loss = 0.2030
Step 6749	dumb batch loss = 0.1380; conv batch loss = 0.1706
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1365; conv batch loss = 0.1570
Step 8999	dumb batch loss = 0.0828; conv batch loss = 0.1132
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0700; conv batch loss = 0.0970
Step 11249	dumb batch loss = 0.1457; conv batch loss = 0.1189
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0869; conv batch loss = 0.1199
Step 13499	dumb batch loss = 0.1129; conv batch loss = 0.1277
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0729; conv batch loss = 0.0888
Step 15749	dumb batch loss = 0.0712; conv batch loss = 0.0726
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0823; conv batch loss = 0.0736
Step 17999	dumb batch loss = 0.0700; conv batch loss = 0.0872
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0843; conv batch loss = 0.0899
Step 20249	dumb batch loss = 0.0567; conv batch loss = 0.0601
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0621; conv batch loss = 0.0767
Step 22499	dumb batch loss = 0.0661; conv batch loss = 0.0889
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0937; conv batch loss = 0.1124
Step 24749	dumb batch loss = 0.1036; conv batch loss = 0.0853
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0850; conv batch loss = 0.0856
Step 26999	dumb batch loss = 0.0745; conv batch loss = 0.0661
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0911; conv batch loss = 0.0776
Step 29249	dumb batch loss = 0.0516; conv batch loss = 0.0482
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0479; conv batch loss = 0.0741
Step 31499	dumb batch loss = 0.0657; conv batch loss = 0.0739
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0666; conv batch loss = 0.0658
Step 33749	dumb batch loss = 0.0990; conv batch loss = 0.0777
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0804; conv batch loss = 0.0656
Step 35999	dumb batch loss = 0.0726; conv batch loss = 0.0790
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0800; conv batch loss = 0.0629
Step 38249	dumb batch loss = 0.0437; conv batch loss = 0.0453
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0807; conv batch loss = 0.0835
Step 40499	dumb batch loss = 0.0684; conv batch loss = 0.0621
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0663; conv batch loss = 0.0722
Step 42749	dumb batch loss = 0.0402; conv batch loss = 0.0835
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0736; conv batch loss = 0.0540
Step 44999	dumb batch loss = 0.0644; conv batch loss = 0.0754
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0584; conv batch loss = 0.0781
Step 47249	dumb batch loss = 0.0801; conv batch loss = 0.0957
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0651; conv batch loss = 0.0803
Step 49499	dumb batch loss = 0.0878; conv batch loss = 0.0970
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/67/final.ckpt
Minimum dumb loss: (42749, 0.040152233)
Minimum conv loss: (38249, 0.04531606)
Dumb model prediction:
[[ 0.  -0.   0.  -0.  -0.  -0.  -0.   0.  -0.  -0. ]
 [ 1.  -0.   0.  -0.  -0.   0.  -0.   0.  -0.   0. ]
 [ 1.   1.   0.   0.  -0.   0.   0.   0.  -0.   0. ]
 [ 0.   0.   0.  -0.  -0.   0.  -0.   0.   0.  -0. ]
 [ 0.   0.   0.  -0.  -0.  -0.   0.   0.   0.   0.4]
 [ 0.  -0.   0.  -0.   1.  -0.  -0.   0.   0.   0.1]
 [ 0.   0.   0.  -0.  -0.   0.   0.   0.  -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.  -0. ]]
Conv model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   0.   0.   0.  -0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.  -0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.  -0.   0.   0.   0.   0.  -0.3]
 [ 0.   0.   0.   0.   1.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.  -0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.   0.   0. ]
 [ 0.   0.   0.   0.  -0.   0.   0.   1.   0.  -0. ]
 [ 0.   0.   0.   0.  -0.  -0.   0.   0.   0.  -0. ]]
2018-04-29 09:02:51.913218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 09:02:51.913509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.83GiB
2018-04-29 09:02:51.913526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 09:02:52.161194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 09:02:52.161234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 09:02:52.161242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 09:02:52.161443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7475 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '68',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 5.5052; conv batch loss = 12.8858
Saved checkpoint 1
Step 1124	dumb batch loss = 0.5556; conv batch loss = 0.8229
Step 2249	dumb batch loss = 0.2381; conv batch loss = 0.4709
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.1942; conv batch loss = 0.3111
Step 4499	dumb batch loss = 0.2017; conv batch loss = 0.2723
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1491; conv batch loss = 0.1731
Step 6749	dumb batch loss = 0.1456; conv batch loss = 0.1550
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1723; conv batch loss = 0.1703
Step 8999	dumb batch loss = 0.1106; conv batch loss = 0.1045
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0950; conv batch loss = 0.1225
Step 11249	dumb batch loss = 0.0988; conv batch loss = 0.1363
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1104; conv batch loss = 0.1181
Step 13499	dumb batch loss = 0.1298; conv batch loss = 0.1013
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.1008; conv batch loss = 0.1181
Step 15749	dumb batch loss = 0.0743; conv batch loss = 0.0689
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0981; conv batch loss = 0.0892
Step 17999	dumb batch loss = 0.0897; conv batch loss = 0.0976
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0930; conv batch loss = 0.1007
Step 20249	dumb batch loss = 0.0628; conv batch loss = 0.0703
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0843; conv batch loss = 0.0777
Step 22499	dumb batch loss = 0.0729; conv batch loss = 0.0839
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1222; conv batch loss = 0.1169
Step 24749	dumb batch loss = 0.0937; conv batch loss = 0.0770
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0732; conv batch loss = 0.0925
Step 26999	dumb batch loss = 0.0846; conv batch loss = 0.0891
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0718; conv batch loss = 0.0680
Step 29249	dumb batch loss = 0.0750; conv batch loss = 0.0512
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0681; conv batch loss = 0.0657
Step 31499	dumb batch loss = 0.0893; conv batch loss = 0.0773
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0736; conv batch loss = 0.0707
Step 33749	dumb batch loss = 0.0922; conv batch loss = 0.0969
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.1116; conv batch loss = 0.0711
Step 35999	dumb batch loss = 0.0962; conv batch loss = 0.0714
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0704; conv batch loss = 0.0879
Step 38249	dumb batch loss = 0.0537; conv batch loss = 0.0417
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.1064; conv batch loss = 0.1011
Step 40499	dumb batch loss = 0.0882; conv batch loss = 0.0566
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0762; conv batch loss = 0.0634
Step 42749	dumb batch loss = 0.0703; conv batch loss = 0.0712
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0667; conv batch loss = 0.0648
Step 44999	dumb batch loss = 0.0833; conv batch loss = 0.0683
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0716; conv batch loss = 0.0600
Step 47249	dumb batch loss = 0.0738; conv batch loss = 0.0921
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0855; conv batch loss = 0.0870
Step 49499	dumb batch loss = 0.0954; conv batch loss = 0.0828
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/68/final.ckpt
Minimum dumb loss: (38249, 0.053669956)
Minimum conv loss: (38249, 0.041651323)
Dumb model prediction:
[[ 0.  -0.  -0.   0.   0.   0.   0.  -0.   0.   0. ]
 [ 1.   0.   0.  -0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.   0.   0.  -0.  -0.  -0.   0.1]
 [ 0.   0.  -0.   0.   1.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.   0.  -0.  -0.   0. ]
 [-0.  -0.  -0.   0.   0.  -0.   1.  -0.  -0.   0. ]
 [ 0.  -0.   0.   0.  -0.   0.   0.   1.   0.   0. ]
 [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.  -0.   0. ]]
Conv model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.  -0.  -0.   0.  -0.   0.   0.   0.  -0.   0. ]
 [ 1.   1.   0.   0.1  0.   0.   0.   0.   0.   0. ]
 [-0.  -0.   0.  -0.   0.  -0.  -0.  -0.   0.   0. ]
 [ 0.  -0.  -0.  -0.  -0.   0.  -0.   0.   0.   0.5]
 [-0.   0.   0.  -0.   1.  -0.  -0.   0.   0.   0. ]
 [-0.  -0.  -0.   0.   0.  -0.  -0.  -0.   0.   0. ]
 [-0.   0.  -0.  -0.   0.   0.   1.  -0.   0.   0. ]
 [ 0.  -0.  -0.   0.  -0.   0.  -0.   1.  -0.   0. ]
 [ 0.   0.   0.  -0.  -0.   0.  -0.   0.   0.   0. ]]
2018-04-29 09:08:41.988084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 09:08:41.990065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.82GiB
2018-04-29 09:08:41.990112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 09:08:42.248178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 09:08:42.248204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 09:08:42.248212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 09:08:42.248379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7426 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '69',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 3.7106; conv batch loss = 14.0815
Saved checkpoint 1
Step 1124	dumb batch loss = 0.5751; conv batch loss = 0.7944
Step 2249	dumb batch loss = 0.2367; conv batch loss = 0.4662
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.1928; conv batch loss = 0.3817
Step 4499	dumb batch loss = 0.1845; conv batch loss = 0.3016
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.0957; conv batch loss = 0.1802
Step 6749	dumb batch loss = 0.1170; conv batch loss = 0.1958
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1328; conv batch loss = 0.1726
Step 8999	dumb batch loss = 0.0857; conv batch loss = 0.1138
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0755; conv batch loss = 0.1287
Step 11249	dumb batch loss = 0.1165; conv batch loss = 0.1383
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1094; conv batch loss = 0.1539
Step 13499	dumb batch loss = 0.1127; conv batch loss = 0.1444
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0573; conv batch loss = 0.0925
Step 15749	dumb batch loss = 0.0704; conv batch loss = 0.1208
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0750; conv batch loss = 0.0733
Step 17999	dumb batch loss = 0.0927; conv batch loss = 0.0872
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0773; conv batch loss = 0.1057
Step 20249	dumb batch loss = 0.0666; conv batch loss = 0.0709
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0589; conv batch loss = 0.0763
Step 22499	dumb batch loss = 0.0573; conv batch loss = 0.0830
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1059; conv batch loss = 0.1293
Step 24749	dumb batch loss = 0.0746; conv batch loss = 0.1210
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0856; conv batch loss = 0.1002
Step 26999	dumb batch loss = 0.0938; conv batch loss = 0.0971
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0566; conv batch loss = 0.1035
Step 29249	dumb batch loss = 0.0423; conv batch loss = 0.0824
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0565; conv batch loss = 0.1034
Step 31499	dumb batch loss = 0.0842; conv batch loss = 0.1114
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0659; conv batch loss = 0.0974
Step 33749	dumb batch loss = 0.0772; conv batch loss = 0.0849
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0646; conv batch loss = 0.0821
Step 35999	dumb batch loss = 0.0648; conv batch loss = 0.0686
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0641; conv batch loss = 0.0644
Step 38249	dumb batch loss = 0.0397; conv batch loss = 0.0446
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0912; conv batch loss = 0.0836
Step 40499	dumb batch loss = 0.0529; conv batch loss = 0.0446
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0557; conv batch loss = 0.0620
Step 42749	dumb batch loss = 0.0560; conv batch loss = 0.0710
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0391; conv batch loss = 0.0474
Step 44999	dumb batch loss = 0.0986; conv batch loss = 0.0896
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0651; conv batch loss = 0.0864
Step 47249	dumb batch loss = 0.0749; conv batch loss = 0.1015
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0802; conv batch loss = 0.0863
Step 49499	dumb batch loss = 0.1042; conv batch loss = 0.0822
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/69/final.ckpt
Minimum dumb loss: (43874, 0.039110374)
Minimum conv loss: (40499, 0.044584792)
Dumb model prediction:
[[ 0.   0.   0.  -0.   0.  -0.  -0.   0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.  -0.   0.1  0.   0.  -0.   0.   0.  -0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.  -0.   0.   0.  -0.   0.   0.   0.8]
 [ 0.   0.   0.  -0.   1.   0.  -0.   0.   0.  -0. ]
 [ 0.   0.   0.   0.   0.   0.  -0.   0.   0.  -0. ]
 [ 0.   0.   0.  -0.   0.   0.   1.   0.   0.  -0. ]
 [-0.   0.   0.  -0.   0.   0.   0.   1.   0.  -0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  -0. ]]
Conv model prediction:
[[ 0.   0.   0.  -0.   0.  -0.   0.   0.   0.   0.1]
 [ 1.   0.   0.  -0.   0.   0.   0.  -0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.  -0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  -0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   1. ]
 [ 0.   0.   0.   0.   1.   0.   0.   0.   0.   0.1]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.  -0.   0.   0.   1.   0.   0.   0. ]
 [-0.   0.   0.  -0.   0.   0.   0.   1.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]
2018-04-29 09:14:33.294957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 09:14:33.298221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.82GiB
2018-04-29 09:14:33.298263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 09:14:33.579644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 09:14:33.579684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 09:14:33.579692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 09:14:33.579891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7337 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '70',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 13.1372; conv batch loss = 8.4328
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7638; conv batch loss = 0.8016
Step 2249	dumb batch loss = 0.3469; conv batch loss = 0.3600
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2536; conv batch loss = 0.3312
Step 4499	dumb batch loss = 0.2057; conv batch loss = 0.2705
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1402; conv batch loss = 0.2030
Step 6749	dumb batch loss = 0.1291; conv batch loss = 0.1810
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1517; conv batch loss = 0.1857
Step 8999	dumb batch loss = 0.1289; conv batch loss = 0.1197
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0900; conv batch loss = 0.0891
Step 11249	dumb batch loss = 0.1446; conv batch loss = 0.1312
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0933; conv batch loss = 0.1031
Step 13499	dumb batch loss = 0.1294; conv batch loss = 0.0954
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0919; conv batch loss = 0.0751
Step 15749	dumb batch loss = 0.0763; conv batch loss = 0.0746
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.1062; conv batch loss = 0.0867
Step 17999	dumb batch loss = 0.0780; conv batch loss = 0.0969
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0872; conv batch loss = 0.0812
Step 20249	dumb batch loss = 0.0703; conv batch loss = 0.0833
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0737; conv batch loss = 0.0942
Step 22499	dumb batch loss = 0.0770; conv batch loss = 0.0959
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0929; conv batch loss = 0.1395
Step 24749	dumb batch loss = 0.0790; conv batch loss = 0.1005
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0801; conv batch loss = 0.1122
Step 26999	dumb batch loss = 0.0737; conv batch loss = 0.1111
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0641; conv batch loss = 0.1252
Step 29249	dumb batch loss = 0.0579; conv batch loss = 0.0748
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0745; conv batch loss = 0.0680
Step 31499	dumb batch loss = 0.0940; conv batch loss = 0.0764
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0942; conv batch loss = 0.0789
Step 33749	dumb batch loss = 0.0913; conv batch loss = 0.0747
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0725; conv batch loss = 0.0912
Step 35999	dumb batch loss = 0.0720; conv batch loss = 0.0761
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0768; conv batch loss = 0.0825
Step 38249	dumb batch loss = 0.0383; conv batch loss = 0.0556
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.1130; conv batch loss = 0.0822
Step 40499	dumb batch loss = 0.0436; conv batch loss = 0.0570
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0567; conv batch loss = 0.0825
Step 42749	dumb batch loss = 0.0657; conv batch loss = 0.0621
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0597; conv batch loss = 0.0737
Step 44999	dumb batch loss = 0.0720; conv batch loss = 0.0609
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0684; conv batch loss = 0.0812
Step 47249	dumb batch loss = 0.0995; conv batch loss = 0.0795
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0835; conv batch loss = 0.0945
Step 49499	dumb batch loss = 0.1015; conv batch loss = 0.1152
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/70/final.ckpt
Minimum dumb loss: (38249, 0.038268346)
Minimum conv loss: (38249, 0.055606004)
Dumb model prediction:
[[ 0.   0.  -0.   0.   0.  -0.  -0.   0.   0.  -0. ]
 [ 1.   0.   0.  -0.  -0.   0.  -0.   0.   0.  -0. ]
 [ 1.   1.  -0.  -0.  -0.  -0.  -0.  -0.   0.  -0. ]
 [ 0.  -0.  -0.   0.  -0.   0.  -0.   0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.1]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.   0.   0.   0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [ 0.  -0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [ 0.  -0.  -0.   0.  -0.  -0.  -0.   0.  -0.  -0. ]]
Conv model prediction:
[[-0.   0.   0.   0.  -0.   0.   0.  -0.   0.   0. ]
 [ 1.   0.  -0.   0.   0.  -0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   0.  -0.   0.   0. ]
 [-0.   0.   0.   0.   0.   0.   0.  -0.   0.   0.2]
 [ 0.  -0.  -0.   0.   1.  -0.  -0.   0.   0.   0. ]
 [ 0.  -0.  -0.   0.   0.  -0.  -0.  -0.   0.   0. ]
 [-0.   0.  -0.   0.  -0.   0.   1.  -0.  -0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [-0.   0.   0.   0.  -0.   0.   0.  -0.  -0.  -0. ]]
2018-04-29 09:20:23.919522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 09:20:23.920115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.74GiB
2018-04-29 09:20:23.920136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 09:20:24.128480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 09:20:24.128512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 09:20:24.128520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 09:20:24.128717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7426 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '71',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 5.3820; conv batch loss = 9.9786
Saved checkpoint 1
Step 1124	dumb batch loss = 0.6174; conv batch loss = 0.8145
Step 2249	dumb batch loss = 0.2367; conv batch loss = 0.4751
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2133; conv batch loss = 0.3460
Step 4499	dumb batch loss = 0.1728; conv batch loss = 0.2576
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1280; conv batch loss = 0.1631
Step 6749	dumb batch loss = 0.1401; conv batch loss = 0.2002
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1701; conv batch loss = 0.2027
Step 8999	dumb batch loss = 0.1035; conv batch loss = 0.1330
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0740; conv batch loss = 0.1103
Step 11249	dumb batch loss = 0.1312; conv batch loss = 0.1369
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1055; conv batch loss = 0.1253
Step 13499	dumb batch loss = 0.1248; conv batch loss = 0.1095
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0738; conv batch loss = 0.0699
Step 15749	dumb batch loss = 0.0797; conv batch loss = 0.0671
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0815; conv batch loss = 0.0798
Step 17999	dumb batch loss = 0.1056; conv batch loss = 0.0943
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.1006; conv batch loss = 0.0870
Step 20249	dumb batch loss = 0.0484; conv batch loss = 0.0493
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0602; conv batch loss = 0.0923
Step 22499	dumb batch loss = 0.0996; conv batch loss = 0.0908
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1118; conv batch loss = 0.1085
Step 24749	dumb batch loss = 0.1019; conv batch loss = 0.0730
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0687; conv batch loss = 0.0794
Step 26999	dumb batch loss = 0.0725; conv batch loss = 0.0872
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0645; conv batch loss = 0.0729
Step 29249	dumb batch loss = 0.0584; conv batch loss = 0.0545
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0515; conv batch loss = 0.0599
Step 31499	dumb batch loss = 0.0723; conv batch loss = 0.0872
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0643; conv batch loss = 0.0886
Step 33749	dumb batch loss = 0.0630; conv batch loss = 0.0990
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0814; conv batch loss = 0.0760
Step 35999	dumb batch loss = 0.0665; conv batch loss = 0.0743
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0588; conv batch loss = 0.0733
Step 38249	dumb batch loss = 0.0613; conv batch loss = 0.0656
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0858; conv batch loss = 0.0993
Step 40499	dumb batch loss = 0.0486; conv batch loss = 0.0742
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0685; conv batch loss = 0.0886
Step 42749	dumb batch loss = 0.0568; conv batch loss = 0.0798
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0787; conv batch loss = 0.0563
Step 44999	dumb batch loss = 0.0744; conv batch loss = 0.0903
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0763; conv batch loss = 0.0661
Step 47249	dumb batch loss = 0.0978; conv batch loss = 0.0974
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0881; conv batch loss = 0.0553
Step 49499	dumb batch loss = 0.0981; conv batch loss = 0.0758
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/71/final.ckpt
Minimum dumb loss: (20249, 0.048397247)
Minimum conv loss: (20249, 0.04926164)
Dumb model prediction:
[[ 0.   0.   0.  -0.   0.  -0.  -0.  -0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.  -0.  -0.   0.  -0. ]
 [ 1.   1.   0.   0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.  -0. ]
 [ 0.   0.   0.  -0.   0.  -0.  -0.  -0.   0.   0.5]
 [-0.   0.   0.  -0.   1.  -0.  -0.  -0.   0.  -0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.  -0. ]
 [ 0.   0.   0.  -0.   0.  -0.   1.   0.   0.  -0. ]
 [-0.   0.   0.  -0.  -0.  -0.  -0.   1.   0.  -0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.  -0. ]]
Conv model prediction:
[[ 0.   0.   0.   0.  -0.   0.   0.   0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.  -0.   0.   0.   0. ]
 [ 0.   0.   0.   0.  -0.  -0.   0.   0.  -0.   0. ]
 [-0.   0.   0.   0.   0.   0.   0.   0.   0.  -0.2]
 [-0.   0.   0.   0.   1.   0.   0.   0.   0.  -0. ]
 [ 0.   0.   0.   0.  -0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [-0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]
2018-04-29 09:26:14.117766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 09:26:14.118060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.74GiB
2018-04-29 09:26:14.118077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 09:26:14.370382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 09:26:14.370420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 09:26:14.370428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 09:26:14.370629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7309 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '72',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 3.8701; conv batch loss = 8.7277
Saved checkpoint 1
Step 1124	dumb batch loss = 0.6739; conv batch loss = 0.7353
Step 2249	dumb batch loss = 0.2806; conv batch loss = 0.3953
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2028; conv batch loss = 0.3358
Step 4499	dumb batch loss = 0.2114; conv batch loss = 0.2495
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1214; conv batch loss = 0.1267
Step 6749	dumb batch loss = 0.1298; conv batch loss = 0.1519
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1515; conv batch loss = 0.1438
Step 8999	dumb batch loss = 0.0827; conv batch loss = 0.0945
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0678; conv batch loss = 0.0872
Step 11249	dumb batch loss = 0.1061; conv batch loss = 0.1088
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.0969; conv batch loss = 0.0890
Step 13499	dumb batch loss = 0.0932; conv batch loss = 0.0966
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0708; conv batch loss = 0.0508
Step 15749	dumb batch loss = 0.0643; conv batch loss = 0.0708
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0529; conv batch loss = 0.0764
Step 17999	dumb batch loss = 0.0797; conv batch loss = 0.1060
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0695; conv batch loss = 0.0801
Step 20249	dumb batch loss = 0.0468; conv batch loss = 0.0695
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0617; conv batch loss = 0.0833
Step 22499	dumb batch loss = 0.0650; conv batch loss = 0.0689
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1031; conv batch loss = 0.1177
Step 24749	dumb batch loss = 0.1026; conv batch loss = 0.1016
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0608; conv batch loss = 0.0907
Step 26999	dumb batch loss = 0.0774; conv batch loss = 0.0740
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0570; conv batch loss = 0.0641
Step 29249	dumb batch loss = 0.0562; conv batch loss = 0.0684
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0494; conv batch loss = 0.0755
Step 31499	dumb batch loss = 0.0846; conv batch loss = 0.0760
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0689; conv batch loss = 0.0844
Step 33749	dumb batch loss = 0.0592; conv batch loss = 0.0640
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0589; conv batch loss = 0.0948
Step 35999	dumb batch loss = 0.0590; conv batch loss = 0.0863
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0738; conv batch loss = 0.0725
Step 38249	dumb batch loss = 0.0502; conv batch loss = 0.0417
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0743; conv batch loss = 0.0797
Step 40499	dumb batch loss = 0.0581; conv batch loss = 0.0708
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0743; conv batch loss = 0.0672
Step 42749	dumb batch loss = 0.0591; conv batch loss = 0.0623
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0614; conv batch loss = 0.0817
Step 44999	dumb batch loss = 0.0667; conv batch loss = 0.0655
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0852; conv batch loss = 0.0957
Step 47249	dumb batch loss = 0.1027; conv batch loss = 0.0777
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0639; conv batch loss = 0.0699
Step 49499	dumb batch loss = 0.0497; conv batch loss = 0.0621
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/72/final.ckpt
Minimum dumb loss: (20249, 0.046796214)
Minimum conv loss: (38249, 0.04168871)
Dumb model prediction:
[[ 0. -0. -0.  0. -0. -0.  0.  0. -0.  0.]
 [ 1.  0. -0.  0.  0.  0.  0.  0. -0.  0.]
 [ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]
 [-0. -0. -0.  0. -0. -0.  0. -0. -0. -0.]
 [-0. -0. -0.  0.  0.  0.  0. -0. -0.  1.]
 [ 0. -0. -0.  0.  1.  0.  0.  0. -0.  0.]
 [-0. -0. -0.  0. -0. -0.  0. -0. -0.  0.]
 [-0. -0. -0.  0. -0.  0.  1. -0. -0.  0.]
 [ 0. -0. -0.  0.  0.  0.  0.  1. -0.  0.]
 [-0. -0. -0.  0. -0. -0. -0. -0. -0. -0.]]
Conv model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [-0.  -0.   0.  -0.  -0.  -0.  -0.   0.  -0.   0. ]
 [ 0.   0.   0.  -0.   0.   0.   0.   0.   0.   0.4]
 [ 0.  -0.  -0.  -0.   1.  -0.   0.   0.  -0.   0. ]
 [ 0.  -0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.   0.  -0.   0.   1.  -0.  -0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.  -0.   0.  -0.  -0.  -0.   0.   0.  -0.   0. ]]
2018-04-29 09:32:03.953409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 09:32:03.953782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.74GiB
2018-04-29 09:32:03.953800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 09:32:04.206839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 09:32:04.206878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 09:32:04.206886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 09:32:04.207081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7330 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '73',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 7.1434; conv batch loss = 7.0967
Saved checkpoint 1
Step 1124	dumb batch loss = 0.7067; conv batch loss = 0.7147
Step 2249	dumb batch loss = 0.2936; conv batch loss = 0.3805
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2206; conv batch loss = 0.2947
Step 4499	dumb batch loss = 0.1826; conv batch loss = 0.2479
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1555; conv batch loss = 0.1734
Step 6749	dumb batch loss = 0.1047; conv batch loss = 0.1295
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1465; conv batch loss = 0.1846
Step 8999	dumb batch loss = 0.0846; conv batch loss = 0.1120
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0862; conv batch loss = 0.1011
Step 11249	dumb batch loss = 0.1036; conv batch loss = 0.1422
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1031; conv batch loss = 0.0898
Step 13499	dumb batch loss = 0.1284; conv batch loss = 0.0839
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0881; conv batch loss = 0.0677
Step 15749	dumb batch loss = 0.0631; conv batch loss = 0.0676
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.1150; conv batch loss = 0.0745
Step 17999	dumb batch loss = 0.1097; conv batch loss = 0.0781
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.1058; conv batch loss = 0.0656
Step 20249	dumb batch loss = 0.0731; conv batch loss = 0.0502
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0751; conv batch loss = 0.0684
Step 22499	dumb batch loss = 0.0713; conv batch loss = 0.0527
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.0802; conv batch loss = 0.0939
Step 24749	dumb batch loss = 0.1107; conv batch loss = 0.0808
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0705; conv batch loss = 0.0628
Step 26999	dumb batch loss = 0.0977; conv batch loss = 0.0598
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0675; conv batch loss = 0.0692
Step 29249	dumb batch loss = 0.0496; conv batch loss = 0.0567
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0733; conv batch loss = 0.0665
Step 31499	dumb batch loss = 0.0853; conv batch loss = 0.0847
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.0963; conv batch loss = 0.0516
Step 33749	dumb batch loss = 0.0778; conv batch loss = 0.0799
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0894; conv batch loss = 0.0647
Step 35999	dumb batch loss = 0.0849; conv batch loss = 0.0727
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0804; conv batch loss = 0.0497
Step 38249	dumb batch loss = 0.0429; conv batch loss = 0.0507
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0935; conv batch loss = 0.0855
Step 40499	dumb batch loss = 0.0559; conv batch loss = 0.0658
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0563; conv batch loss = 0.0636
Step 42749	dumb batch loss = 0.0557; conv batch loss = 0.0526
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0636; conv batch loss = 0.0635
Step 44999	dumb batch loss = 0.0703; conv batch loss = 0.0682
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0642; conv batch loss = 0.0549
Step 47249	dumb batch loss = 0.1150; conv batch loss = 0.0936
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0789; conv batch loss = 0.0594
Step 49499	dumb batch loss = 0.1189; conv batch loss = 0.0806
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/73/final.ckpt
Minimum dumb loss: (38249, 0.04291595)
Minimum conv loss: (37124, 0.04968759)
Dumb model prediction:
[[-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 1.   1.  -0.   0.2 -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   0.   0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0.1]
 [-0.  -0.  -0.  -0.   1.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0. ]
 [-0.  -0.   0.  -0.  -0.   0.   0.  -0.  -0.  -0. ]]
Conv model prediction:
[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 1.  1.  0.  0.  0.  0.  0. -0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]
 [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0. -0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]
 [ 0.  0.  0.  0.  0. -0. -0.  1.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]
2018-04-29 09:37:54.792152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-29 09:37:54.792447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.83GiB
2018-04-29 09:37:54.792465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-29 09:37:54.991665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-29 09:37:54.991703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-29 09:37:54.991712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-29 09:37:54.992597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7561 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
# b
30
# d
40
# n
10
# batchSize
32
# initLearnRate
0.001
# trainingSteps
50000
# prefix
dataStaging/9neur50k/
# testMaxIdx, validMaxIdx, trainMaxIdx
50000, 45000, 36000
# noDumb
0
{'--b': '30',
 '--bs': '32',
 '--d': '40',
 '--help': False,
 '--immediate': True,
 '--lr': '.001',
 '--noDumb': False,
 '--outDir': '9neur',
 '--r': '1',
 '--runId': '74',
 '--s': '50k',
 '--ts': '50k',
 '<dataDir>': '9neur50k'}
Initialized model
Loading training data
Successfully loaded 36000 samples
Cropped 0 samples to fit batch size
Loading validation data
Successfully loaded 9000 samples
Cropped 8 samples to fit batch size
Loading testing data
Successfully loaded 5008 samples
Cropped 16 samples to fit batch size
Step 1	dumb batch loss = 4.3451; conv batch loss = 9.4873
Saved checkpoint 1
Step 1124	dumb batch loss = 0.5551; conv batch loss = 0.8138
Step 2249	dumb batch loss = 0.2442; conv batch loss = 0.5184
Saved checkpoint 2249
Step 3374	dumb batch loss = 0.2256; conv batch loss = 0.3160
Step 4499	dumb batch loss = 0.1887; conv batch loss = 0.1970
Saved checkpoint 4499
Step 5624	dumb batch loss = 0.1438; conv batch loss = 0.1126
Step 6749	dumb batch loss = 0.1033; conv batch loss = 0.1114
Saved checkpoint 6749
Step 7874	dumb batch loss = 0.1391; conv batch loss = 0.1308
Step 8999	dumb batch loss = 0.1024; conv batch loss = 0.0844
Saved checkpoint 8999
Step 10124	dumb batch loss = 0.0991; conv batch loss = 0.0872
Step 11249	dumb batch loss = 0.1283; conv batch loss = 0.1241
Saved checkpoint 11249
Step 12374	dumb batch loss = 0.1158; conv batch loss = 0.0789
Step 13499	dumb batch loss = 0.1122; conv batch loss = 0.0862
Saved checkpoint 13499
Step 14624	dumb batch loss = 0.0641; conv batch loss = 0.0866
Step 15749	dumb batch loss = 0.0831; conv batch loss = 0.0618
Saved checkpoint 15749
Step 16874	dumb batch loss = 0.0774; conv batch loss = 0.0719
Step 17999	dumb batch loss = 0.0838; conv batch loss = 0.0980
Saved checkpoint 17999
Step 19124	dumb batch loss = 0.0787; conv batch loss = 0.0909
Step 20249	dumb batch loss = 0.0564; conv batch loss = 0.0376
Saved checkpoint 20249
Step 21374	dumb batch loss = 0.0457; conv batch loss = 0.0629
Step 22499	dumb batch loss = 0.0658; conv batch loss = 0.0561
Saved checkpoint 22499
Step 23624	dumb batch loss = 0.1151; conv batch loss = 0.0985
Step 24749	dumb batch loss = 0.0948; conv batch loss = 0.0704
Saved checkpoint 24749
Step 25874	dumb batch loss = 0.0841; conv batch loss = 0.0715
Step 26999	dumb batch loss = 0.0807; conv batch loss = 0.0738
Saved checkpoint 26999
Step 28124	dumb batch loss = 0.0904; conv batch loss = 0.0756
Step 29249	dumb batch loss = 0.0894; conv batch loss = 0.0580
Saved checkpoint 29249
Step 30374	dumb batch loss = 0.0604; conv batch loss = 0.0565
Step 31499	dumb batch loss = 0.0791; conv batch loss = 0.0585
Saved checkpoint 31499
Step 32624	dumb batch loss = 0.1003; conv batch loss = 0.0847
Step 33749	dumb batch loss = 0.0699; conv batch loss = 0.0709
Saved checkpoint 33749
Step 34874	dumb batch loss = 0.0605; conv batch loss = 0.0614
Step 35999	dumb batch loss = 0.0735; conv batch loss = 0.0587
Saved checkpoint 35999
Step 37124	dumb batch loss = 0.0754; conv batch loss = 0.0551
Step 38249	dumb batch loss = 0.0466; conv batch loss = 0.0472
Saved checkpoint 38249
Step 39374	dumb batch loss = 0.0677; conv batch loss = 0.0699
Step 40499	dumb batch loss = 0.0513; conv batch loss = 0.0490
Saved checkpoint 40499
Step 41624	dumb batch loss = 0.0660; conv batch loss = 0.0651
Step 42749	dumb batch loss = 0.0471; conv batch loss = 0.0465
Saved checkpoint 42749
Step 43874	dumb batch loss = 0.0491; conv batch loss = 0.0640
Step 44999	dumb batch loss = 0.0648; conv batch loss = 0.0694
Saved checkpoint 44999
Step 46124	dumb batch loss = 0.0722; conv batch loss = 0.0632
Step 47249	dumb batch loss = 0.1028; conv batch loss = 0.1057
Saved checkpoint 47249
Step 48374	dumb batch loss = 0.0595; conv batch loss = 0.0625
Step 49499	dumb batch loss = 0.0736; conv batch loss = 0.0878
Saved checkpoint 49499
Training complete; model saved in file model/checkpoints/bench/9neur/74/final.ckpt
Minimum dumb loss: (21374, 0.045656767)
Minimum conv loss: (20249, 0.03759271)
Dumb model prediction:
[[-0.  -0.  -0.   0.   0.   0.   0.   0.  -0.   0. ]
 [ 1.   0.  -0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.  -0.   0.   0.   0.   0.   0.   0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]
 [ 0.  -0.  -0.   0.   0.   0.  -0.   0.  -0.   0.3]
 [-0.  -0.  -0.  -0.   1.   0.  -0.  -0.  -0.   0.1]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.   1.  -0.  -0.  -0. ]
 [ 0.  -0.  -0.   0.   0.   0.   0.   1.  -0.   0. ]
 [-0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0.  -0. ]]
Conv model prediction:
[[ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 1.   1.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  -0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.7]
 [ 0.   0.   0.   0.   1.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   1.   0.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   1.   0.   0. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]
