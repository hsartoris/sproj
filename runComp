#!/usr/bin/python3
"""
Simultaneously runs dumb & conv networks and logs both.

Usage: 
    runComp <dataDir> [--r=<runs>] [--s=<samples>] [--lr=<lr>]
        [--outDir=<outDir>] [--runId=<runId>] [--bs=<batchSize>]
        [--ts=<trainingSteps>] [--b=<b>] [--d=<d>]
    runComp -h | --help

Options:
    -h --help           Show this screen
    <dataDir>           Where to load inputs from. Assumes format dataStaging/!
    --r=<runs>          How many runs. [default: 1]
    --s=<samples>       How many samples to load from <dataDir> [default: 25000].
    --lr=<lr>           Init learning rate [default: .001].
    --outDir=<outDir>   Checkpoint & log directory. If not specified, leaves ckptDir to model/checkpoints/comp/; otherwise that + outDir
    --runId=<runId>     Specify runId. Defaults to timestamp.
    --bs=<batchSize>    Batch size [default: 32].
    --ts=<trainingSteps> Max training steps [default: 20000].
    --b=<b>             Time truncation [default: 30].
    --d=<d>             Featurespace depth [default: 20].
"""

from docopt import docopt
import numpy as np
import signal
import sys
import tensorflow as tf
import model.scripts.Prettify as Prettify
import math
import time
import shutil, os
from model.scripts.SeqData import seqData
from model.model import Model
pretty = Prettify.pretty()

arguments = docopt(__doc__)

SAVE_CKPT = True
# if you set this to False it will break
TBOARD_LOG = False

dataFile = "runData"
epochsToSave = 2 # directly dependent on batchsize of course

# default 32
batchSize = int(arguments['--bs'])

# default .001
initLearnRate = float(arguments['--lr'])

# default 20000
ts = arguments['--ts'].lower()
if 'k' in ts:
    trainingSteps = int(ts.split('k')[0]) * 1000
else:
    trainingSteps = int(ts)

# obvious default
ckptDir = "model/checkpoints/comp/"
if arguments['--outDir']: ckptDir += arguments['--outDir'] + "/"
if not os.path.exists(ckptDir):
    try: os.makedirs(ckptDir)
    except OSError as err:
        print("OSError while creating ckptDir " + ckptDir + ": {0}".format(err))


# default 25000
samples = arguments['--s'].lower()
if 'k' in samples:
    testMaxIdx = int(samples.split('k')[0]) * 1000
else:
    testMaxIdx = int(samples)

validMaxIdx = int(testMaxIdx * .9)
trainMaxIdx = int(validMaxIdx * .8)

# timesteps (default 30)
b = int(arguments['--b'])
# metalayers (default 20)
d = int(arguments['--d'])

prefix = "dataStaging/" + arguments['<dataDir>'] + "/"
if not os.path.exists(prefix):
    print("dataDir '" + prefix + "' not found, exiting.")
    sys.exit()

n = np.loadtxt(prefix + "struct", delimiter=',').shape[0]

runs = int(arguments['--r'])

if arguments['--runId'] is None:
    localtime = time.localtime()
    runId = str(localtime.tm_mday) + "_" + str(localtime.tm_hour) + str(localtime.tm_min)
else:
    runId = arguments['--runId']

training = None
validation = None
testing = None

def loadData():
    global training
    global validation
    global testing
    global trainMaxIdx
    global validMaxIdx
    global testMaxIdx
    # 5120, 6400, 8000
    # 1280, 1600, 2000
    print("Loading training data")
    training = seqData(0, trainMaxIdx, prefix, b)
    trainMaxIdx -= training.crop(batchSize)
    print("Loading validation data")
    validation = seqData(trainMaxIdx, validMaxIdx, prefix, b)
    validMaxIdx -= validation.crop(batchSize)
    print("Loading testing data")
    testing = seqData(validMaxIdx, testMaxIdx, prefix, b)
    testMaxIdx -= testing.crop(batchSize)

def signal_handler(signal, frame):
    makePred()
    if (input("Exit? [Y/n]") or "Y") == "Y":
        cleanup()
        sess.close()
        sys.exit()
signal.signal(signal.SIGINT, signal_handler)

def cleanup():
    clean = input("Clean up logs and checkpoints? [Y/n]") or "Y"
    if clean == "Y":
        shutil.rmtree(ckptDir + runId)

def makePred(checkDir=None):
    global testing
    global sess
    if checkDir is not None:
        saver = tf.train.Saver()
        f = open(checkDir + "latest")
        saver.restore(sess, checkDir + f.readline() + ".ckpt")
        f.close()
        testing = seqData(0, 5, prefix, b)
        testData = testing.data
        testLabels = testing.labels
    testX, testY, _ = testing.next(1)
    print("Dumb model prediction:")
    print(np.round(sess.run(m_dumb.prediction, 
        feed_dict={_data: testX, _labels: testY})[0].reshape(n,n), 1))
    print("Conv model prediction:")
    print(np.round(sess.run(m_conv.prediction,
        feed_dict={_data: testX, _labels: testY})[0].reshape(n,n), 1))

def dumpData():
    out = "# b\n" + str(b) + "\n"
    out += "# d\n" + str(d) + "\n"
    out += "# n\n" + str(n) + "\n"
    out += "# batchSize\n" + str(batchSize) + "\n"
    out += "# initLearnRate\n" + str(initLearnRate) + "\n"
    out += "# trainingSteps\n" + str(trainingSteps) + "\n"
    out += "# prefix\n" + prefix + "\n"
    out += ("# testMaxIdx, validMaxIdx, trainMaxIdx\n" + str(testMaxIdx) + ", " +
            str(validMaxIdx) + ", " + str(trainMaxIdx) + "\n")
    return out

_data = tf.placeholder(tf.float32, [None, b, n])
_labels = tf.placeholder(tf.float32, [None, 1, n*n])
m_dumb = Model(b, d, n, _data, _labels, batchSize, learnRate = initLearnRate, dumb=True)
m_conv = Model(b, d, n, _data, _labels, batchSize, learnRate = initLearnRate, dumb=False)


# save some data
if SAVE_CKPT:
    saver = tf.train.Saver()
    saveDir = (ckptDir + runId + "/")
    try: os.mkdir(saveDir)
    except OSError as err:
        print(err)
        cont = input("Do you wish to overwrite and continue? [Y/n]") or "Y"
        if cont.upper() == "Y":
            shutil.rmtree(saveDir)
            os.mkdir(saveDir)
        else:
            print("exiting")
            sys.exit()
    f = open(saveDir + dataFile, "w+")
    f.write(dumpData())
    f.close()
    f = open(saveDir + "prefix", "w+")
    f.write(prefix)
    f.close()

print(dumpData())

if TBOARD_LOG:
    lossSum = tf.summary.scalar("train_loss", m.loss)
    summWriter = tf.summary.FileWriter(ckptDir + runId + "/train")
    validWriter = tf.summary.FileWriter(ckptDir + runId + "/validation")

loadData()

init = tf.global_variables_initializer()
config = tf.ConfigProto()
config.gpu_options.allow_growth = True

#-----------------------------MODEL TRAINING------------------------------------

sess = tf.Session(config=config)
sess.run(init)

steps = []
losses_dumb = []
losses_conv = []
vlosses_dumb = []
vlosses_conv = []

epochCount = 0
for step in range(trainingSteps):
    batchX, batchY, batchId = training.next(batchSize)
    sess.run(m_dumb.optimize, feed_dict={_data: batchX, _labels: batchY})
    sess.run(m_conv.optimize, feed_dict={_data: batchX, _labels: batchY})
    if batchId == trainMaxIdx or step == 1:
        # end of epoch
        # calculate current loss on training data
        loss_dumb, loss_conv = sess.run([m_dumb.loss, m_conv.loss], 
                feed_dict={_data: batchX, _labels: batchY})

        #loss_conv = sess.run([m_conv.loss], 
        #        feed_dict={_data: batchX, _labels: batchY})

        # calculate validation loss
        validX, validY, _ = validation.next(batchSize)
        vloss_dumb, vloss_conv = sess.run([m_dumb.loss, m_conv.loss], 
                feed_dict={_data: validX, _labels: validY})

        #vloss_conv = sess.run([m_conv.loss], 
        #        feed_dict={_data: validX, _labels: validY})

        steps.append(step)
        losses_dumb.append(loss_dumb)
        losses_conv.append(loss_conv)
        vlosses_dumb.append(vloss_dumb)
        vlosses_conv.append(vloss_conv)

        if TBOARD_LOG:
            # log various data
             validWriter.add_summary(vloss, step)
             summWriter.add_summary(tLoss, step)
        if not step == 1: epochCount += 1
        print("Step " + str(step) + "\tdumb batch loss = {:.4f}".format(vloss_dumb) + 
            "; conv batch loss = {:.4f}".format(vloss_conv))

        if epochCount % epochsToSave == 0 and SAVE_CKPT:
            save = saver.save(sess, saveDir + "/" + str(step) + ".ckpt")
            f = open(saveDir + "latest", "w+")
            f.write(str(step))
            f.close()
            print("Saved checkpoint " + str(step))

    pretty.arrow(batchId, trainMaxIdx)

if SAVE_CKPT:
    save = saver.save(sess, saveDir + "final.ckpt")
    f = open(saveDir + "latest", "w+")
    f.write("final")
    f.close()

    minLossDumb = min(enumerate(vlosses_dumb), key = lambda t: t[1])
    minLossDumb = (steps[minLossDumb[0]], minLossDumb[1])
    minLossConv = min(enumerate(vlosses_conv), key = lambda t: t[1])
    minLossConv = (steps[minLossConv[0]], minLossConv[1])
    print("Training complete; model saved in file %s" % save)
    print("Minimum dumb loss:", str(minLossDumb))
    print("Minimum conv loss:", str(minLossConv))
    f = open(saveDir + dataFile, 'a')
    f.write("# min dumb loss\n" + str(minLossDumb) + "\n")
    f.write("# min conv loss\n" + str(minLossConv) + "\n")
    f.close()

makePred()

os.mkdir(ckptDir + runId + "/conv")
os.mkdir(ckptDir + runId + "/dumb")
os.mkdir(ckptDir + runId + "/conv/mats")
os.mkdir(ckptDir + runId + "/dumb/mats")
m_conv.saveMats(ckptDir + runId + "/conv/mats/", sess)
m_dumb.saveMats(ckptDir + runId + "/dumb/mats/", sess)
np.savetxt(ckptDir + runId + "/steps", np.array(steps), delimiter=',')
np.savetxt(ckptDir + runId + "/conv/losses", np.array(losses_conv), delimiter=',')
np.savetxt(ckptDir + runId + "/conv/vlosses", np.array(vlosses_conv), delimiter=',')
np.savetxt(ckptDir + runId + "/dumb/losses", np.array(losses_dumb), delimiter=',')
np.savetxt(ckptDir + runId + "/dumb/vlosses", np.array(vlosses_dumb), delimiter=',')
sess.close()
